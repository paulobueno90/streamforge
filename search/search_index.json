{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"StreamForge","text":"<p> Real-time cryptocurrency and financial data ingestion made simple </p> <p> </p> <p> Get Started View Examples </p>"},{"location":"#what-is-streamforge","title":"What is StreamForge?","text":"<p>StreamForge is a unified, async-first framework for ingesting real-time market data from cryptocurrency exchanges. Built with Python's asyncio, it offers high-performance data streaming, normalization, and multiple output formats.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> Real-time WebSocket Streaming - Live market data from multiple exchanges</li> <li> Multiple Output Formats - CSV, PostgreSQL, Kafka</li> <li> Multi-Exchange Support - Binance, Kraken, OKX with unified API</li> <li> Timeframe Aggregation - Automatic aggregation to higher timeframes</li> <li> Historical Backfilling - Load months of historical data effortlessly</li> <li> Data Transformation - Built-in transformers for custom data processing</li> <li> Stream Merging - Combine multiple exchanges into unified streams</li> <li> Type-Safe - Full type hints and Pydantic validation</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Install StreamForge in seconds:</p> <pre><code>pip install streamforge\n</code></pre> <p>Stream Bitcoin data in 3 lines:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    # Configure what to stream\n    stream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"1m\")\n\n    # Create runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Start streaming!\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>Output: <pre><code>2025-10-14 16:21:32 - INFO - Aggregation Deactivated\n2025-10-14 16:21:33 - INFO - Binance    | Subscribed Successful to params: {'method': 'SUBSCRIBE', 'params': ['btcusdt@kline_1m'], 'id': 999} | Websocket Input: DataInput(type='kline', symbols=['BTCUSDT'], timeframe='1m', aggregate_list=[]).\n2025-10-14 16:21:33 - INFO - Binance    | Websocket Connection established successfully!\n2025-10-14 16:22:00 - INFO - Binance    | Data Received: source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n2025-10-14 16:22:00 - INFO - Binance | Received Data | source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n</code></pre></p> <p>Learn More \u2192</p>"},{"location":"#supported-exchanges","title":"Supported Exchanges","text":"<ul> <li> <p> Binance</p> <p>World's largest cryptocurrency exchange</p> <ul> <li>Kline/OHLC data</li> <li>Real-time WebSocket</li> <li>Historical backfilling</li> </ul> <p>Guide</p> </li> <li> <p> Kraken</p> <p>Trusted US-based exchange</p> <ul> <li>OHLC data streams</li> <li>WebSocket integration</li> </ul> <p>Guide</p> </li> <li> <p> OKX</p> <p>Leading global crypto exchange</p> <ul> <li>Candlestick data</li> <li>Real-time streaming</li> <li>Historical support</li> </ul> <p>Guide</p> </li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#stream-to-database","title":"Stream to Database","text":"<p>Continuously save market data to PostgreSQL:</p> <pre><code>emitter = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))\n\nrunner = sf.BinanceRunner(stream_input=stream)\nrunner.register_emitter(emitter)\nawait runner.run()\n</code></pre> <p>PostgreSQL Guide \u2192</p>"},{"location":"#multi-timeframe-aggregation","title":"Multi-Timeframe Aggregation","text":"<p>Stream 1-minute data and auto-aggregate to higher timeframes:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"1h\", \"4h\"]  # Auto-aggregate!\n)\n\nrunner = sf.BinanceRunner(stream_input=stream, active_warmup=True)\n</code></pre> <p>Aggregation Guide \u2192</p>"},{"location":"#historical-backfilling","title":"Historical Backfilling","text":"<p>Load months of historical data:</p> <pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2025-01-01\"\n)\n\nbackfiller.register_emitter(postgres_emitter)\nbackfiller.run()\n</code></pre> <p>Backfilling Guide \u2192</p>"},{"location":"#multi-exchange-comparison","title":"Multi-Exchange Comparison","text":"<p>Merge streams from multiple exchanges:</p> <pre><code>from streamforge.merge_stream import merge_streams\n\nbinance_runner = sf.BinanceRunner(stream_input=binance_stream)\nokx_runner = sf.OKXRunner(stream_input=okx_stream)\n\nasync for data in merge_streams(binance_runner, okx_runner):\n    print(f\"{data.source} | {data.symbol} | ${data.close:,.2f}\")\n</code></pre> <p>Multi-Exchange Guide \u2192</p>"},{"location":"#architecture","title":"Architecture","text":"<p>StreamForge uses a simple, composable architecture:</p> <pre><code>graph LR\n    A[Exchange WebSocket] --&gt; B[Runner]\n    B --&gt; C[Normalizer]\n    C --&gt; D[Processor]\n    D --&gt; E[Aggregator]\n    E --&gt; F[Transformer]\n    F --&gt; G1[CSV Emitter]\n    F --&gt; G2[PostgreSQL Emitter]\n    F --&gt; G3[Kafka Emitter]\n    F --&gt; G4[Custom Emitter]</code></pre> <ol> <li>Runner - Manages WebSocket connections and coordinates data flow</li> <li>Normalizer - Standardizes data format across exchanges</li> <li>Processor - Buffers and processes incoming data</li> <li>Aggregator - Aggregates to higher timeframes (optional)</li> <li>Transformer - Applies custom transformations (optional)</li> <li>Emitter - Outputs data to your destination(s)</li> </ol> <p>Core Concepts \u2192</p>"},{"location":"#why-streamforge","title":"Why StreamForge?","text":"<p>Simple &amp; Intuitive</p> <p>Clean, Pythonic API that's easy to learn. Get started in minutes, not hours.</p> <p>Performance Focused</p> <p>Async-first architecture handles high-frequency data streams efficiently.</p> <p>Extensible</p> <p>Create custom emitters, transformers, and processors. Built for customization.</p> <p>Type Safe</p> <p>Full type hints and Pydantic validation catch errors before runtime.</p>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li> <p> Installation</p> <p>Get StreamForge installed and ready to use</p> </li> <li> <p> Quick Start</p> <p>Your first stream in 5 minutes</p> </li> <li> <p> User Guide</p> <p>Deep dive into features and capabilities</p> </li> <li> <p> Examples</p> <p>Copy-paste examples for common tasks</p> </li> <li> <p> API Reference</p> <p>Complete API documentation</p> </li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>Documentation: You're reading it!</li> <li>GitHub: Issues &amp; Discussions</li> <li>PyPI: Package Repository</li> <li>License: MIT License</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.8+</li> <li>asyncio support</li> <li>Modern Python async libraries (aiohttp, websockets)</li> </ul> <p>Ready to start? Install StreamForge \u2192</p>"},{"location":"TESTING/","title":"Testing Documentation Locally","text":"<p>This guide shows you how to build and test the StreamForge documentation on your local machine.</p>"},{"location":"TESTING/#quick-start","title":"Quick Start","text":""},{"location":"TESTING/#1-install-dependencies","title":"1. Install Dependencies","text":"<p>From the project root:</p> <pre><code>pip install -r docs/requirements.txt\n</code></pre> <p>This installs: - <code>mkdocs</code> - Documentation generator - <code>mkdocs-material</code> - Material theme - <code>mkdocstrings[python]</code> - API documentation generator - <code>pymdown-extensions</code> - Markdown extensions</p>"},{"location":"TESTING/#2-serve-locally","title":"2. Serve Locally","text":"<pre><code>mkdocs serve\n</code></pre> <p>Open your browser to: http://localhost:8000</p> <p>The site will automatically reload when you save changes to any documentation file!</p>"},{"location":"TESTING/#3-build-static-site","title":"3. Build Static Site","text":"<pre><code>mkdocs build\n</code></pre> <p>Output is in the <code>site/</code> directory.</p>"},{"location":"TESTING/#development-workflow","title":"Development Workflow","text":""},{"location":"TESTING/#edit-documentation","title":"Edit Documentation","text":"<ol> <li>Open a documentation file in <code>docs/</code></li> <li>Make your changes</li> <li>Save the file</li> <li>Browser auto-refreshes (if <code>mkdocs serve</code> is running)</li> </ol>"},{"location":"TESTING/#preview-changes","title":"Preview Changes","text":"<p>With <code>mkdocs serve</code> running:</p> <ol> <li>Edit file</li> <li>Save</li> <li>Refresh browser (or wait for auto-reload)</li> <li>See changes instantly</li> </ol>"},{"location":"TESTING/#build-for-production","title":"Build for Production","text":"<pre><code>mkdocs build --clean\n</code></pre> <p>The <code>--clean</code> flag removes the old site directory first.</p>"},{"location":"TESTING/#file-structure","title":"File Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                    # Home page\n\u251c\u2500\u2500 getting-started/            # Installation &amp; quick start\n\u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u251c\u2500\u2500 quick-start.md\n\u2502   \u2514\u2500\u2500 core-concepts.md\n\u251c\u2500\u2500 user-guide/                 # Feature guides\n\u2502   \u251c\u2500\u2500 emitters.md\n\u2502   \u251c\u2500\u2500 transformers.md\n\u2502   \u251c\u2500\u2500 aggregation.md\n\u2502   \u251c\u2500\u2500 backfilling.md\n\u2502   \u2514\u2500\u2500 multi-exchange.md\n\u251c\u2500\u2500 exchanges/                  # Exchange-specific docs\n\u2502   \u251c\u2500\u2500 binance.md\n\u2502   \u251c\u2500\u2500 kraken.md\n\u2502   \u2514\u2500\u2500 okx.md\n\u251c\u2500\u2500 examples/                   # Code examples\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 basic-streaming.md\n\u2502   \u251c\u2500\u2500 data_emitters.md\n\u2502   \u251c\u2500\u2500 data-transformation.md\n\u2502   \u2514\u2500\u2500 advanced-patterns.md\n\u251c\u2500\u2500 api-reference/              # Auto-generated API docs\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 runners.md\n\u2502   \u251c\u2500\u2500 emitters.md\n\u2502   \u251c\u2500\u2500 data-models.md\n\u2502   \u2514\u2500\u2500 backfilling.md\n\u251c\u2500\u2500 contributing.md\n\u251c\u2500\u2500 changelog.md\n\u2514\u2500\u2500 stylesheets/\n    \u2514\u2500\u2500 extra.css\n</code></pre>"},{"location":"TESTING/#common-tasks","title":"Common Tasks","text":""},{"location":"TESTING/#add-a-new-page","title":"Add a New Page","text":"<ol> <li>Create the markdown file in <code>docs/</code></li> <li>Add it to <code>mkdocs.yml</code> navigation:</li> </ol> <pre><code>nav:\n  - Section Name:\n      - Page Title: path/to/page.md\n</code></pre> <ol> <li>Link to it from other pages:</li> </ol> <pre><code>[Link text](path/to/page.md)\n</code></pre>"},{"location":"TESTING/#add-code-examples","title":"Add Code Examples","text":"<p>Use fenced code blocks with language:</p> <pre><code>```python\nimport streamforge as sf\n\nrunner = sf.BinanceRunner(...)\n```\n</code></pre>"},{"location":"TESTING/#add-admonitions","title":"Add Admonitions","text":"<pre><code>!!! note \"Optional Title\"\n    This is a note.\n\n!!! warning\n    This is a warning.\n\n!!! tip\n    This is a tip.\n\n!!! info\n    This is info.\n</code></pre>"},{"location":"TESTING/#add-tabs","title":"Add Tabs","text":"<pre><code>=== \"Option 1\"\n    Content for option 1\n\n=== \"Option 2\"\n    Content for option 2\n</code></pre>"},{"location":"TESTING/#add-tables","title":"Add Tables","text":"<pre><code>| Column 1 | Column 2 | Column 3 |\n|----------|----------|----------|\n| Value 1  | Value 2  | Value 3  |\n</code></pre>"},{"location":"TESTING/#markdown-extensions","title":"Markdown Extensions","text":"<p>The documentation uses these extensions:</p> <ul> <li>Admonitions - <code>!!! note</code>, <code>!!! warning</code>, etc.</li> <li>Code Highlighting - Syntax highlighting for code blocks</li> <li>Superfences - Advanced code blocks</li> <li>Tabbed - Tabbed content sections</li> <li>Tables - GitHub-flavored tables</li> <li>TOC - Table of contents with permalinks</li> <li>Emoji -  icons</li> </ul>"},{"location":"TESTING/#testing-checklist","title":"Testing Checklist","text":"<p>Before submitting changes:</p> <ul> <li> <code>mkdocs serve</code> runs without errors</li> <li> <code>mkdocs build</code> completes successfully</li> <li> All links work (no 404s)</li> <li> Code examples are syntactically correct</li> <li> No spelling/grammar errors</li> <li> Navigation structure makes sense</li> <li> Mobile responsive (check browser dev tools)</li> </ul>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#build-errors","title":"Build Errors","text":"<p>Problem: <code>mkdocs build</code> fails</p> <p>Solutions:</p> <ol> <li>Check YAML syntax in <code>mkdocs.yml</code></li> <li>Verify all nav paths exist</li> <li>Check for invalid markdown syntax</li> </ol>"},{"location":"TESTING/#serve-not-working","title":"Serve Not Working","text":"<p>Problem: <code>mkdocs serve</code> doesn't start</p> <p>Solutions:</p> <ol> <li>Check if port 8000 is already in use</li> <li>Try a different port: <code>mkdocs serve -a localhost:8001</code></li> <li>Reinstall dependencies: <code>pip install -r docs/requirements.txt</code></li> </ol>"},{"location":"TESTING/#broken-links","title":"Broken Links","text":"<p>Problem: Links don't work</p> <p>Solutions:</p> <ol> <li>Use relative paths: <code>../user-guide/emitters.md</code></li> <li>Ensure file exists at that path</li> <li>Check for typos in path</li> </ol>"},{"location":"TESTING/#api-docs-not-generating","title":"API Docs Not Generating","text":"<p>Problem: mkdocstrings not working</p> <p>Solutions:</p> <ol> <li>Verify package is installed: <code>pip install -e .</code></li> <li>Check import paths in API docs</li> <li>Ensure docstrings exist in source code</li> </ol>"},{"location":"TESTING/#deployment","title":"Deployment","text":"<p>Documentation deploys automatically via GitHub Actions:</p> <ul> <li>Trigger: Push to <code>main</code> or <code>master</code> branch</li> <li>Destination: GitHub Pages (gh-pages branch)</li> <li>URL: <code>https://paulobueno90.github.io/streamforge/</code></li> </ul> <p>See <code>.github/workflows/docs.yml</code> for the workflow configuration.</p>"},{"location":"TESTING/#resources","title":"Resources","text":"<ul> <li>MkDocs Documentation</li> <li>Material for MkDocs</li> <li>mkdocstrings</li> <li>PyMdown Extensions</li> </ul>"},{"location":"TESTING/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the error message carefully</li> <li>Verify file paths in <code>mkdocs.yml</code></li> <li>Test in a fresh virtual environment</li> <li>Open an issue on GitHub</li> </ol>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to StreamForge will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#planned","title":"Planned","text":"<ul> <li>Additional exchange integrations</li> <li>Enhanced error handling and retry mechanisms</li> <li>Comprehensive test suite</li> <li>Performance optimizations</li> </ul>"},{"location":"changelog/#010-2025-01-06","title":"0.1.0 - 2025-01-06","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Initial release of StreamForge</li> <li>Real-time WebSocket data ingestion from multiple exchanges:</li> <li>Binance integration with kline/OHLC support</li> <li>Kraken integration with OHLC support</li> <li>OKX integration with candlestick support</li> <li>Multiple data output formats:</li> <li>CSV file output</li> <li>PostgreSQL database integration</li> <li>Kafka streaming support</li> <li>Data processing features:</li> <li>OHLC/Kline data normalization</li> <li>Timeframe aggregation</li> <li>Data buffering and processing</li> <li>Base framework for exchange integrations:</li> <li>Abstract base classes for WebSocket handlers</li> <li>Data processor architecture</li> <li>Emitter pattern for output handling</li> <li>Stream input configuration</li> <li>Cross-platform compatibility (Windows, Linux, macOS)</li> <li>Async/await architecture for high performance</li> <li>Type hints and Pydantic models for data validation</li> </ul>"},{"location":"changelog/#infrastructure","title":"Infrastructure","text":"<ul> <li>Modern Python packaging with pyproject.toml</li> <li>Comprehensive .gitignore</li> <li>MIT License</li> <li>Professional README and documentation</li> <li>Installation guide</li> </ul>"},{"location":"changelog/#links","title":"Links","text":""},{"location":"contributing/","title":"Contributing to StreamForge","text":"<p>Thank you for your interest in contributing to StreamForge! This guide will help you get started.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"contributing/#1-report-bugs","title":"1. Report Bugs","text":"<p>Found a bug? Please create an issue on GitHub:</p> <ul> <li>Use a clear, descriptive title</li> <li>Describe the expected behavior</li> <li>Describe the actual behavior</li> <li>Include steps to reproduce</li> <li>Include your environment (OS, Python version, StreamForge version)</li> </ul> <p>Report a Bug \u2192</p>"},{"location":"contributing/#2-suggest-features","title":"2. Suggest Features","text":"<p>Have an idea for a new feature?</p> <ul> <li>Check if it's already been suggested</li> <li>Clearly describe the feature and its use case</li> <li>Explain why it would be useful to other users</li> </ul> <p>Suggest a Feature \u2192</p>"},{"location":"contributing/#3-improve-documentation","title":"3. Improve Documentation","text":"<p>Documentation improvements are always welcome:</p> <ul> <li>Fix typos or clarify unclear sections</li> <li>Add examples</li> <li>Improve API documentation</li> <li>Translate documentation</li> </ul>"},{"location":"contributing/#4-submit-code","title":"4. Submit Code","text":"<p>Ready to code? Here's how:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Add tests</li> <li>Submit a pull request</li> </ol> <p>Commit Message Format:</p> <ul> <li><code>feat:</code> - New feature</li> <li><code>fix:</code> - Bug fix</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Adding tests</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>style:</code> - Formatting changes</li> <li><code>chore:</code> - Maintenance tasks</li> </ul>"},{"location":"contributing/#code-style","title":"Code Style","text":""},{"location":"contributing/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8</li> <li>Use black for formatting (line length: 100)</li> <li>Use type hints</li> <li>Write docstrings for public APIs</li> </ul>"},{"location":"contributing/#example","title":"Example","text":"<pre><code>from typing import List, Optional\n\ndef process_symbols(\n    symbols: List[str],\n    timeframe: str = \"1m\",\n    limit: Optional[int] = None\n) -&gt; List[dict]:\n    \"\"\"\n    Process cryptocurrency symbols.\n\n    Args:\n        symbols: List of trading pair symbols\n        timeframe: Candle interval (default: \"1m\")\n        limit: Maximum number of results (optional)\n\n    Returns:\n        List of processed data dictionaries\n\n    Example:\n        &gt;&gt;&gt; process_symbols([\"BTCUSDT\"], timeframe=\"5m\")\n        [{'symbol': 'BTCUSDT', ...}]\n    \"\"\"\n    results = []\n    # Implementation...\n    return results\n</code></pre>"},{"location":"contributing/#docstring-format","title":"Docstring Format","text":"<p>Use Google-style docstrings:</p> <pre><code>def function(arg1: str, arg2: int) -&gt; bool:\n    \"\"\"\n    Short description.\n\n    Longer description if needed.\n\n    Args:\n        arg1: Description of arg1\n        arg2: Description of arg2\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: If arg2 is negative\n\n    Example:\n        &gt;&gt;&gt; function(\"test\", 5)\n        True\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":""},{"location":"contributing/#building-docs-locally","title":"Building Docs Locally","text":"<pre><code># Install docs dependencies\npip install -r docs/requirements.txt\n\n# Serve locally\nmkdocs serve\n\n# Build static site\nmkdocs build\n</code></pre> <p>Visit http://localhost:8000</p>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ul> <li> Code follows style guidelines</li> <li> All tests pass</li> <li> Added tests for new features</li> <li> Updated documentation</li> <li> Commit messages are clear</li> </ul>"},{"location":"contributing/#pr-description","title":"PR Description","text":"<p>Include in your PR:</p> <ul> <li>What problem does it solve?</li> <li>How does it solve it?</li> <li>Any breaking changes?</li> <li>Screenshots (if UI changes)</li> </ul>"},{"location":"contributing/#review-process","title":"Review Process","text":"<ol> <li>Submit PR</li> <li>Automated checks run</li> <li>Maintainer reviews code</li> <li>Address feedback</li> <li>PR is merged!</li> </ol>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"contributing/#our-standards","title":"Our Standards","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers</li> <li>Accept constructive criticism</li> <li>Focus on what's best for the community</li> </ul>"},{"location":"contributing/#unacceptable-behavior","title":"Unacceptable Behavior","text":"<ul> <li>Harassment or discriminatory language</li> <li>Personal attacks</li> <li>Publishing private information</li> <li>Other unprofessional conduct</li> </ul>"},{"location":"contributing/#questions","title":"Questions?","text":"<ul> <li>General Questions: GitHub Discussions</li> <li>Bug Reports: GitHub Issues</li> <li>Email: paulohmbueno@gmail.com</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"contributing/#thank-you","title":"Thank You!","text":"<p>Your contributions help make StreamForge better for everyone. Thank you for taking the time to contribute! \ud83c\udf89</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for StreamForge, auto-generated from source code.</p>"},{"location":"api-reference/#overview","title":"Overview","text":"<p>StreamForge's API is organized into several key modules:</p> <ul> <li> <p> Runners</p> <p>Main entry points for streaming data</p> </li> <li> <p> Emitters</p> <p>Output destinations for data</p> </li> <li> <p> Data Models</p> <p>Data structures and schemas</p> </li> <li> <p> Backfilling</p> <p>Historical data loading</p> </li> </ul>"},{"location":"api-reference/#quick-reference","title":"Quick Reference","text":""},{"location":"api-reference/#import-statement","title":"Import Statement","text":"<pre><code>import streamforge as sf\n</code></pre>"},{"location":"api-reference/#main-classes","title":"Main Classes","text":"Class Module Purpose <code>BinanceRunner</code> <code>streamforge</code> Binance streaming <code>KrakenRunner</code> <code>streamforge</code> Kraken streaming <code>OKXRunner</code> <code>streamforge</code> OKX streaming <code>DataInput</code> <code>streamforge</code> Stream configuration <code>CSVEmitter</code> <code>streamforge.base.emitters.csv</code> CSV file output <code>PostgresEmitter</code> <code>streamforge</code> PostgreSQL output <code>KafkaEmitter</code> <code>streamforge</code> Kafka streaming <code>Kline</code> <code>streamforge</code> OHLC data model <code>BinanceBackfilling</code> <code>streamforge</code> Binance backfilling <code>OkxBackfilling</code> <code>streamforge</code> OKX backfilling"},{"location":"api-reference/#type-hints","title":"Type Hints","text":"<p>StreamForge is fully type-hinted for better IDE support:</p> <pre><code>from streamforge import DataInput, BinanceRunner\nfrom streamforge.base.normalize.ohlc.models.candle import Kline\n\ndef process_kline(kline: Kline) -&gt; None:\n    price: float = kline.close\n    symbol: str = kline.symbol\n</code></pre>"},{"location":"api-reference/#explore-the-api","title":"Explore the API","text":"<ul> <li>Runners \u2192 - Exchange-specific runners</li> <li>Emitters \u2192 - Output destinations</li> <li>Data Models \u2192 - Data structures</li> <li>Backfilling \u2192 - Historical data</li> </ul>"},{"location":"api-reference/#source-code","title":"Source Code","text":"<p>Browse the source code on GitHub:</p> <p>View Source \u2192</p>"},{"location":"api-reference/backfilling/","title":"Backfilling API","text":"<p>Auto-generated API documentation for StreamForge backfilling.</p>"},{"location":"api-reference/backfilling/#binancebackfilling","title":"BinanceBackfilling","text":""},{"location":"api-reference/backfilling/#streamforge.ingestion.binance.backfilling.BinanceBackfilling","title":"BinanceBackfilling","text":"<pre><code>BinanceBackfilling(symbol: str, timeframe: str, from_date: str, to_date: str = 'now', file_path: Optional[str] = None, data_type: str = 'klines', market_type: str = 'DEFAULT', transformer: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None)\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.binance.backfilling.BinanceBackfilling.run","title":"run","text":"<pre><code>run()\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.binance.backfilling.BinanceBackfilling.register_emitter","title":"register_emitter","text":"<pre><code>register_emitter(emitter: DataEmitter, model: Optional[Union[Base, BaseModel]] = None, map_object: Optional[Dict] = None)\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.binance.backfilling.BinanceBackfilling.set_transformer","title":"set_transformer","text":"<pre><code>set_transformer(transformer_func: Callable[[Dict[str, Any]], Dict[str, Any]], inplace: bool = False)\n</code></pre>"},{"location":"api-reference/backfilling/#okxbackfilling","title":"OkxBackfilling","text":""},{"location":"api-reference/backfilling/#streamforge.ingestion.okx.backfilling.OkxBackfilling","title":"OkxBackfilling","text":"<pre><code>OkxBackfilling(symbol: str, timeframe: str, from_date: str, to_date: str = 'now', file_path: Optional[str] = None, data_type: str = 'klines', transformer: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None)\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.okx.backfilling.OkxBackfilling.run","title":"run","text":"<pre><code>run()\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.okx.backfilling.OkxBackfilling.register_emitter","title":"register_emitter","text":"<pre><code>register_emitter(emitter: DataEmitter, model: Optional[Union[Base, BaseModel]] = None, map_object: Optional[Dict] = None)\n</code></pre>"},{"location":"api-reference/backfilling/#streamforge.ingestion.okx.backfilling.OkxBackfilling.set_transformer","title":"set_transformer","text":"<pre><code>set_transformer(transformer_func: Callable[[Dict[str, Any]], Dict[str, Any]], inplace: bool = False)\n</code></pre>"},{"location":"api-reference/backfilling/#common-usage","title":"Common Usage","text":""},{"location":"api-reference/backfilling/#basic-backfill","title":"Basic Backfill","text":"<pre><code>from streamforge import BinanceBackfilling\n\nbackfiller = BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.run()  # Sync method\n</code></pre>"},{"location":"api-reference/backfilling/#with-emitter","title":"With Emitter","text":"<pre><code>backfiller = BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.register_emitter(postgres_emitter)\nbackfiller.run()\n</code></pre>"},{"location":"api-reference/backfilling/#with-transformer","title":"With Transformer","text":"<pre><code>def my_transformer(data: dict) -&gt; dict:\n    return {...data, \"custom_field\": value}\n\nbackfiller.set_transformer(my_transformer)\nbackfiller.run()\n</code></pre> <p>Back to API Reference \u2192</p>"},{"location":"api-reference/data-models/","title":"Data Models API","text":"<p>Auto-generated API documentation for StreamForge data models.</p>"},{"location":"api-reference/data-models/#kline","title":"Kline","text":""},{"location":"api-reference/data-models/#streamforge.base.normalize.ohlc.models.candle.Kline","title":"Kline","text":"<p>               Bases: <code>BaseModel</code></p> <p>Normalized candlestick/kline data model.</p> <p>Kline represents OHLC market data in a standardized format across all exchanges. It uses Pydantic for validation and supports multiple field aliases to handle different exchange data formats.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Optional[str]</code> <p>Exchange name (e.g., 'Binance', 'Kraken', 'OKX')</p> <code>symbol</code> <code>str</code> <p>Trading pair symbol (e.g., 'BTCUSDT', 'BTC/USD')</p> <code>timeframe</code> <code>str</code> <p>Candle timeframe (e.g., '1m', '5m', '1h', '1d')</p> <code>open_ts</code> <code>int</code> <p>Opening timestamp in seconds (Unix epoch)</p> <code>end_ts</code> <code>int</code> <p>Closing timestamp in seconds (Unix epoch)</p> <code>open</code> <code>float</code> <p>Opening price</p> <code>high</code> <code>float</code> <p>Highest price during the period</p> <code>low</code> <code>float</code> <p>Lowest price during the period</p> <code>close</code> <code>float</code> <p>Closing price</p> <code>volume</code> <code>float</code> <p>Base asset volume traded</p> <code>quote_volume</code> <code>Optional[float]</code> <p>Quote asset volume traded (optional)</p> <code>vwap</code> <code>Optional[float]</code> <p>Volume-weighted average price (optional)</p> <code>n_trades</code> <code>Optional[int]</code> <p>Number of trades during the period (optional)</p> <code>is_closed</code> <code>Optional[bool]</code> <p>Whether the candle is closed/finalized (optional)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; kline = Kline(\n...     source=\"Binance\",\n...     symbol=\"BTCUSDT\",\n...     timeframe=\"1m\",\n...     open_ts=1609459200,\n...     end_ts=1609459260,\n...     open=29000.0,\n...     high=29100.0,\n...     low=28900.0,\n...     close=29050.0,\n...     volume=125.5,\n...     is_closed=True\n... )\n&gt;&gt;&gt; print(f\"BTC closed at ${kline.close}\")\nBTC closed at $29050.0\n</code></pre> Note <p>The model supports multiple field aliases (e.g., 's', 'symbol', 'ticker', 'pair') to handle different exchange data formats. Fields are automatically validated and converted to the standard format.</p>"},{"location":"api-reference/data-models/#streamforge.base.normalize.ohlc.models.candle.Kline.__eq__","title":"__eq__","text":"<pre><code>__eq__(other: Any) -&gt; bool\n</code></pre> <p>Compares Kline objects based on their open timestamp.</p>"},{"location":"api-reference/data-models/#streamforge.base.normalize.ohlc.models.candle.Kline.__lt__","title":"__lt__","text":"<pre><code>__lt__(other: Any) -&gt; bool\n</code></pre> <p>Compares Kline objects based on their open timestamp.</p>"},{"location":"api-reference/data-models/#streamforge.base.normalize.ohlc.models.candle.Kline.__gt__","title":"__gt__","text":"<pre><code>__gt__(other: Any) -&gt; bool\n</code></pre> <p>Compares Kline objects based on their open timestamp.</p>"},{"location":"api-reference/data-models/#streamforge.base.normalize.ohlc.models.candle.Kline.__sub__","title":"__sub__","text":"<pre><code>__sub__(other: Any) -&gt; int\n</code></pre> <p>Calculates the time difference in seconds between two Klines.</p>"},{"location":"api-reference/data-models/#datainput","title":"DataInput","text":""},{"location":"api-reference/data-models/#streamforge.base.stream_input.DataInput","title":"DataInput  <code>dataclass</code>","text":"<pre><code>DataInput(type: str, symbols: list, timeframe: Optional[str], market_type: Optional[str] = 'DEFAULT', aggregate_list: Optional[List[str]] = list())\n</code></pre> <p>Configuration for a data stream subscription.</p> <p>DataInput specifies what type of market data to stream from an exchange, including the symbols, timeframe, and any aggregation requirements.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of data stream (e.g., 'kline', 'trade', 'depth', 'ticker')</p> <code>symbols</code> <code>list</code> <p>List of trading pair symbols to subscribe to (e.g., ['BTCUSDT', 'ETHUSDT'])</p> <code>timeframe</code> <code>Optional[str]</code> <p>Timeframe interval for OHLC data (e.g., '1m', '5m', '1h', '1d')</p> <code>aggregate_list</code> <code>Optional[List[str]]</code> <p>Optional list of additional timeframes to aggregate to            (e.g., ['5m', '15m', '1h'] when base is '1m')</p> <p>Examples:</p> <p>Basic kline stream:</p> <pre><code>&gt;&gt;&gt; stream = DataInput(\n...     type=\"kline\",\n...     symbols=[\"BTCUSDT\"],\n...     timeframe=\"1m\"\n... )\n</code></pre> <p>With aggregation:</p> <pre><code>&gt;&gt;&gt; stream = DataInput(\n...     type=\"kline\",\n...     symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n...     timeframe=\"1m\",\n...     aggregate_list=[\"5m\", \"15m\", \"1h\"]\n... )\n</code></pre> Note <p>The 'type' field determines which processor will handle the data. Supported types vary by exchange but commonly include: - 'kline', 'candle', 'ohlc': OHLC/candlestick data - 'trade': Individual trades (not implemented yet) - 'depth': Order book depth (not implemented yet) - 'ticker': Price ticker updates (not implemented yet)</p>"},{"location":"api-reference/data-models/#common-usage","title":"Common Usage","text":""},{"location":"api-reference/data-models/#kline-model","title":"Kline Model","text":"<p>The <code>Kline</code> dataclass represents OHLC/candlestick data:</p> <pre><code>from streamforge.base.normalize.ohlc.models.candle import Kline\n\nkline = Kline(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    open_ts=1735689600000,\n    end_ts=1735689659999,\n    open=43250.00,\n    high=43275.00,\n    low=43240.00,\n    close=43260.00,\n    volume=12.45\n)\n\n# Access fields\nprint(kline.close)   # 43260.00\nprint(kline.symbol)  # BTCUSDT\n</code></pre>"},{"location":"api-reference/data-models/#datainput-configuration","title":"DataInput Configuration","text":"<pre><code>from streamforge import DataInput\n\n# Basic\nstream = DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\"\n)\n\n# With aggregation\nstream = DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"1h\"]\n)\n</code></pre> <p>Back to API Reference \u2192</p>"},{"location":"api-reference/emitters/","title":"Emitters API","text":"<p>Auto-generated API documentation for StreamForge emitters.</p> <p>Note: The Logger emitter has been removed. Use <code>sf.config.logger</code> for internal logging, or create a custom emitter to log data items.</p>"},{"location":"api-reference/emitters/#csvemitter","title":"CSVEmitter","text":""},{"location":"api-reference/emitters/#streamforge.base.emitters.csv.csv.CSVEmitter","title":"CSVEmitter","text":"<pre><code>CSVEmitter(name: str = EMITTER, file_path: Optional[str] = None, transformer_function: Callable[[Dict[str, Any]], dict] = None)\n</code></pre> <p>               Bases: <code>DataEmitter</code></p>"},{"location":"api-reference/emitters/#postgresemitter","title":"PostgresEmitter","text":""},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter","title":"PostgresEmitter","text":"<pre><code>PostgresEmitter(name: str = EMITTER, url: Optional[str] = None, host: Optional[str] = None, dbname: Optional[str] = None, user: Optional[str] = None, password: Optional[str] = None, port: int = 5432, upsert: bool = False, index_elements: Optional[list[str]] = None, transformer: Callable[[Dict[str, Any]], dict] = None, from_model_create_table: bool = False)\n</code></pre> <p>               Bases: <code>DataEmitter</code></p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.set_model","title":"set_model","text":"<pre><code>set_model(model: type[Base], inplace=False)\n</code></pre>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.on_conflict","title":"on_conflict","text":"<pre><code>on_conflict(index_elements: list[str], inplace=False)\n</code></pre>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.set_transformer","title":"set_transformer","text":"<pre><code>set_transformer(transformer_function: Callable[[Dict[str, Any]], dict], inplace=False)\n</code></pre>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.connect","title":"connect  <code>async</code>","text":"<pre><code>connect()\n</code></pre> <p>Initializes the SQLAlchemy async engine and sessionmaker.</p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.emit","title":"emit  <code>async</code>","text":"<pre><code>emit(data: BaseModel)\n</code></pre>"},{"location":"api-reference/emitters/#streamforge.base.emitters.postgresql.db.PostgresEmitter.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Disposes the engine, closing the connection pool.</p>"},{"location":"api-reference/emitters/#kafkaemitter","title":"KafkaEmitter","text":""},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter","title":"KafkaEmitter","text":"<pre><code>KafkaEmitter(topic: str, bootstrap_servers: str = 'localhost:9092', key_serializer: Optional[callable] = None, value_serializer: Optional[callable] = None, name: str = EMITTER)\n</code></pre> <p>               Bases: <code>DataEmitter</code></p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter.set_model","title":"set_model","text":"<pre><code>set_model(model: Type[BaseModel])\n</code></pre> <p>Set the canonical Pydantic model for this emitter.</p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter.register_map","title":"register_map","text":"<pre><code>register_map(columns_map: Dict[str, str])\n</code></pre> <p>Optional field mapping for output.</p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter.connect","title":"connect  <code>async</code>","text":"<pre><code>connect()\n</code></pre> <p>Initialize the Kafka producer.</p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter.emit","title":"emit  <code>async</code>","text":"<pre><code>emit(data: BaseModel, key: Optional[str] = None)\n</code></pre> <p>Send a single message to Kafka.</p>"},{"location":"api-reference/emitters/#streamforge.base.emitters.kafka.kafka.KafkaEmitter.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the Kafka producer.</p>"},{"location":"api-reference/emitters/#dataemitter-base-class","title":"DataEmitter (Base Class)","text":""},{"location":"api-reference/emitters/#streamforge.base.emitters.base.DataEmitter","title":"DataEmitter","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for data output emitters.</p> <p>DataEmitter defines the interface for outputting processed market data to various destinations. Implementations include CSV files, PostgreSQL databases, Kafka streams, and logging outputs.</p> <p>Attributes:</p> Name Type Description <code>EMITTER_TYPE</code> <p>Category of emitter (e.g., 'database', 'file writer', 'stream')</p> <code>EMITTER</code> <p>Specific emitter name (e.g., 'postgresql', 'csv', 'kafka')</p> <code>DATA_MODEL</code> <p>Optional data model for structured outputs</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use concrete implementations\n&gt;&gt;&gt; emitter = CSVEmitter(file_path=\"btc_data.csv\")\n&gt;&gt;&gt; await emitter.connect()\n&gt;&gt;&gt; await emitter.emit(kline_data)\n&gt;&gt;&gt; await emitter.close()\n</code></pre> Note <p>Subclasses must implement all abstract methods: register_map, set_model, emit, connect, and close.</p>"},{"location":"api-reference/emitters/#common-usage","title":"Common Usage","text":""},{"location":"api-reference/emitters/#csv","title":"CSV","text":"<pre><code>csv = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"data.csv\"\n)\nrunner.register_emitter(csv)\n</code></pre>"},{"location":"api-reference/emitters/#postgresql","title":"PostgreSQL","text":"<pre><code>postgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))\nrunner.register_emitter(postgres)\n</code></pre>"},{"location":"api-reference/emitters/#kafka","title":"Kafka","text":"<pre><code>kafka = sf.KafkaEmitter(\n    bootstrap_servers=\"localhost:9092\",\n    topic=\"crypto\"\n)\nrunner.register_emitter(kafka)\n</code></pre> <p>Back to API Reference \u2192</p>"},{"location":"api-reference/runners/","title":"Runners API","text":"<p>Auto-generated API documentation for StreamForge runners.</p>"},{"location":"api-reference/runners/#binancerunner","title":"BinanceRunner","text":""},{"location":"api-reference/runners/#streamforge.ingestion.binance.runner.BinanceRunner","title":"BinanceRunner","text":"<pre><code>BinanceRunner(stream_input: DataInput, websocket_client=BinanceWS, processor_class=BinanceProcessor, source='Binance', active_warmup=True, emit_warmup=False, emit_only_closed_candles=True, verbose=False, market_type: Optional[str] = 'SPOT')\n</code></pre> <p>               Bases: <code>Runner</code></p> <p>Runner for Binance exchange data ingestion.</p> <p>BinanceRunner provides a simple interface for streaming real-time market data from Binance, including kline/candlestick data, with support for multiple timeframe aggregation and various output formats.</p> <p>Parameters:</p> Name Type Description Default <code>stream_input</code> <code>DataInput</code> <p>DataInput configuration specifying what to stream</p> required <code>websocket_client</code> <p>WebSocket handler class (default: BinanceWS)</p> <code>BinanceWS</code> <code>processor_class</code> <p>Data processor class (default: BinanceProcessor)</p> <code>BinanceProcessor</code> <code>source</code> <p>Exchange name (default: \"Binance\")</p> <code>'Binance'</code> <code>active_warmup</code> <p>Whether to fetch historical data on startup (default: True)</p> <code>True</code> <code>emit_warmup</code> <p>Whether to emit warmup data to outputs (default: False)</p> <code>False</code> <code>emit_only_closed_candles</code> <p>Only emit completed candles (default: True)</p> <code>True</code> <code>verbose</code> <p>Enable verbose logging (default: False)</p> <code>False</code> <code>market_type</code> <code>Optional[str]</code> <p>Market type (default: \"SPOT\")</p> <code>'SPOT'</code> <p>Examples:     Basic usage:     &gt;&gt;&gt; import asyncio     &gt;&gt;&gt; from streamforge.ingestion.binance.runner import BinanceRunner     &gt;&gt;&gt; from streamforge.base.stream_input import DataInput     &gt;&gt;&gt; from streamforge.base.emitters import CSVEmitter     &gt;&gt;&gt;      &gt;&gt;&gt; async def main():     ...     # Configure stream     ...     stream = DataInput(     ...         type=\"kline\",     ...         symbols=[\"BTCUSDT\"],     ...         timeframe=\"1m\"     ...     )     ...        ...     # Create runner     ...     runner = BinanceRunner(stream_input=stream)     ...        ...     # Add CSV output     ...     runner.register_emitter(CSVEmitter(file_path=\"btc_1m.csv\"))     ...        ...     # Start streaming     ...     await runner.run()     &gt;&gt;&gt;      &gt;&gt;&gt; asyncio.run(main())</p> <pre><code>With aggregation:\n&gt;&gt;&gt; stream = DataInput(\n...     type=\"kline\",\n...     symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n...     timeframe=\"1m\",\n...     aggregate_list=[\"5m\", \"15m\", \"1h\"]\n... )\n&gt;&gt;&gt; runner = BinanceRunner(stream_input=stream, active_warmup=True)\n&gt;&gt;&gt; await runner.run()\n</code></pre> Note <p>Binance WebSocket streams are free and don't require API keys for public market data. Rate limits apply for API calls during warmup.</p>"},{"location":"api-reference/runners/#krakenrunner","title":"KrakenRunner","text":""},{"location":"api-reference/runners/#streamforge.ingestion.kraken.runner.KrakenRunner","title":"KrakenRunner","text":"<pre><code>KrakenRunner(stream_input: DataInput, websocket_client=KrakenWS, processor_class=KrakenProcessor, source='Kraken', active_warmup=True, emit_warmup=False, verbose=False)\n</code></pre> <p>               Bases: <code>Runner</code></p> <p>Runner for Kraken exchange data ingestion.</p> <p>KrakenRunner provides an interface for streaming real-time OHLC data from Kraken exchange, with support for timeframe aggregation and multiple output formats.</p> <p>Parameters:</p> Name Type Description Default <code>stream_input</code> <code>DataInput</code> <p>DataInput configuration specifying what to stream</p> required <code>websocket_client</code> <p>WebSocket handler class (default: KrakenWS)</p> <code>KrakenWS</code> <code>processor_class</code> <p>Data processor class (default: KrakenProcessor)</p> <code>KrakenProcessor</code> <code>source</code> <p>Exchange name (default: \"Kraken\")</p> <code>'Kraken'</code> <code>active_warmup</code> <p>Whether to fetch historical data on startup (default: True)</p> <code>True</code> <code>emit_warmup</code> <p>Whether to emit warmup data to outputs (default: False)</p> <code>False</code> <code>verbose</code> <p>Enable verbose logging (default: False)</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from streamforge.ingestion.kraken.runner import KrakenRunner\n&gt;&gt;&gt; from streamforge.base.stream_input import DataInput\n&gt;&gt;&gt; \n&gt;&gt;&gt; async def main():\n...     stream = DataInput(\n...         type=\"ohlc\",\n...         symbols=[\"BTC/USD\"],\n...         timeframe=\"1\"  # Kraken uses minutes as integers\n...     )\n...     runner = KrakenRunner(stream_input=stream)\n...     await runner.run()\n&gt;&gt;&gt; \n&gt;&gt;&gt; asyncio.run(main())\n</code></pre> Note <p>Kraken uses different symbol formats (BTC/USD vs BTCUSDT) and timeframe representations (integer minutes vs strings like '1m').</p>"},{"location":"api-reference/runners/#okxrunner","title":"OKXRunner","text":""},{"location":"api-reference/runners/#streamforge.ingestion.okx.runner.OKXRunner","title":"OKXRunner","text":"<pre><code>OKXRunner(stream_input: DataInput, websocket_client=OkxWS, processor_class=OkxProcessor, source='OKX', active_warmup=True, emit_warmup=False, verbose=False)\n</code></pre> <p>               Bases: <code>Runner</code></p> <p>Runner for OKX exchange data ingestion.</p> <p>OKXRunner provides an interface for streaming real-time candlestick data from OKX exchange, with support for timeframe aggregation and multiple output formats.</p> <p>Parameters:</p> Name Type Description Default <code>stream_input</code> <code>DataInput</code> <p>DataInput configuration specifying what to stream</p> required <code>websocket_client</code> <p>WebSocket handler class (default: OkxWS)</p> <code>OkxWS</code> <code>processor_class</code> <p>Data processor class (default: OkxProcessor)</p> <code>OkxProcessor</code> <code>source</code> <p>Exchange name (default: \"OKX\")</p> <code>'OKX'</code> <code>active_warmup</code> <p>Whether to fetch historical data on startup (default: True)</p> <code>True</code> <code>emit_warmup</code> <p>Whether to emit warmup data to outputs (default: False)</p> <code>False</code> <code>verbose</code> <p>Enable verbose logging (default: False)</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from streamforge.ingestion.okx.runner import OKXRunner\n&gt;&gt;&gt; from streamforge.base.stream_input import DataInput\n&gt;&gt;&gt; \n&gt;&gt;&gt; async def main():\n...     stream = DataInput(\n...         type=\"candle\",\n...         symbols=[\"BTC-USDT\"],\n...         timeframe=\"1m\"\n...     )\n...     runner = OKXRunner(stream_input=stream)\n...     await runner.run()\n&gt;&gt;&gt; \n&gt;&gt;&gt; asyncio.run(main())\n</code></pre> Note <p>OKX uses hyphenated symbol format (BTC-USDT) and supports various timeframe intervals for candlestick data.</p>"},{"location":"api-reference/runners/#common-usage","title":"Common Usage","text":""},{"location":"api-reference/runners/#creating-a-runner","title":"Creating a Runner","text":"<pre><code>import streamforge as sf\n\nrunner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    ),\n    active_warmup=False,\n    emit_warmup=False\n)\n</code></pre>"},{"location":"api-reference/runners/#registering-emitters","title":"Registering Emitters","text":"<pre><code>runner.register_emitter(csv_emitter)\nrunner.register_emitter(postgres_emitter)\n</code></pre>"},{"location":"api-reference/runners/#running","title":"Running","text":"<pre><code># Continuous streaming\nawait runner.run()\n\n# Manual iteration\nasync for data in runner.stream():\n    print(data)\n</code></pre> <p>Back to API Reference \u2192</p>"},{"location":"examples/","title":"Examples Gallery","text":"<p>Complete, copy-paste examples for common StreamForge use cases.</p>"},{"location":"examples/#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> Basic Streaming</p> <p>Get started with simple streaming examples</p> </li> <li> <p> Database/Streaming Output</p> <p>Save data to PostgreSQL, Kafka and CSV</p> </li> <li> <p> Data Transformation</p> <p>Transform and enrich your data</p> </li> <li> <p> Advanced Patterns</p> <p>Aggregation, backfilling, and multi-exchange</p> </li> </ul>"},{"location":"examples/#by-use-case","title":"By Use Case","text":""},{"location":"examples/#i-want-to","title":"I want to...","text":""},{"location":"examples/#get-started-quickly","title":"...get started quickly","text":"<p>\u2192 Basic Streaming \u2192</p>"},{"location":"examples/#save-data-to-csv","title":"...save data to CSV","text":"<p>\u2192 CSV Example \u2192</p>"},{"location":"examples/#save-data-to-postgresql","title":"...save data to PostgreSQL","text":"<p>\u2192 PostgreSQL Example \u2192</p>"},{"location":"examples/#stream-to-kafka","title":"...stream to Kafka","text":"<p>\u2192 Database Output \u2192</p>"},{"location":"examples/#rename-database-columns","title":"...rename database columns","text":"<p>\u2192 Data Transformation \u2192</p>"},{"location":"examples/#aggregate-1m-to-5m-15m-1h","title":"...aggregate 1m to 5m, 15m, 1h","text":"<p>\u2192 Advanced Patterns \u2192</p>"},{"location":"examples/#load-historical-data","title":"...load historical data","text":"<p>\u2192 Advanced Patterns \u2192</p>"},{"location":"examples/#compare-prices-across-exchanges","title":"...compare prices across exchanges","text":"<p>\u2192 Advanced Patterns \u2192</p>"},{"location":"examples/#by-complexity","title":"By Complexity","text":""},{"location":"examples/#beginner","title":"Beginner \u2b50","text":"<p>Start here if you're new to StreamForge:</p> <ol> <li>Hello World - Simplest possible example</li> <li>CSV Output - Save to file</li> <li>Multiple Symbols - Track multiple assets</li> </ol>"},{"location":"examples/#intermediate","title":"Intermediate \u2b50\u2b50","text":"<p>Once you understand the basics:</p> <ol> <li>PostgreSQL - Database integration</li> <li>Upsert Patterns - Handle duplicates</li> <li>Transformers - Modify data</li> <li>Aggregation - Multiple timeframes</li> </ol>"},{"location":"examples/#advanced","title":"Advanced \u2b50\u2b50\u2b50","text":"<p>For complex use cases:</p> <ol> <li>Backfilling - Historical data</li> <li>Multi-Exchange - Merge exchanges</li> <li>Custom Emitters - Build your own</li> </ol>"},{"location":"examples/#source-code","title":"Source Code","text":"<p>All examples are available in the GitHub repository:</p> <p>View on GitHub \u2192</p>"},{"location":"examples/#example-categories","title":"Example Categories","text":""},{"location":"examples/#basic-streaming","title":"Basic Streaming","text":"<p>Simple examples to get you started:</p> <ul> <li>Hello World</li> <li>CSV Output  </li> <li>Multiple Symbols</li> <li>Different Timeframes</li> <li>Different Exchanges</li> </ul> <p>View Examples \u2192</p>"},{"location":"examples/#database-output","title":"Database Output","text":"<p>Save data to databases and streaming platforms:</p> <ul> <li>PostgreSQL Basic</li> <li>PostgreSQL with Upsert</li> <li>Kafka Streaming</li> <li>Multiple Outputs</li> </ul> <p>View Examples \u2192</p>"},{"location":"examples/#data-transformation","title":"Data Transformation","text":"<p>Modify and enrich your data:</p> <ul> <li>Rename Fields</li> <li>Add Computed Fields</li> <li>Filter Data</li> <li>Custom Transformers</li> </ul> <p>View Examples \u2192</p>"},{"location":"examples/#advanced-patterns","title":"Advanced Patterns","text":"<p>Complex real-world patterns:</p> <ul> <li>Multi-Timeframe Aggregation</li> <li>Historical Backfilling</li> <li>Multi-Exchange Merging</li> <li>Arbitrage Detection</li> <li>Production Patterns</li> </ul> <p>View Examples \u2192</p>"},{"location":"examples/#running-examples","title":"Running Examples","text":""},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<p>Install StreamForge:</p> <pre><code>pip install streamforge\n</code></pre> <p>For database examples, you'll also need:</p> <pre><code># PostgreSQL\npip install streamforge  # Already includes asyncpg\n\n# For examples with additional dependencies\npip install -r examples/requirements.txt\n</code></pre>"},{"location":"examples/#running-an-example","title":"Running an Example","text":"<pre><code># 1. Copy the example code\n# 2. Save to a Python file\npython my_example.py\n\n# Or download from GitHub\ngit clone https://github.com/paulobueno90/streamforge.git\ncd streamforge/examples\npython 01_basic/hello_world.py\n</code></pre>"},{"location":"examples/#example-template","title":"Example Template","text":"<p>Use this template for your own scripts:</p> <pre><code>\"\"\"\nMy StreamForge Script\n=====================\n\nDescription: What this script does\n\nPrerequisites:\n- streamforge installed\n- (any other requirements)\n\nRun:\n    python my_script.py\n\"\"\"\n\nimport asyncio\nimport streamforge as sf\n\nasync def main():\n    \"\"\"Main function\"\"\"\n\n    # 1. Configure stream\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    # 2. Create runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # 3. Add emitter(s)\n    runner.register_emitter(sf.CSVEmitter(...))\n\n    # 4. Run!\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"examples/#test-with-short-periods","title":"Test with Short Periods","text":"<p>Use timeouts for testing:</p> <pre><code>import asyncio\n\nasync def main():\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Run for 30 seconds only\n    try:\n        await asyncio.wait_for(runner.run(), timeout=30)\n    except asyncio.TimeoutError:\n        print(\"Test complete!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/#getting-help","title":"Getting Help","text":"<p>If you need help with examples:</p> <ol> <li>Check the User Guide</li> <li>Read Core Concepts</li> <li>See API Reference</li> <li>Ask on GitHub Discussions</li> <li>Report issues on GitHub Issues</li> </ol>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<p>Ready to dive in?</p> <ol> <li>Basic Streaming \u2192 - Start here</li> <li>Database Output \u2192 - Save your data</li> <li>Data Transformation \u2192 - Customize output</li> <li>Advanced Patterns \u2192 - Complex use cases</li> </ol>"},{"location":"examples/advanced-patterns/","title":"Advanced Patterns","text":"<p>Complex real-world patterns including aggregation, backfilling, and multi-exchange streaming.</p>"},{"location":"examples/advanced-patterns/#multi-timeframe-aggregation","title":"Multi-Timeframe Aggregation","text":"<p>Stream 1-minute data and automatically create 5m, 15m, and 1h candles:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\",                      # Base timeframe\n            aggregate_list=[\"5m\", \"15m\", \"1h\"]  # Auto-aggregate!\n        ),\n        active_warmup=True  # Required for aggregation\n    )\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/advanced-patterns/#backfilling","title":"Backfilling","text":"<p>Load historical data into database:</p> <pre><code>import streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\ndef main():\n    postgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))  # Important!\n\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1h\",\n        from_date=\"2024-01-01\",\n        to_date=\"2024-12-31\"\n    )\n\n    backfiller.register_emitter(postgres)\n    backfiller.run()  # Sync, not async!\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/advanced-patterns/#multi-exchange-merging","title":"Multi-Exchange Merging","text":"<p>Combine streams from multiple exchanges:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def main():\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    # Merge and process\n    async for data in merge_streams(binance, okx):\n        print(f\"{data.source:8} | {data.symbol:10} | ${data.close:,.2f}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/advanced-patterns/#arbitrage-detection","title":"Arbitrage Detection","text":"<p>Detect price differences across exchanges:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def main():\n    latest_prices = {}\n\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    async for data in merge_streams(binance, okx):\n        latest_prices[data.source] = data.close\n\n        if len(latest_prices) &gt;= 2:\n            binance_price = latest_prices.get(\"Binance\", 0)\n            okx_price = latest_prices.get(\"OKX\", 0)\n\n            if binance_price and okx_price:\n                diff = binance_price - okx_price\n                diff_pct = (diff / binance_price) * 100\n\n                print(f\"\\n\ud83d\udcb0 Binance: ${binance_price:,.2f} | OKX: ${okx_price:,.2f} | Diff: {diff_pct:+.4f}%\")\n\n                if abs(diff_pct) &gt; 0.1:\n                    print(\"   \ud83d\udea8 ARBITRAGE OPPORTUNITY!\")\n\nasyncio.run(main())\n</code></pre> <p>See more examples \u2192</p>"},{"location":"examples/basic-streaming/","title":"Basic Streaming","text":"<p>Simple examples to get you started with StreamForge.</p>"},{"location":"examples/basic-streaming/#hello-world","title":"Hello World","text":"<p>The simplest possible example - stream Bitcoin data and print to console:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    # Configure what to stream\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    # Create runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Start streaming!\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Output: <pre><code>2025-10-14 16:21:32 - INFO - Aggregation Deactivated\n2025-10-14 16:21:33 - INFO - Binance    | Subscribed Successful to params: {'method': 'SUBSCRIBE', 'params': ['btcusdt@kline_1m'], 'id': 999} | Websocket Input: DataInput(type='kline', symbols=['BTCUSDT'], timeframe='1m', aggregate_list=[]).\n2025-10-14 16:21:33 - INFO - Binance    | Websocket Connection established successfully!\n2025-10-14 16:22:00 - INFO - Binance    | Data Received: source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n2025-10-14 16:22:00 - INFO - Logger-Binance | Received Data | source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n</code></pre></p>"},{"location":"examples/basic-streaming/#csv-output","title":"CSV Output","text":"<p>Save streaming data to CSV file:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Add CSV emitter\n    csv_emitter = sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"btc_data.csv\"\n    )\n\n    runner.register_emitter(csv_emitter)\n\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/basic-streaming/#multiple-symbols","title":"Multiple Symbols","text":"<p>Stream multiple cryptocurrencies at once:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],  # 3 symbols!\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/basic-streaming/#different-timeframes","title":"Different Timeframes","text":"<p>Change the candle interval:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def timeframe_example(timeframe: str):\n    \"\"\"Stream with custom timeframe\"\"\"\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=timeframe\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    await runner.run()\n\nif __name__ == \"__main__\":\n    # Try different timeframes:\n    # asyncio.run(timeframe_example(\"1m\"))   # 1-minute\n    # asyncio.run(timeframe_example(\"5m\"))   # 5-minute\n    # asyncio.run(timeframe_example(\"1h\"))   # 1-hour\n    asyncio.run(timeframe_example(\"1d\"))   # Daily\n</code></pre>"},{"location":"examples/basic-streaming/#different-exchanges","title":"Different Exchanges","text":"<p>StreamForge works with multiple exchanges:</p> BinanceOKXKraken <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],  # Binance format\n            timeframe=\"1m\"\n        )\n    )\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",          # OKX uses \"candle\"\n            symbols=[\"BTC-USDT\"],   # OKX format with dash\n            timeframe=\"1m\"\n        )\n    )\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",            # Kraken uses \"ohlc\"\n            symbols=[\"BTC/USD\"],    # Kraken format with slash\n            timeframe=\"1m\"\n        )\n    )\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/basic-streaming/#multiple-outputs","title":"Multiple Outputs","text":"<p>Send data to multiple destinations simultaneously:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Add multiple emitters - data goes to ALL\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"backup.csv\"\n    ))\n\n    # Data flows to CSV!\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/basic-streaming/#timed-run","title":"Timed Run","text":"<p>Run for a specific duration:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Run for 60 seconds\n    try:\n        await asyncio.wait_for(runner.run(), timeout=60)\n    except asyncio.TimeoutError:\n        print(\"\\nDone!\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/basic-streaming/#next-steps","title":"Next Steps","text":"<ul> <li>Database Output \u2192 - Save to PostgreSQL and Kafka</li> <li>Data Transformation \u2192 - Modify your data</li> <li>Advanced Patterns \u2192 - Complex use cases</li> </ul>"},{"location":"examples/data-transformation/","title":"Data Transformation","text":"<p>Examples for modifying and enriching streaming data.</p>"},{"location":"examples/data-transformation/#basic-transformer","title":"Basic Transformer","text":""},{"location":"examples/data-transformation/#rename-fields","title":"Rename Fields","text":"<p>Map StreamForge fields to your database schema:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass CustomTable(Base):\n    __tablename__ = 'custom_klines'\n    exchange = Column(String, primary_key=True)\n    ticker = Column(String, primary_key=True)\n    tf = Column(String, primary_key=True)\n    timestamp = Column(BigInteger, primary_key=True)\n    o = Column(Float)\n    h = Column(Float)\n    l = Column(Float)\n    c = Column(Float)\n    v = Column(Float)\n\ndef rename_transformer(data: dict) -&gt; dict:\n    \"\"\"Map to custom schema\"\"\"\n    return {\n        \"exchange\": data[\"source\"],\n        \"ticker\": data[\"symbol\"],\n        \"tf\": data[\"timeframe\"],\n        \"timestamp\": data[\"open_ts\"],\n        \"o\": data[\"open\"],\n        \"h\": data[\"high\"],\n        \"l\": data[\"low\"],\n        \"c\": data[\"close\"],\n        \"v\": data[\"volume\"]\n    }\n\nasync def main():\n    postgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n        .set_model(CustomTable)\n        .set_transformer(rename_transformer)  # Apply transformer\n        .on_conflict([\"exchange\", \"ticker\", \"tf\", \"timestamp\"]))\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/data-transformation/#add-computed-fields","title":"Add Computed Fields","text":"<p>Calculate technical indicators:</p> <pre><code>import asyncio\nimport streamforge as sf\n\ndef add_indicators(data: dict) -&gt; dict:\n    \"\"\"Add technical indicators\"\"\"\n    return {\n        **data,\n        \"price_change\": data[\"close\"] - data[\"open\"],\n        \"price_change_pct\": ((data[\"close\"] - data[\"open\"]) / data[\"open\"]) * 100,\n        \"is_bullish\": data[\"close\"] &gt; data[\"open\"],\n        \"body_size\": abs(data[\"close\"] - data[\"open\"]),\n        \"price_range\": data[\"high\"] - data[\"low\"],\n    }\n\nasync def main():\n    csv = sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"btc_with_indicators.csv\",\n        transformer_function=add_indicators\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(csv)\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/data-transformation/#custom-emitter","title":"Custom Emitter","text":"<p>Build your own custom emitter:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.base.emitters.base import DataEmitter\nfrom streamforge.base.normalize.ohlc.models.candle import Kline\n\nclass CustomEmitter(DataEmitter):\n    \"\"\"Custom emitter example\"\"\"\n\n    def __init__(self, threshold: float = 50000):\n        self.threshold = threshold\n\n    async def emit(self, data: Kline):\n        \"\"\"Handle each data point\"\"\"\n        if data.close &gt; self.threshold:\n            print(f\"\ud83d\udea8 ALERT: {data.symbol} above ${self.threshold:,.0f}! Current: ${data.close:,.2f}\")\n\n    async def connect(self):\n        \"\"\"Setup\"\"\"\n        print(f\"Custom emitter ready. Threshold: ${self.threshold:,.0f}\")\n\n    async def close(self):\n        \"\"\"Cleanup\"\"\"\n        print(\"Custom emitter closed\")\n\nasync def main():\n    custom = CustomEmitter(threshold=43000)\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(custom)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>See more examples \u2192</p>"},{"location":"examples/data_emitters/","title":"Database &amp; Streaming Output","text":"<p>Examples for saving streaming data to databases and other persistent storage.</p>"},{"location":"examples/data_emitters/#basic-postgresql","title":"Basic PostgreSQL","text":"<p>Save streaming data to PostgreSQL database:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    postgres = sf.PostgresEmitter(\n        host=\"localhost\",\n        dbname=\"crypto\",\n        user=\"postgres\",\n        password=\"mysecretpassword\"\n    )\n    postgres.set_model(KlineTable, inplace=True)\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/data_emitters/#upsert-patterns","title":"Upsert Patterns","text":"<p>Handle duplicate data with ON CONFLICT:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    # Method chaining style\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])  # Upsert!\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/data_emitters/#kafka","title":"Kafka","text":""},{"location":"examples/data_emitters/#kafka-streaming","title":"Kafka Streaming","text":"<p>Stream to Apache Kafka:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    kafka = sf.KafkaEmitter(\n        bootstrap_servers=\"localhost:9092\",\n        topic=\"crypto-stream\",\n        compression_type=\"gzip\"\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(kafka)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/data_emitters/#multiple-outputs","title":"Multiple Outputs","text":"<p>Save to PostgreSQL, CSV, and Kafka simultaneously:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    # PostgreSQL\n    postgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))\n\n    # CSV\n    csv = sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"backup.csv\"\n    )\n\n    # Kafka\n    kafka = sf.KafkaEmitter(\n        bootstrap_servers=\"localhost:9092\",\n        topic=\"crypto\"\n    )\n\n    # Stream\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    # Register all 3 emitters - data flows to ALL!\n    runner.register_emitter(postgres)\n    runner.register_emitter(csv)\n    runner.register_emitter(kafka)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>See more examples \u2192</p>"},{"location":"exchanges/binance/","title":"Binance","text":"<p>Complete guide to using StreamForge with Binance, the world's largest cryptocurrency exchange.</p>"},{"location":"exchanges/binance/#quick-start","title":"Quick Start","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/binance/#symbol-format","title":"Symbol Format","text":"<p>Binance uses no separator between base and quote currencies:</p> Asset Pair Binance Symbol Bitcoin/USDT <code>BTCUSDT</code> Ethereum/USDT <code>ETHUSDT</code> Solana/USDT <code>SOLUSDT</code> Bitcoin/BTC <code>ETHBTC</code> BNB/USDT <code>BNBUSDT</code>"},{"location":"exchanges/binance/#common-symbols","title":"Common Symbols","text":"<pre><code>symbols = [\n    \"BTCUSDT\",    # Bitcoin\n    \"ETHUSDT\",    # Ethereum\n    \"BNBUSDT\",    # Binance Coin\n    \"SOLUSDT\",    # Solana\n    \"ADAUSDT\",    # Cardano\n    \"XRPUSDT\",    # Ripple\n    \"DOGEUSDT\",   # Dogecoin\n    \"DOTUSDT\",    # Polkadot\n    \"MATICUSDT\",  # Polygon\n    \"AVAXUSDT\"    # Avalanche\n]\n</code></pre>"},{"location":"exchanges/binance/#supported-timeframes","title":"Supported Timeframes","text":"<p>StreamForge supports these timeframe intervals for Binance:</p> Timeframe Description API Value <code>1m</code> 1 minute \u2713 <code>5m</code> 5 minutes \u2713 <code>15m</code> 15 minutes \u2713 <code>30m</code> 30 minutes \u2713 <code>1h</code> 1 hour \u2713 <code>4h</code> 4 hours \u2713 <code>1d</code> 1 day \u2713"},{"location":"exchanges/binance/#usage","title":"Usage","text":"<pre><code># 5-minute candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"5m\")\n\n# 1-hour candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"1h\")\n\n# Daily candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"1d\")\n</code></pre>"},{"location":"exchanges/binance/#data-types","title":"Data Types","text":""},{"location":"exchanges/binance/#klinecandlestick","title":"Kline/Candlestick","text":"<p>Use <code>type=\"kline\"</code> for OHLC data:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\"\n)\n</code></pre> <p>Data format:</p> <pre><code>{\n    \"source\": \"Binance\",\n    \"symbol\": \"BTCUSDT\",\n    \"timeframe\": \"1m\",\n    \"open_ts\": 1735689600,      \n    \"end_ts\": 1735689659,\n    \"open\": 43250.00,\n    \"high\": 43275.00,\n    \"low\": 43240.00,\n    \"close\": 43260.00,\n    \"volume\": 12.45\n}\n</code></pre>"},{"location":"exchanges/binance/#real-time-streaming","title":"Real-Time Streaming","text":""},{"location":"exchanges/binance/#basic-streaming","title":"Basic Streaming","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def binance_stream():\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(binance_stream())\n</code></pre>"},{"location":"exchanges/binance/#multiple-symbols","title":"Multiple Symbols","text":"<pre><code>runner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],  # Multiple!\n        timeframe=\"1m\"\n    )\n)\n</code></pre>"},{"location":"exchanges/binance/#with-aggregation","title":"With Aggregation","text":"<pre><code>runner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\",\"ETHUSDT\", \"SOLUSDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    ),\n    active_warmup=True  # Required for aggregation\n)\n</code></pre>"},{"location":"exchanges/binance/#historical-backfilling","title":"Historical Backfilling","text":""},{"location":"exchanges/binance/#basic-backfill","title":"Basic Backfill","text":"<pre><code>import streamforge as sf\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.run()  # Saves to CSV by default\n</code></pre>"},{"location":"exchanges/binance/#backfill-to-postgresql","title":"Backfill to PostgreSQL","text":"<pre><code>from sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\npostgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.register_emitter(postgres)\nbackfiller.run()\n</code></pre>"},{"location":"exchanges/binance/#date-ranges","title":"Date Ranges","text":"<pre><code># Specific period\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-01-31\"\n)\n\n# Until present\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"now\"  # Until current time\n)\n</code></pre>"},{"location":"exchanges/binance/#complete-examples","title":"Complete Examples","text":""},{"location":"exchanges/binance/#example-1-stream-to-postgresql","title":"Example 1: Stream to PostgreSQL","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'binance_klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/binance/#example-2-multi-timeframe-csv","title":"Example 2: Multi-Timeframe CSV","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Example 5: Separate Files Per Timeframe\")\nprint(\"=\"*60)\n\n# Create emitters for each timeframe\nemitters = {\n    \"1m\": sf.CSVEmitter(\n        source=\"Binance\", symbol=\"BTCUSDT\", timeframe=\"1m\",\n        file_path=\"btc_1m.csv\"\n    ),\n    \"5m\": sf.CSVEmitter(\n        source=\"Binance\", symbol=\"BTCUSDT\", timeframe=\"5m\",\n        file_path=\"btc_5m.csv\"\n    ),\n    \"15m\": sf.CSVEmitter(\n        source=\"Binance\", symbol=\"BTCUSDT\", timeframe=\"15m\",\n        file_path=\"btc_15m.csv\"\n    ),\n    \"1h\": sf.CSVEmitter(\n        source=\"Binance\", symbol=\"BTCUSDT\", timeframe=\"1h\",\n        file_path=\"btc_1h.csv\"\n    ),\n}\n\n\nrunner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    ),\n    active_warmup=True\n)\n\nprint(\"\u2713 Creating separate files:\")\nprint(\"  - btc_1m.csv\")\nprint(\"  - btc_5m.csv\")\nprint(\"  - btc_15m.csv\")\nprint(\"  - btc_1h.csv\")\n\n# Stream and route to appropriate file\nasync for kline in runner.stream():\n    timeframe = kline.timeframe\n    if timeframe in emitters:\n        await emitters[timeframe].emit(kline.model_dump())\n        print(f\"  Saved {timeframe} candle to btc_{timeframe}.csv\")\n</code></pre>"},{"location":"exchanges/binance/#rate-limits","title":"Rate Limits","text":"<p>Binance has WebSocket and API rate limits:</p>"},{"location":"exchanges/binance/#websocket-limits","title":"WebSocket Limits","text":"<ul> <li>Connection limit: 300 connections per 5 minutes</li> <li>Message rate: No explicit limit, but don't spam</li> <li>Subscriptions: Up to 200 streams per connection</li> </ul> <p>StreamForge handles these automatically.</p>"},{"location":"exchanges/binance/#api-limits-backfilling","title":"API Limits (Backfilling)","text":"<ul> <li>Weight limit: 1200 per minute</li> <li>Order limit: 50 orders per 10 seconds</li> </ul> <p>StreamForge implements automatic rate limiting for backfilling.</p>"},{"location":"exchanges/binance/#best-practices","title":"Best Practices","text":""},{"location":"exchanges/binance/#1-use-appropriate-timeframes","title":"1. Use Appropriate Timeframes","text":"<pre><code># \u2713 Good for day trading\ntimeframe=\"1m\"\n\n# \u2713 Good for swing trading\ntimeframe=\"1h\"\n\n# \u2713 Good for long-term analysis\ntimeframe=\"1d\"\n</code></pre>"},{"location":"exchanges/binance/#2-enable-warmup-for-aggregation","title":"2. Enable Warmup for Aggregation","text":"<pre><code># \u2713 Always use warmup with aggregate_list\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True\n)\n</code></pre>"},{"location":"exchanges/binance/#3-use-upsert-for-backfilling","title":"3. Use Upsert for Backfilling","text":"<pre><code># \u2713 Safe to re-run\npostgres.on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n</code></pre>"},{"location":"exchanges/binance/#4-monitor-multiple-symbols","title":"4. Monitor Multiple Symbols","text":"<pre><code># \u2713 Efficient - one connection\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n\n# \u2717 Inefficient - multiple connections\n# Don't create separate runners for each symbol\n</code></pre>"},{"location":"exchanges/binance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"exchanges/binance/#connection-errors","title":"Connection Errors","text":"<p>Problem: Can't connect to Binance WebSocket.</p> <p>Solutions:</p> <ol> <li>Check internet connection</li> <li>Verify Binance is not experiencing downtime</li> <li>Check firewall settings</li> </ol>"},{"location":"exchanges/binance/#symbol-not-found","title":"Symbol Not Found","text":"<p>Problem: <code>Symbol 'XYZ' not found</code> error.</p> <p>Solutions:</p> <ol> <li>Verify symbol format (no separator): <code>BTCUSDT</code> not <code>BTC-USDT</code></li> <li>Check if symbol exists on Binance</li> <li>Ensure correct spelling</li> </ol>"},{"location":"exchanges/binance/#no-data-streaming","title":"No Data Streaming","text":"<p>Problem: Connected but no data appears.</p> <p>Solutions:</p> <ol> <li>Verify you registered an emitter</li> <li>Check symbol is actively traded</li> <li>Ensure timeframe is valid</li> </ol>"},{"location":"exchanges/binance/#resources","title":"Resources","text":"<ul> <li>Binance Official Documentation: https://binance-docs.github.io/apidocs/</li> <li>Symbol Information: Check Binance Market Page</li> <li>API Status: Binance Status Page</li> </ul>"},{"location":"exchanges/binance/#next-steps","title":"Next Steps","text":"<ul> <li>Kraken Guide \u2192 - Learn about Kraken integration</li> <li>OKX Guide \u2192 - Learn about OKX integration  </li> <li>User Guide \u2192 - Deep dive into emitters</li> <li>Examples \u2192 - See more examples</li> </ul>"},{"location":"exchanges/kraken/","title":"Kraken","text":"<p>Complete guide to using StreamForge with Kraken, a trusted US-based cryptocurrency exchange.</p>"},{"location":"exchanges/kraken/#quick-start","title":"Quick Start","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\", \"ETH/USD\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/kraken/#symbol-format","title":"Symbol Format","text":"<p>Kraken uses forward slash (/) separator between base and quote currencies:</p> Asset Pair Kraken Symbol Bitcoin/USD <code>BTC/USD</code> Ethereum/USD <code>ETH/USD</code> Solana/USD <code>SOL/USD</code> Bitcoin/EUR <code>BTC/EUR</code> Ethereum/BTC <code>ETH/BTC</code>"},{"location":"exchanges/kraken/#common-symbols","title":"Common Symbols","text":"<pre><code>symbols = [\n    \"BTC/USD\",    # Bitcoin/USD\n    \"ETH/USD\",    # Ethereum/USD\n    \"SOL/USD\",    # Solana/USD\n    \"ADA/USD\",    # Cardano/USD\n    \"XRP/USD\",    # Ripple/USD\n    \"DOT/USD\",    # Polkadot/USD\n    \"MATIC/USD\",  # Polygon/USD\n    \"AVAX/USD\",   # Avalanche/USD\n    \"BTC/EUR\",    # Bitcoin/EUR\n    \"ETH/EUR\"     # Ethereum/EUR\n]\n</code></pre> <p>Symbol Variants</p> <p>Kraken sometimes uses variants like <code>XBT/USD</code> for Bitcoin. StreamForge normalizes these automatically.</p>"},{"location":"exchanges/kraken/#supported-timeframes","title":"Supported Timeframes","text":"<p>Kraken supports these timeframe intervals:</p> Timeframe Description API Value <code>1m</code> 1 minute \u2713 <code>5m</code> 5 minutes \u2713 <code>15m</code> 15 minutes \u2713 <code>30m</code> 30 minutes \u2713 <code>1h</code> 1 hour \u2713 <code>4h</code> 4 hours \u2713 <code>1d</code> 1 day \u2713 <code>1w</code> 1 week \u2713 <code>15d</code> 15 days \u2713"},{"location":"exchanges/kraken/#usage","title":"Usage","text":"<pre><code># 1-minute candles\nstream = sf.DataInput(type=\"ohlc\", symbols=[\"BTC/USD\"], timeframe=\"1m\")\n\n# 1-hour candles\nstream = sf.DataInput(type=\"ohlc\", symbols=[\"BTC/USD\"], timeframe=\"1h\")\n\n# Daily candles\nstream = sf.DataInput(type=\"ohlc\", symbols=[\"BTC/USD\"], timeframe=\"1d\")\n</code></pre>"},{"location":"exchanges/kraken/#data-types","title":"Data Types","text":""},{"location":"exchanges/kraken/#ohlc-candlestick","title":"OHLC (Candlestick)","text":"<p>Use <code>type=\"ohlc\"</code> for candlestick data:</p> <pre><code>stream = sf.DataInput(\n    type=\"ohlc\",\n    symbols=[\"BTC/USD\"],\n    timeframe=\"1m\"\n)\n</code></pre> <p>Data format:</p> <pre><code>{\n    \"source\": \"Kraken\",\n    \"symbol\": \"BTC/USD\",\n    \"timeframe\": \"1m\",\n    \"open_ts\": 1735689600000,      # Unix timestamp (ms)\n    \"end_ts\": 1735689659999,       # Unix timestamp (ms)\n    \"open\": 43250.00,\n    \"high\": 43275.00,\n    \"low\": 43240.00,\n    \"close\": 43260.00,\n    \"volume\": 12.45\n}\n</code></pre>"},{"location":"exchanges/kraken/#real-time-streaming","title":"Real-Time Streaming","text":""},{"location":"exchanges/kraken/#basic-streaming","title":"Basic Streaming","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def kraken_stream():\n    runner = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(kraken_stream())\n</code></pre>"},{"location":"exchanges/kraken/#multiple-symbols","title":"Multiple Symbols","text":"<pre><code>runner = sf.KrakenRunner(\n    stream_input=sf.DataInput(\n        type=\"ohlc\",\n        symbols=[\"BTC/USD\", \"ETH/USD\", \"SOL/USD\"],  # Multiple!\n        timeframe=\"1m\"\n    )\n)\n</code></pre>"},{"location":"exchanges/kraken/#with-aggregation","title":"With Aggregation","text":"<pre><code>runner = sf.KrakenRunner(\n    stream_input=sf.DataInput(\n        type=\"ohlc\",\n        symbols=[\"BTC/USD\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    ),\n    active_warmup=True  # Required for aggregation\n)\n</code></pre>"},{"location":"exchanges/kraken/#complete-examples","title":"Complete Examples","text":""},{"location":"exchanges/kraken/#example-1-stream-to-postgresql","title":"Example 1: Stream to PostgreSQL","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'kraken_klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    runner = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\", \"ETH/USD\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/kraken/#example-2-csv-output","title":"Example 2: CSV Output","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def kraken_to_csv():\n    csv_emitter = sf.CSVEmitter(\n        source=\"Kraken\",\n        symbol=\"BTC/USD\",\n        timeframe=\"1h\",\n        file_path=\"kraken_btc_1h.csv\"\n    )\n\n    runner = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\"],\n            timeframe=\"1h\"\n        )\n    )\n\n    runner.register_emitter(csv_emitter)\n\n\n    await runner.run()\n\nasyncio.run(kraken_to_csv())\n</code></pre>"},{"location":"exchanges/kraken/#kraken-specific-notes","title":"Kraken-Specific Notes","text":""},{"location":"exchanges/kraken/#symbol-naming","title":"Symbol Naming","text":"<p>Kraken uses some unique symbol names:</p> Common Name Kraken Symbol Bitcoin <code>BTC/USD</code> or <code>XBT/USD</code> Ethereum <code>ETH/USD</code> USDT <code>USDT/USD</code> <p>StreamForge handles these variations automatically.</p>"},{"location":"exchanges/kraken/#timeframe-differences","title":"Timeframe Differences","text":"<p>Kraken's timeframe options differ from other exchanges:</p> <ul> <li>\u2713 Has: <code>15d</code> (15 days)</li> <li>\u2717 Doesn't have: <code>3m</code>, <code>2h</code>, <code>6h</code>, <code>8h</code>, <code>12h</code>, <code>3d</code></li> </ul>"},{"location":"exchanges/kraken/#update-frequency","title":"Update Frequency","text":"<p>Kraken WebSocket updates:</p> <ul> <li>1m timeframe: Updates approximately every second during active trading</li> <li>Higher timeframes: Less frequent updates</li> </ul>"},{"location":"exchanges/kraken/#rate-limits","title":"Rate Limits","text":""},{"location":"exchanges/kraken/#websocket-limits","title":"WebSocket Limits","text":"<ul> <li>Connections: Reasonable limits (not publicly specified)</li> <li>Subscriptions: Multiple subscriptions per connection</li> <li>Messages: No explicit rate limit</li> </ul> <p>StreamForge manages connections automatically.</p>"},{"location":"exchanges/kraken/#best-practices","title":"Best Practices","text":""},{"location":"exchanges/kraken/#1-use-correct-symbol-format","title":"1. Use Correct Symbol Format","text":"<pre><code># \u2713 Correct - forward slash\nsymbols = [\"BTC/USD\", \"ETH/USD\"]\n\n# \u2717 Wrong - no separator (Binance format)\nsymbols = [\"BTCUSD\", \"ETHUSD\"]\n\n# \u2717 Wrong - dash (OKX format)\nsymbols = [\"BTC-USD\", \"ETH-USD\"]\n</code></pre>"},{"location":"exchanges/kraken/#2-choose-supported-timeframes","title":"2. Choose Supported Timeframes","text":"<pre><code># \u2713 Supported by Kraken\ntimeframe = \"1m\"   # \u2713\ntimeframe = \"5m\"   # \u2713\ntimeframe = \"1h\"   # \u2713\ntimeframe = \"1d\"   # \u2713\n\n# \u2717 NOT supported by Kraken\ntimeframe = \"3m\"   # \u2717\ntimeframe = \"2h\"   # \u2717\n</code></pre>"},{"location":"exchanges/kraken/#3-enable-warmup-for-aggregation","title":"3. Enable Warmup for Aggregation","text":"<pre><code># \u2713 Required for aggregation\nrunner = sf.KrakenRunner(\n    stream_input=stream,\n    active_warmup=True\n)\n</code></pre>"},{"location":"exchanges/kraken/#comparison-with-other-exchanges","title":"Comparison with Other Exchanges","text":"Feature Binance Kraken OKX Symbol Format <code>BTCUSDT</code> <code>BTC/USD</code> <code>BTC-USDT</code> Type Name <code>kline</code> <code>ohlc</code> <code>candle</code> 1m Timeframe \u2713 \u2713 \u2713 3m Timeframe \u2713 \u2717 \u2713 15d Timeframe \u2717 \u2713 \u2717 Backfilling \u2713 \u26a0\ufe0f Limited \u2713"},{"location":"exchanges/kraken/#troubleshooting","title":"Troubleshooting","text":""},{"location":"exchanges/kraken/#symbol-format-errors","title":"Symbol Format Errors","text":"<p>Problem: <code>Invalid symbol format</code> error.</p> <p>Solution: Use forward slash:</p> <pre><code># \u2713 Correct\nsymbols = [\"BTC/USD\"]\n\n# \u2717 Wrong\nsymbols = [\"BTCUSD\"]\n</code></pre>"},{"location":"exchanges/kraken/#timeframe-not-supported","title":"Timeframe Not Supported","text":"<p>Problem: Timeframe not available.</p> <p>Solution: Use supported timeframes:</p> <pre><code># \u2713 Supported\ntimeframe = \"1m\"  # or 5m, 15m, 30m, 1h, 4h, 1d, 1w, 15d\n</code></pre>"},{"location":"exchanges/kraken/#connection-issues","title":"Connection Issues","text":"<p>Problem: Can't connect to Kraken WebSocket.</p> <p>Solutions:</p> <ol> <li>Check Kraken status page</li> <li>Verify firewall allows WebSocket connections</li> <li>Try different symbol</li> </ol>"},{"location":"exchanges/kraken/#resources","title":"Resources","text":"<ul> <li>Kraken API Documentation: https://docs.kraken.com/websockets/</li> <li>Symbol Information: Kraken Markets</li> <li>API Status: Kraken Status</li> </ul>"},{"location":"exchanges/kraken/#next-steps","title":"Next Steps","text":"<ul> <li>Binance Guide \u2192 - Learn about Binance integration</li> <li>OKX Guide \u2192 - Learn about OKX integration</li> <li>Multi-Exchange \u2192 - Merge multiple exchanges</li> <li>Examples \u2192 - See more examples</li> </ul>"},{"location":"exchanges/okx/","title":"OKX","text":"<p>Complete guide to using StreamForge with OKX, a leading global cryptocurrency exchange.</p>"},{"location":"exchanges/okx/#quick-start","title":"Quick Start","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/okx/#symbol-format","title":"Symbol Format","text":"<p>OKX uses dash (-) separator between base and quote currencies:</p> Asset Pair OKX Symbol Bitcoin/USDT <code>BTC-USDT</code> Ethereum/USDT <code>ETH-USDT</code> Solana/USDT <code>SOL-USDT</code> Bitcoin/USDC <code>BTC-USDC</code> Ethereum/BTC <code>ETH-BTC</code>"},{"location":"exchanges/okx/#common-symbols","title":"Common Symbols","text":"<pre><code>symbols = [\n    \"BTC-USDT\",    # Bitcoin/USDT\n    \"ETH-USDT\",    # Ethereum/USDT\n    \"SOL-USDT\",    # Solana/USDT\n    \"ADA-USDT\",    # Cardano/USDT\n    \"XRP-USDT\",    # Ripple/USDT\n    \"DOT-USDT\",    # Polkadot/USDT\n    \"MATIC-USDT\",  # Polygon/USDT\n    \"AVAX-USDT\",   # Avalanche/USDT\n    \"DOGE-USDT\",   # Dogecoin/USDT\n    \"LINK-USDT\"    # Chainlink/USDT\n]\n</code></pre>"},{"location":"exchanges/okx/#supported-timeframes","title":"Supported Timeframes","text":"<p>OKX supports these timeframe intervals:</p> Timeframe Description API Value <code>1m</code> 1 minute \u2713 <code>3m</code> 3 minutes \u2713 <code>5m</code> 5 minutes \u2713 <code>15m</code> 15 minutes \u2713 <code>30m</code> 30 minutes \u2713 <code>1h</code> 1 hour \u2713 <code>2h</code> 2 hours \u2713 <code>4h</code> 4 hours \u2713 <code>6h</code> 6 hours \u2713 <code>12h</code> 12 hours \u2713 <code>1d</code> 1 day \u2713 <code>1w</code> 1 week \u2713 <code>1M</code> 1 month \u2713"},{"location":"exchanges/okx/#usage","title":"Usage","text":"<pre><code># 5-minute candles\nstream = sf.DataInput(type=\"candle\", symbols=[\"BTC-USDT\"], timeframe=\"5m\")\n\n# 1-hour candles\nstream = sf.DataInput(type=\"candle\", symbols=[\"BTC-USDT\"], timeframe=\"1h\")\n\n# Daily candles\nstream = sf.DataInput(type=\"candle\", symbols=[\"BTC-USDT\"], timeframe=\"1d\")\n</code></pre>"},{"location":"exchanges/okx/#data-types","title":"Data Types","text":""},{"location":"exchanges/okx/#candlecandlestick","title":"Candle/Candlestick","text":"<p>Use <code>type=\"candle\"</code> for OHLC data:</p> <pre><code>stream = sf.DataInput(\n    type=\"candle\",\n    symbols=[\"BTC-USDT\"],\n    timeframe=\"1m\"\n)\n</code></pre> <p>Data format:</p> <pre><code>{\n    \"source\": \"OKX\",\n    \"symbol\": \"BTC-USDT\",\n    \"timeframe\": \"1m\",\n    \"open_ts\": 1735689600000,      # Unix timestamp (ms)\n    \"end_ts\": 1735689659999,       # Unix timestamp (ms)\n    \"open\": 43250.00,\n    \"high\": 43275.00,\n    \"low\": 43240.00,\n    \"close\": 43260.00,\n    \"volume\": 12.45\n}\n</code></pre>"},{"location":"exchanges/okx/#real-time-streaming","title":"Real-Time Streaming","text":""},{"location":"exchanges/okx/#basic-streaming","title":"Basic Streaming","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def okx_stream():\n    runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n\n    await runner.run()\n\nasyncio.run(okx_stream())\n</code></pre>"},{"location":"exchanges/okx/#multiple-symbols","title":"Multiple Symbols","text":"<pre><code>runner = sf.OKXRunner(\n    stream_input=sf.DataInput(\n        type=\"candle\",\n        symbols=[\"BTC-USDT\", \"ETH-USDT\", \"SOL-USDT\"],  # Multiple!\n        timeframe=\"1m\"\n    )\n)\n</code></pre>"},{"location":"exchanges/okx/#with-aggregation","title":"With Aggregation","text":"<pre><code>runner = sf.OKXRunner(\n    stream_input=sf.DataInput(\n        type=\"candle\",\n        symbols=[\"BTC-USDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    ),\n    active_warmup=True  # Required for aggregation\n)\n</code></pre>"},{"location":"exchanges/okx/#historical-backfilling","title":"Historical Backfilling","text":""},{"location":"exchanges/okx/#basic-backfill","title":"Basic Backfill","text":"<pre><code>import streamforge as sf\n\nbackfiller = sf.OkxBackfilling(\n    symbol=\"BTC-USDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.run()  # Saves to CSV by default\n</code></pre>"},{"location":"exchanges/okx/#backfill-to-postgresql","title":"Backfill to PostgreSQL","text":"<pre><code>from sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\npostgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"]))\n\nbackfiller = sf.OkxBackfilling(\n    symbol=\"BTC-USDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.register_emitter(postgres)\nbackfiller.run()\n</code></pre>"},{"location":"exchanges/okx/#complete-examples","title":"Complete Examples","text":""},{"location":"exchanges/okx/#example-1-stream-to-postgresql","title":"Example 1: Stream to PostgreSQL","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'okx_klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    runner.register_emitter(postgres)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"exchanges/okx/#example-2-multi-timeframe","title":"Example 2: Multi-Timeframe","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def multi_timeframe():\n    runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\",\n            aggregate_list=[\"5m\", \"15m\", \"1h\", \"4h\"]\n        ),\n        active_warmup=True\n    )\n\n\n\n    await runner.run()\n\nasyncio.run(multi_timeframe())\n</code></pre>"},{"location":"exchanges/okx/#rate-limits","title":"Rate Limits","text":"<p>OKX has WebSocket and API rate limits:</p>"},{"location":"exchanges/okx/#websocket-limits","title":"WebSocket Limits","text":"<ul> <li>Connection limit: Reasonable limits for personal use</li> <li>Subscriptions: Multiple subscriptions per connection</li> <li>Message rate: No explicit public limit</li> </ul> <p>StreamForge handles these automatically.</p>"},{"location":"exchanges/okx/#api-limits-backfilling","title":"API Limits (Backfilling)","text":"<p>OKX implements rate limiting for API calls. StreamForge respects these limits automatically during backfilling.</p>"},{"location":"exchanges/okx/#best-practices","title":"Best Practices","text":""},{"location":"exchanges/okx/#1-use-correct-symbol-format","title":"1. Use Correct Symbol Format","text":"<pre><code># \u2713 Correct - dash separator\nsymbols = [\"BTC-USDT\", \"ETH-USDT\"]\n\n# \u2717 Wrong - no separator (Binance format)\nsymbols = [\"BTCUSDT\", \"ETHUSDT\"]\n\n# \u2717 Wrong - slash (Kraken format)\nsymbols = [\"BTC/USDT\", \"ETH/USDT\"]\n</code></pre>"},{"location":"exchanges/okx/#2-enable-warmup-for-aggregation","title":"2. Enable Warmup for Aggregation","text":"<pre><code># \u2713 Required for aggregation\nrunner = sf.OKXRunner(\n    stream_input=stream,\n    active_warmup=True\n)\n</code></pre>"},{"location":"exchanges/okx/#3-use-upsert-for-backfilling","title":"3. Use Upsert for Backfilling","text":"<pre><code># \u2713 Safe to re-run\npostgres.on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n</code></pre>"},{"location":"exchanges/okx/#comparison-with-other-exchanges","title":"Comparison with Other Exchanges","text":"Feature Binance Kraken OKX Symbol Format <code>BTCUSDT</code> <code>BTC/USD</code> <code>BTC-USDT</code> Type Name <code>kline</code> <code>ohlc</code> <code>candle</code> Timeframes 15 options 9 options 13 options Backfilling \u2713 Full \u26a0\ufe0f Limited \u2713 Full Spot Trading \u2713 \u2713 \u2713 Derivatives \u2713 \u2713 \u2713"},{"location":"exchanges/okx/#troubleshooting","title":"Troubleshooting","text":""},{"location":"exchanges/okx/#symbol-format-errors","title":"Symbol Format Errors","text":"<p>Problem: <code>Invalid symbol format</code> error.</p> <p>Solution: Use dash separator:</p> <pre><code># \u2713 Correct\nsymbols = [\"BTC-USDT\"]\n\n# \u2717 Wrong\nsymbols = [\"BTCUSDT\"]\n</code></pre>"},{"location":"exchanges/okx/#connection-issues","title":"Connection Issues","text":"<p>Problem: Can't connect to OKX WebSocket.</p> <p>Solutions:</p> <ol> <li>Check OKX status page</li> <li>Verify internet connection</li> <li>Check firewall settings</li> </ol>"},{"location":"exchanges/okx/#no-data-streaming","title":"No Data Streaming","text":"<p>Problem: Connected but no data appears.</p> <p>Solutions:</p> <ol> <li>Verify you registered an emitter</li> <li>Check symbol is actively traded</li> <li>Ensure timeframe is valid</li> </ol>"},{"location":"exchanges/okx/#resources","title":"Resources","text":"<ul> <li>OKX API Documentation: https://www.okx.com/docs-v5/</li> <li>Symbol Information: OKX Markets</li> <li>API Status: Check OKX official channels</li> </ul>"},{"location":"exchanges/okx/#next-steps","title":"Next Steps","text":"<ul> <li>Binance Guide \u2192 - Learn about Binance integration</li> <li>Kraken Guide \u2192 - Learn about Kraken integration</li> <li>Multi-Exchange \u2192 - Merge multiple exchanges</li> <li>Examples \u2192 - See more examples</li> </ul>"},{"location":"getting-started/core-concepts/","title":"Core Concepts","text":"<p>Understanding StreamForge's architecture will help you build robust, maintainable data pipelines.</p>"},{"location":"getting-started/core-concepts/#architecture-overview","title":"Architecture Overview","text":"<p>StreamForge follows a simple data flow:</p> <pre><code>graph LR\n    A[Exchange API] --&gt; B[Runner]\n    B --&gt; C[WebSocket Handler]\n    C --&gt; D[Normalizer]\n    D --&gt; E[Processor]\n    E --&gt; F[Aggregator]\n    F --&gt; G[Transformer]\n    G --&gt; H1[Emitter 1]\n    G --&gt; H2[Emitter 2]\n    G --&gt; H3[Emitter N]</code></pre> <p>Let's understand each component:</p>"},{"location":"getting-started/core-concepts/#1-datainput","title":"1. DataInput","text":"<p>DataInput is your configuration object. It tells StreamForge what data to stream.</p> <pre><code>import streamforge as sf\n\nstream = sf.DataInput(\n    type=\"kline\",                           # Data type\n    symbols=[\"BTCUSDT\", \"ETHUSDT\"],        # Trading pairs\n    timeframe=\"1m\",                         # Candle interval\n    aggregate_list=[\"5m\", \"15m\", \"1h\"]     # Optional aggregation\n)\n</code></pre>"},{"location":"getting-started/core-concepts/#attributes","title":"Attributes","text":"Attribute Type Description Example <code>type</code> <code>str</code> Data stream type <code>\"kline\"</code>, <code>\"candle\"</code>, <code>\"ohlc\"</code> <code>symbols</code> <code>list[str]</code> Trading pairs to track <code>[\"BTCUSDT\"]</code> <code>timeframe</code> <code>str</code> Candle interval <code>\"1m\"</code>, <code>\"5m\"</code>, <code>\"1h\"</code> <code>aggregate_list</code> <code>list[str]</code> Higher timeframes (optional) <code>[\"5m\", \"1h\"]</code>"},{"location":"getting-started/core-concepts/#supported-types","title":"Supported Types","text":"<p>Different exchanges use different names:</p> Exchange Type Name Description Binance <code>kline</code> Candlestick/OHLC data OKX <code>candle</code> Candlestick/OHLC data Kraken <code>ohlc</code> Candlestick/OHLC data"},{"location":"getting-started/core-concepts/#symbol-formats","title":"Symbol Formats","text":"<p>Each exchange has its own symbol format:</p> BinanceOKXKraken <pre><code>symbols=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n# Format: BASEQUOTE (no separator)\n</code></pre> <pre><code>symbols=[\"BTC-USDT\", \"ETH-USDT\", \"SOL-USDT\"]\n# Format: BASE-QUOTE (dash separator)\n</code></pre> <pre><code>symbols=[\"BTC/USD\", \"ETH/USD\", \"SOL/USD\"]\n# Format: BASE/QUOTE (slash separator)\n</code></pre>"},{"location":"getting-started/core-concepts/#2-runner","title":"2. Runner","text":"<p>Runner manages the entire data pipeline for a specific exchange.</p> <pre><code>runner = sf.BinanceRunner(stream_input=stream)\n</code></pre>"},{"location":"getting-started/core-concepts/#responsibilities","title":"Responsibilities","text":"<ol> <li>Connection Management - WebSocket lifecycle</li> <li>Data Flow - Coordinates all components</li> <li>Error Handling - Reconnection logic</li> <li>Emitter Registry - Manages output destinations</li> </ol>"},{"location":"getting-started/core-concepts/#available-runners","title":"Available Runners","text":"<pre><code># Binance\nrunner = sf.BinanceRunner(stream_input=stream)\n\n# Kraken\nrunner = sf.KrakenRunner(stream_input=stream)\n\n# OKX\nrunner = sf.OKXRunner(stream_input=stream)\n</code></pre>"},{"location":"getting-started/core-concepts/#configuration-options","title":"Configuration Options","text":"<pre><code>runner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True,      # Load today's data (used in aggregation)\n    emit_warmup=False        # Don't emit warmup data\n)\n</code></pre> Parameter Type Default Description <code>stream_input</code> <code>DataInput</code> Required Stream configuration <code>active_warmup</code> <code>bool</code> <code>False</code> Load historical data for context <code>emit_warmup</code> <code>bool</code> <code>False</code> Emit historical data too <p>Warmup</p> <p>Warmup loads historical data before streaming. Required for aggregation.</p> <ul> <li><code>active_warmup=True</code> - Load history for context</li> <li><code>emit_warmup=True</code> - Also emit historical data</li> </ul>"},{"location":"getting-started/core-concepts/#3-emitters","title":"3. Emitters","text":"<p>Emitters define where data goes. You can register multiple emitters.</p> <pre><code>runner.register_emitter(emitter)\n</code></pre>"},{"location":"getting-started/core-concepts/#built-in-emitters","title":"Built-in Emitters","text":""},{"location":"getting-started/core-concepts/#csv","title":"CSV","text":"<p>Save to CSV file:</p> <pre><code>csv = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"data.csv\"\n)\nrunner.register_emitter(csv)\n</code></pre>"},{"location":"getting-started/core-concepts/#postgresql","title":"PostgreSQL","text":"<p>Save to database:</p> <pre><code>postgres = sf.PostgresEmitter(\n    host=\"localhost\",\n    dbname=\"crypto\",\n    user=\"postgres\",\n    password=\"secret\"\n)\npostgres.set_model(MyTable)\nrunner.register_emitter(postgres)\n</code></pre>"},{"location":"getting-started/core-concepts/#kafka","title":"Kafka","text":"<p>Stream to Kafka:</p> <pre><code>kafka = sf.KafkaEmitter(\n    bootstrap_servers=\"localhost:9092\",\n    topic=\"crypto-stream\"\n)\nrunner.register_emitter(kafka)\n</code></pre>"},{"location":"getting-started/core-concepts/#multiple-emitters","title":"Multiple Emitters","text":"<p>Data flows to all registered emitters:</p> <pre><code># Register 3 emitters\nrunner.register_emitter(csv)\nrunner.register_emitter(postgres)\nrunner.register_emitter(kafka)\n\n# Data goes to all 3!\nawait runner.run()\n</code></pre> <p>Emitters Guide \u2192</p>"},{"location":"getting-started/core-concepts/#4-processors","title":"4. Processors","text":"<p>Processors handle incoming data internally. You typically don't interact with them directly.</p>"},{"location":"getting-started/core-concepts/#what-they-do","title":"What They Do","text":"<ul> <li>Buffer incoming messages</li> <li>Parse WebSocket frames</li> <li>Convert to normalized format</li> <li>Aggregate timeframes</li> <li>Apply transformations</li> </ul>"},{"location":"getting-started/core-concepts/#5-normalizers","title":"5. Normalizers","text":"<p>Normalizers convert exchange-specific formats to a unified <code>Kline</code> model.</p>"},{"location":"getting-started/core-concepts/#purpose","title":"Purpose","text":"<p>Different exchanges send different formats:</p> <pre><code># Binance format\n{\n    \"e\": \"kline\",\n    \"s\": \"BTCUSDT\",\n    \"k\": {\n        \"t\": 1735689600000,\n        \"o\": \"43250.00\",\n        \"h\": \"43275.00\",\n        ...\n    }\n}\n\n# Normalized format (all exchanges)\nKline(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    open_ts=1735689600000,\n    open=43250.00,\n    high=43275.00,\n    ...\n)\n</code></pre>"},{"location":"getting-started/core-concepts/#kline-data-model","title":"Kline Data Model","text":"<pre><code>from typing import List, Any, Optional\nfrom pydantic import BaseModel, Field, AliasChoices, field_validator\n\nclass Kline(BaseModel):\n\n    # Metadata Variables\n    source: Optional[str] = Field(None, alias=\"source\", validation_alias=AliasChoices(\"source\"))\n    symbol: str = Field(alias=\"s\", validation_alias=AliasChoices(\"s\", \"symbol\", \"ticker\", \"pair\"))\n    timeframe: str = Field(alias=\"i\", validation_alias=AliasChoices(\"i\", \"timeframe\", \"tf\"))\n\n    # Time related Variables\n    open_ts: int = Field(alias=\"t\", validation_alias=AliasChoices(\"t\",\"interval_begin\",\"ts\"))\n    end_ts: int = Field(alias=\"T\", validation_alias=AliasChoices(\"T\",\"timestamp\"))\n\n    # Price Variables\n    open: float = Field(alias=\"o\", validation_alias=AliasChoices(\"o\", \"open\", \"open_price\"))\n    high: float = Field(alias=\"h\", validation_alias=AliasChoices(\"h\", \"high\", \"high_price\"))\n    low: float = Field(alias=\"l\", validation_alias=AliasChoices(\"l\", \"low\", \"low_price\"))\n    close: float = Field(alias=\"c\", validation_alias=AliasChoices(\"c\", \"close\", \"close_price\"))\n\n    # Volume Variables\n    volume: float = Field(alias=\"v\", validation_alias=AliasChoices(\"v\", \"volume\", \"base_volume\"))\n    quote_volume: Optional[float] = Field(None, alias=\"q\",validation_alias=AliasChoices(\"q\", \"quote_volume\", \"Quote asset volume\"))\n    vwap: Optional[float] = Field(None, alias=\"vwap\", validation_alias=AliasChoices(\"vwap\", \"volume_weighted_avg_price\"))\n    n_trades: Optional[int] = Field(None, alias=\"n\", validation_alias=AliasChoices(\"n\", \"count\", \"trades\"))\n    is_closed: Optional[bool] = Field(None, alias=\"is_closed\", validation_alias=AliasChoices(\"is_closed\", \"x\"))\n\n    ... # methods\n</code></pre>"},{"location":"getting-started/core-concepts/#6-aggregators","title":"6. Aggregators","text":"<p>Aggregators create higher timeframe candles from base candles.</p>"},{"location":"getting-started/core-concepts/#how-it-works","title":"How It Works","text":"<p>Stream 1-minute candles, get 5m/15m/1h automatically:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",                      # Base timeframe\n    aggregate_list=[\"5m\", \"15m\", \"1h\"]  # Aggregate to these\n)\n\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True  # Required for aggregation!\n)\n</code></pre>"},{"location":"getting-started/core-concepts/#rules","title":"Rules","text":"<ul> <li>Base timeframe must be smaller than aggregate timeframes</li> <li>Aggregation preserves OHLCV integrity</li> <li>Requires warmup for accurate candles in aggregation</li> </ul> <p>Example:</p> <pre><code># \u2713 Valid\ntimeframe=\"1m\", aggregate_list=[\"5m\", \"1h\"]\n\n# \u2717 Invalid\ntimeframe=\"1h\", aggregate_list=[\"5m\"]  # Can't aggregate down\n</code></pre> <p>Aggregation Guide \u2192</p>"},{"location":"getting-started/core-concepts/#7-transformers","title":"7. Transformers","text":"<p>Transformers modify data before it reaches emitters.</p> <pre><code>def my_transformer(data: dict) -&gt; dict:\n    \"\"\"Add computed fields\"\"\"\n    return {\n        **data,\n        \"price_range\": data[\"high\"] - data[\"low\"],\n        \"is_bullish\": data[\"close\"] &gt; data[\"open\"]\n    }\n\nemitter.set_transformer(my_transformer)\n</code></pre>"},{"location":"getting-started/core-concepts/#use-cases","title":"Use Cases","text":"<ul> <li>Rename fields</li> <li>Add computed columns</li> <li>Convert units</li> <li>Filter data</li> </ul> <p>Transformers Guide \u2192</p>"},{"location":"getting-started/core-concepts/#8-backfilling","title":"8. Backfilling","text":"<p>Backfilling loads historical data instead of streaming live data.</p> <pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.register_emitter(postgres_emitter)\nbackfiller.run()  # Sync, not async!\n</code></pre> <p>Backfilling Guide \u2192</p>"},{"location":"getting-started/core-concepts/#data-flow-example","title":"Data Flow Example","text":"<p>Let's trace a complete data flow:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    # 1. Configure what to stream\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    # 2. Create runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # 3. Add emitter\n    runner.register_emitter(some_emitter)\n\n    # 4. Start!\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/core-concepts/#what-happens","title":"What Happens","text":"<ol> <li>Runner connects to Binance WebSocket</li> <li>WebSocket receives raw JSON message</li> <li>Normalizer converts to <code>Kline</code> object</li> <li>Processor buffers and validates</li> <li>Emitter receives <code>Kline</code> and logs it</li> </ol>"},{"location":"getting-started/core-concepts/#execution-modes","title":"Execution Modes","text":"<p>StreamForge has two execution modes:</p>"},{"location":"getting-started/core-concepts/#1-internal-run-mode-async-run","title":"1. Internal Run Mode (async) (.run())","text":"<p>For real-time WebSocket streaming internally:</p> <pre><code>async def main():\n    runner = sf.BinanceRunner(stream_input=stream)\n    runner.register_emitter(emitter)\n    await runner.run()  # Async\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/core-concepts/#2-streaming-mode-async-stream","title":"2. Streaming Mode (async) (.stream())","text":"<p>For real-time WebSocket streaming and handling data manually:</p> <pre><code>runner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n)\n\n# No emitters registered - we'll handle data manually\n\nasync for kline in runner.stream():\n    # Custom logic for each data point\n    price = kline.close\n\n    # Example: Only log when price crosses certain thresholds\n    if price &gt; 50000:\n        print(f\"\ud83d\ude80 BTC above $50k! Current: ${price:,.2f}\")\n    elif price &lt; 30000:\n        print(f\"\ud83d\udcc9 BTC below $30k! Current: ${price:,.2f}\")\n    else:\n        print(f\"\ud83d\udcca BTC: ${price:,.2f}\")\n</code></pre>"},{"location":"getting-started/core-concepts/#3-backfill-mode-sync","title":"3. Backfill Mode (sync)","text":"<p>For historical data loading:</p> <pre><code>def main():\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        from_date=\"2024-01-01\",\n        to_date=\"2024-12-31\"\n    )\n    backfiller.register_emitter(emitter)\n    backfiller.run()  # Sync\n\nmain()\n</code></pre>"},{"location":"getting-started/core-concepts/#automatic-reconnection","title":"Automatic Reconnection","text":"<p>WebSocket disconnects are handled:</p> <pre><code># Runner automatically reconnects on:\n# - Network errors\n# - Exchange disconnects\n# - Timeout errors\n</code></pre>"},{"location":"getting-started/core-concepts/#advanced-stream-iterator","title":"Advanced: Stream Iterator","text":"<p>For advanced use cases, use the stream iterator:</p> <pre><code>async def main():\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Iterate over data manually\n    async for kline in runner.stream():\n        print(f\"Received: {kline.symbol} @ ${kline.close}\")\n\n        # Custom logic here\n        if kline.close &gt; 50000:\n            print(\"BTC above $50k!\")\n</code></pre> <p>This gives you full control over data handling.</p>"},{"location":"getting-started/core-concepts/#performance-tips","title":"Performance Tips","text":""},{"location":"getting-started/core-concepts/#1-use-appropriate-timeframes","title":"1. Use Appropriate Timeframes","text":"<p>Higher timeframes = less data:</p> <pre><code># More data\ntimeframe=\"1m\"  # 1440 candles/day\n\n# Less data  \ntimeframe=\"1h\"  # 24 candles/day\n</code></pre>"},{"location":"getting-started/core-concepts/#2-limit-symbols","title":"2. Limit Symbols","text":"<p>Only stream what you need:</p> <pre><code># Better\nsymbols=[\"BTCUSDT\"]\n\n# More load\nsymbols=[\"BTCUSDT\", \"ETHUSDT\", ..., \"100 symbols\"]\n</code></pre>"},{"location":"getting-started/core-concepts/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>DataInput - Configures what to stream</li> <li>Runner - Manages the pipeline</li> <li>Emitters - Define where data goes</li> <li>Normalizers - Unify exchange formats</li> <li>Aggregators - Create higher timeframes</li> <li>Transformers - Modify data</li> <li>Backfilling - Load historical data</li> </ol>"},{"location":"getting-started/core-concepts/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Emitters</p> <p>Deep dive into output destinations</p> </li> <li> <p> Transformers</p> <p>Learn data transformation</p> </li> <li> <p> Aggregation</p> <p>Multi-timeframe streaming</p> </li> <li> <p> Examples</p> <p>See it all in action</p> </li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>StreamForge can be installed via pip from PyPI. Choose the installation method that fits your needs.</p>"},{"location":"getting-started/installation/#production-installation","title":"Production Installation","text":"<p>For production use, install from PyPI:</p> <pre><code>pip install streamforge\n</code></pre> <p>This installs StreamForge with all required dependencies for basic functionality.</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute or modify StreamForge, install in development mode:</p>"},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/paulobueno90/streamforge.git\ncd streamforge\n</code></pre>"},{"location":"getting-started/installation/#2-install-in-editable-mode","title":"2. Install in Editable Mode","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"getting-started/installation/#3-install-development-dependencies","title":"3. Install Development Dependencies","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This includes testing tools, linters, and formatters.</p>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>StreamForge has optional dependencies for specific features:</p>"},{"location":"getting-started/installation/#postgresql-support","title":"PostgreSQL Support","text":"<p>Already included in the base installation:</p> <pre><code>pip install streamforge  # Includes asyncpg and sqlalchemy\n</code></pre>"},{"location":"getting-started/installation/#kafka-support","title":"Kafka Support","text":"<p>Already included in the base installation:</p> <pre><code>pip install streamforge  # Includes aiokafka\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#python-version","title":"Python Version","text":"<p>StreamForge requires Python 3.8 or higher:</p> <pre><code>python --version  # Should be 3.8+\n</code></pre>"},{"location":"getting-started/installation/#operating-systems","title":"Operating Systems","text":"<p>StreamForge is tested and supported on:</p> <ul> <li> Linux (Ubuntu, Debian, CentOS, etc.)</li> <li> macOS (10.14+)</li> <li> Windows (10, 11, Server 2016+)</li> </ul>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>StreamForge installs the following core dependencies:</p> Package Purpose <code>aiohttp</code> Async HTTP client <code>websockets</code> WebSocket client <code>sqlalchemy</code> SQL ORM <code>pandas</code> Data manipulation <code>pydantic</code> Data validation <code>orjson</code> Fast JSON parsing <code>aiokafka</code> Kafka client <code>asyncpg</code> PostgreSQL driver <code>aiolimiter</code> Rate limiting <code>python-dateutil</code> Date parsing <code>numpy</code> Numerical operations <code>requests</code> HTTP requests <code>ciso8601</code> Fast datetime parsing <p>All dependencies are installed automatically.</p>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify your installation:</p> <pre><code>import streamforge as sf\n\nprint(f\"StreamForge version: {sf.__version__}\")\nprint(f\"Author: {sf.__author__}\")\n</code></pre> <p>Expected output:</p> <pre><code>StreamForge version: 0.1.0\nAuthor: Paulo Bueno\n</code></pre>"},{"location":"getting-started/installation/#test-imports","title":"Test Imports","text":"<p>Verify all major components import correctly:</p> <pre><code>import streamforge as sf\n\n# Runners\nprint(sf.BinanceRunner)\nprint(sf.KrakenRunner)\nprint(sf.OKXRunner)\n\n# Emitters\nprint(sf.CSVEmitter)\nprint(sf.PostgresEmitter)\nprint(sf.KafkaEmitter)\n\n# Configuration\nprint(sf.DataInput)\n\n# Backfilling\nprint(sf.BinanceBackfilling)\nprint(sf.OkxBackfilling)\n</code></pre> <p>If all imports succeed, your installation is complete!</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that StreamForge is installed:</p> <ol> <li>Quick Start \u2192 - Your first stream in 5 minutes</li> <li>Core Concepts \u2192 - Understand the architecture</li> <li>Examples \u2192 - See StreamForge in action</li> </ol>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter installation issues:</p> <ul> <li>Check GitHub Issues</li> <li>Create a new issue with your:</li> <li>Python version</li> <li>Operating system</li> <li>Error message</li> <li>Installation command used</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get streaming in 5 minutes! This guide walks you through your first StreamForge application.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Make sure you have StreamForge installed:</p> <pre><code>pip install streamforge\n</code></pre> <p>Installation Guide \u2192</p>"},{"location":"getting-started/quick-start/#your-first-stream","title":"Your First Stream","text":"<p>Let's create a simple script that streams Bitcoin price data from Binance.</p>"},{"location":"getting-started/quick-start/#step-1-create-a-python-file","title":"Step 1: Create a Python File","text":"<p>Create a new file called <code>my_first_stream.py</code>:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    # Configure what to stream\n    stream = sf.DataInput(\n        type=\"kline\",           # Candlestick/OHLC data\n        symbols=[\"BTCUSDT\"],    # Bitcoin/USDT pair\n        timeframe=\"1m\"          # 1-minute candles\n    )\n\n    # Create Binance runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Start streaming!\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/quick-start/#step-2-run-it","title":"Step 2: Run It","text":"<pre><code>python my_first_stream.py\n</code></pre>"},{"location":"getting-started/quick-start/#step-3-see-the-magic","title":"Step 3: See the Magic!","text":"<p>You'll see live Bitcoin data streaming to your console:</p> <pre><code>2025-10-14 16:21:32 - INFO - Aggregation Deactivated\n2025-10-14 16:21:33 - INFO - Binance    | Subscribed Successful to params: {'method': 'SUBSCRIBE', 'params': ['btcusdt@kline_1m'], 'id': 999} | Websocket Input: DataInput(type='kline', symbols=['BTCUSDT'], timeframe='1m', aggregate_list=[]).\n2025-10-14 16:21:33 - INFO - Binance    | Websocket Connection established successfully!\n2025-10-14 16:22:00 - INFO - Binance    | Data Received: source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n2025-10-14 16:22:00 - INFO - Binance | Received Data | source='binance' symbol='BTCUSDT' timeframe='1m' open_ts=1760469660 end_ts=1760469719 open=113329.98 high=113411.45 low=113329.98 close=113383.03 volume=11.95122 quote_volume=1355147.9103971 vwap=None n_trades=5228 is_closed=True\n...\n</code></pre> <p>Press <code>Ctrl+C</code> to stop.</p> <p>Congratulations!</p> <p>You just streamed live cryptocurrency data! \ud83c\udf89</p>"},{"location":"getting-started/quick-start/#understanding-the-code","title":"Understanding the Code","text":"<p>Let's break down what each part does:</p>"},{"location":"getting-started/quick-start/#1-datainput-configure-what-to-stream","title":"1. DataInput - Configure What to Stream","text":"<pre><code>stream = sf.DataInput(\n    type=\"kline\",           # What type of data\n    symbols=[\"BTCUSDT\"],    # Which trading pairs\n    timeframe=\"1m\"          # Time interval\n)\n</code></pre> <p>DataInput tells StreamForge:</p> <ul> <li>type: What kind of data (<code>kline</code>, <code>trade</code>, <code>depth</code>, etc.)</li> <li>symbols: Which cryptocurrencies to track</li> <li>timeframe: For OHLC data, the candle interval</li> </ul>"},{"location":"getting-started/quick-start/#2-runner-connect-to-exchange","title":"2. Runner - Connect to Exchange","text":"<pre><code>runner = sf.BinanceRunner(stream_input=stream)\n</code></pre> <p>The Runner manages the WebSocket connection and data flow from the exchange.</p> <p>Each exchange has its own runner:</p> <ul> <li><code>BinanceRunner</code> - For Binance</li> <li><code>KrakenRunner</code> - For Kraken</li> <li><code>OKXRunner</code> - For OKX</li> </ul>"},{"location":"getting-started/quick-start/#3-emitter-output-the-data","title":"3. Emitter - Output the Data","text":"<p>Emitters determine where data goes:</p> <ul> <li><code>CSVEmitter</code> - Save to CSV file</li> <li><code>PostgresEmitter</code> - Save to database</li> <li><code>KafkaEmitter</code> - Stream to Kafka</li> </ul> <p>You can register multiple emitters!</p>"},{"location":"getting-started/quick-start/#4-run-start-streaming","title":"4. Run - Start Streaming","text":"<pre><code>await runner.run()\n</code></pre> <p>This starts the WebSocket connection and begins streaming data.</p>"},{"location":"getting-started/quick-start/#save-to-csv","title":"Save to CSV","text":"<p>Let's modify the script to save data to a CSV file:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Add CSV emitter\n    csv_emitter = sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"btc_data.csv\"\n    )\n\n    runner.register_emitter(csv_emitter)\n\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Now data is saved to <code>btc_data.csv</code>!</p>"},{"location":"getting-started/quick-start/#multiple-symbols","title":"Multiple Symbols","text":"<p>Stream multiple cryptocurrencies at once:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],  # 3 symbols!\n    timeframe=\"1m\"\n)\n\nrunner = sf.BinanceRunner(stream_input=stream)\nrunner.register_emitter(kafka_emitter)\n\nawait runner.run()\n</code></pre>"},{"location":"getting-started/quick-start/#multiple-emitters","title":"Multiple Emitters","text":"<p>Send data to multiple destinations:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Register multiple emitters\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"btc_data.csv\"\n    ))\n\n    # Data goes to CSV!\n    await runner.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/quick-start/#different-timeframes","title":"Different Timeframes","text":"<p>Change the candle interval:</p> <pre><code># 5-minute candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"5m\")\n\n# 1-hour candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"1h\")\n\n# Daily candles\nstream = sf.DataInput(type=\"kline\", symbols=[\"BTCUSDT\"], timeframe=\"1d\")\n</code></pre> <p>Supported timeframes: <code>1m</code>, <code>5m</code>, <code>15m</code>, <code>30m</code>, <code>1h</code>, <code>4h</code>, <code>1d</code></p>"},{"location":"getting-started/quick-start/#different-exchanges","title":"Different Exchanges","text":"<p>StreamForge supports multiple exchanges with the same API:</p> BinanceOKXKraken <pre><code>import streamforge as sf\n\nrunner = sf.BinanceRunner(\n    stream_input=sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],  # Binance format\n        timeframe=\"1m\"\n    )\n)\n</code></pre> <pre><code>import streamforge as sf\n\nrunner = sf.OKXRunner(\n    stream_input=sf.DataInput(\n        type=\"candle\",  # OKX calls it \"candle\"\n        symbols=[\"BTC-USDT\"],  # OKX format with dash\n        timeframe=\"1m\"\n    )\n)\n</code></pre> <pre><code>import streamforge as sf\n\nrunner = sf.KrakenRunner(\n    stream_input=sf.DataInput(\n        type=\"ohlc\",  # Kraken calls it \"ohlc\"\n        symbols=[\"BTC/USD\"],  # Kraken format with slash\n        timeframe=\"1m\"\n    )\n)\n</code></pre> <p>Symbol Formats</p> <p>Each exchange uses different symbol formats:</p> <ul> <li>Binance: <code>BTCUSDT</code></li> <li>OKX: <code>BTC-USDT</code></li> <li>Kraken: <code>BTC/USD</code></li> </ul> <p>See Exchange Guides for details.</p>"},{"location":"getting-started/quick-start/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quick-start/#pattern-1-save-everything-to-csv","title":"Pattern 1: Save Everything to CSV","text":"<p>Simple data collection:</p> <pre><code>csv = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"all_data.csv\"\n)\nrunner.register_emitter(csv)\n</code></pre>"},{"location":"getting-started/quick-start/#pattern-2-multiple-emitters","title":"Pattern 2: Multiple Emitters","text":"<p>Send data to multiple destinations:</p> <pre><code>runner.register_emitter(csv_emitter)\nrunner.register_emitter(postgres_emitter)\n</code></pre>"},{"location":"getting-started/quick-start/#stopping-gracefully","title":"Stopping Gracefully","text":"<p>StreamForge runs forever until interrupted. To stop:</p> <ol> <li>Keyboard: Press <code>Ctrl+C</code></li> <li>Programmatically: Use <code>asyncio</code> timeout</li> </ol> <pre><code>import asyncio\n\nasync def main():\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Run for 60 seconds\n    try:\n        await asyncio.wait_for(runner.run(), timeout=60)\n    except asyncio.TimeoutError:\n        print(\"Done!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#connection-errors","title":"Connection Errors","text":"<p>If you can't connect:</p> <ul> <li>Check your internet connection</li> <li>Verify the exchange is not down</li> <li>Try a different symbol</li> </ul>"},{"location":"getting-started/quick-start/#no-data-appearing","title":"No Data Appearing","text":"<p>If nothing prints:</p> <ul> <li>Make sure you registered an emitter</li> <li>Check the symbol format for your exchange</li> <li>Verify the timeframe is valid</li> </ul>"},{"location":"getting-started/quick-start/#import-errors","title":"Import Errors","text":"<p>If imports fail:</p> <pre><code>pip install --upgrade streamforge\n</code></pre>"},{"location":"getting-started/quick-start/#whats-next","title":"What's Next?","text":"<p>Now that you've created your first stream:</p> <ul> <li> <p> Core Concepts</p> <p>Understand how StreamForge works</p> </li> <li> <p> Emitters Guide</p> <p>Save to databases, Kafka, and more</p> </li> <li> <p> Examples</p> <p>See more complete examples</p> </li> <li> <p> Exchange Guides</p> <p>Learn exchange-specific details</p> </li> </ul>"},{"location":"getting-started/quick-start/#complete-example","title":"Complete Example","text":"<p>Here's a complete, production-ready example:</p> <pre><code>\"\"\"\nProduction-ready StreamForge example\nStreams BTC and ETH data to both console and CSV\n\"\"\"\n\nimport asyncio\nimport streamforge as sf\nfrom datetime import datetime\n\nasync def main():\n    print(f\"Starting StreamForge at {datetime.now()}\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Configure stream\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    # Create runner\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Add emitters\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"binance_data.csv\"\n    ))\n\n    # Start streaming\n    try:\n        await runner.run()\n    except KeyboardInterrupt:\n        print(\"\\n\\nStopped by user\")\n    except Exception as e:\n        print(f\"\\n\\nError: {e}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Save and run:</p> <pre><code>python production_stream.py\n</code></pre> <p>Happy streaming! \ud83d\ude80</p>"},{"location":"user-guide/aggregation/","title":"Aggregation","text":"<p>Stream one timeframe and automatically aggregate to higher timeframes. Get 1m, 5m, 15m, and 1h candles from a single 1m stream!</p>"},{"location":"user-guide/aggregation/#what-is-aggregation","title":"What is Aggregation?","text":"<p>Aggregation creates higher timeframe candles from lower timeframe candles:</p> <pre><code>1-minute candles \u2192 Automatically create:\n  - 5-minute candles (5\u00d7 1m)\n  - 15-minute candles (15\u00d7 1m)\n  - 1-hour candles (60\u00d7 1m)\n  - 4-hour candles (240\u00d7 1m)\n</code></pre> <p>Benefits:</p> <ul> <li>Stream once, get multiple timeframes</li> <li>Accurate OHLCV aggregation</li> <li>Reduced API load</li> <li>Consistent timestamps</li> </ul>"},{"location":"user-guide/aggregation/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/aggregation/#enable-aggregation","title":"Enable Aggregation","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\",                      # Base timeframe\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]  # Aggregate to these\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=stream,\n        active_warmup=True  # Required for aggregation!\n    )\n\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>Output: <pre><code>[Multi-TF] BTCUSDT 1m  | Close: $43,260.00\n[Multi-TF] BTCUSDT 5m  | Close: $43,275.00  \u2190 Aggregated from 5\u00d7 1m\n[Multi-TF] BTCUSDT 15m | Close: $43,280.00  \u2190 Aggregated from 15\u00d7 1m\n[Multi-TF] BTCUSDT 1h  | Close: $43,290.00  \u2190 Aggregated from 60\u00d7 1m\n</code></pre></p>"},{"location":"user-guide/aggregation/#how-it-works","title":"How It Works","text":""},{"location":"user-guide/aggregation/#aggregation-rules","title":"Aggregation Rules","text":"<ol> <li>Base timeframe must be smaller than aggregate timeframes</li> <li>Warmup required to initialize aggregators correctly</li> <li>OHLCV preserved - mathematically accurate aggregation</li> </ol>"},{"location":"user-guide/aggregation/#valid-combinations","title":"Valid Combinations","text":"<pre><code># \u2713 Valid - aggregate UP\ntimeframe=\"1m\", aggregate_list=[\"5m\", \"1h\"]\n\n# \u2713 Valid - any higher timeframes\ntimeframe=\"5m\", aggregate_list=[\"15m\", \"1h\", \"4h\"]\n\n# \u2717 Invalid - can't aggregate DOWN\ntimeframe=\"1h\", aggregate_list=[\"5m\"]\n</code></pre>"},{"location":"user-guide/aggregation/#ohlcv-aggregation","title":"OHLCV Aggregation","text":"<p>For aggregated candles:</p> <ul> <li>Open = First candle's open</li> <li>High = Highest high across all candles</li> <li>Low = Lowest low across all candles</li> <li>Close = Last candle's close</li> <li>Volume = Sum of all volumes</li> </ul> <p>Example: <pre><code># Input: 5\u00d7 1-minute candles\n[\n    {open: 100, high: 102, low: 99,  close: 101, volume: 10},\n    {open: 101, high: 103, low: 100, close: 102, volume: 15},\n    {open: 102, high: 104, low: 101, close: 103, volume: 12},\n    {open: 103, high: 105, low: 102, close: 104, volume: 18},\n    {open: 104, high: 106, low: 103, close: 105, volume: 14}\n]\n\n# Output: 1\u00d7 5-minute candle\n{\n    open: 100,        # First open\n    high: 106,        # Highest high\n    low: 99,          # Lowest low\n    close: 105,       # Last close\n    volume: 69        # Sum of volumes\n}\n</code></pre></p>"},{"location":"user-guide/aggregation/#warmup","title":"Warmup","text":"<p>Warmup loads historical data to initialize aggregators correctly.</p>"},{"location":"user-guide/aggregation/#why-warmup","title":"Why Warmup?","text":"<p>Without warmup, the first aggregated candle would be incomplete:</p> <pre><code># Without warmup - First 5m candle has only 2 candles (incomplete!)\nTime 0:00 - Start streaming\nTime 0:03 - First 1m candle arrives\nTime 0:04 - Second 1m candle arrives\nTime 0:05 - Emit 5m candle (only 2 candles! \u274c)\n\n# With warmup - First 5m candle has all 5 candles (complete!)\nBefore streaming - Load last 5 candles\nTime 0:00 - Start streaming\nTime 0:03 - First 1m candle arrives\nTime 0:05 - Emit 5m candle (has 5 complete candles! \u2713)\n</code></pre>"},{"location":"user-guide/aggregation/#enable-warmup","title":"Enable Warmup","text":"<pre><code>runner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True  # Enable warmup\n)\n</code></pre>"},{"location":"user-guide/aggregation/#warmup-options","title":"Warmup Options","text":"Parameter Default Description <code>active_warmup</code> <code>False</code> Load historical data for context <code>emit_warmup</code> <code>False</code> Also emit historical data <pre><code># Load history but don't emit it\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True,   # Load history\n    emit_warmup=False     # Don't emit it\n)\n\n# Load history AND emit it\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True,   # Load history\n    emit_warmup=True      # Emit it too\n)\n</code></pre> <p>When to use <code>emit_warmup=True</code>:</p> <ul> <li>Backfilling while streaming</li> <li>Initializing a new database</li> <li>Want complete historical coverage</li> </ul> <p>When to use <code>emit_warmup=False</code>:</p> <ul> <li>Normal operation</li> <li>Database already has history</li> <li>Only want live data</li> </ul>"},{"location":"user-guide/aggregation/#supported-timeframes","title":"Supported Timeframes","text":""},{"location":"user-guide/aggregation/#base-timeframes","title":"Base Timeframes","text":"<p>Stream from any of these:</p> <ul> <li><code>1m</code>, <code>3m</code>, <code>5m</code>, <code>15m</code>, <code>30m</code></li> <li><code>1h</code>, <code>2h</code>, <code>4h</code>, <code>6h</code>, <code>8h</code>, <code>12h</code></li> <li><code>1d</code>, <code>3d</code></li> <li><code>1w</code>, <code>1M</code></li> </ul>"},{"location":"user-guide/aggregation/#common-aggregation-patterns","title":"Common Aggregation Patterns","text":""},{"location":"user-guide/aggregation/#pattern-1-minute-based","title":"Pattern 1: Minute-Based","text":"<pre><code>timeframe=\"1m\",\naggregate_list=[\"5m\", \"15m\", \"30m\", \"1h\"]\n</code></pre>"},{"location":"user-guide/aggregation/#pattern-2-hour-based","title":"Pattern 2: Hour-Based","text":"<pre><code>timeframe=\"1h\",\naggregate_list=[\"2h\", \"4h\", \"6h\", \"12h\", \"1d\"]\n</code></pre>"},{"location":"user-guide/aggregation/#pattern-3-day-based","title":"Pattern 3: Day-Based","text":"<pre><code>timeframe=\"1d\",\naggregate_list=[\"3d\", \"1w\", \"1M\"]\n</code></pre>"},{"location":"user-guide/aggregation/#pattern-4-all-timeframes","title":"Pattern 4: All Timeframes","text":"<pre><code>timeframe=\"1m\",\naggregate_list=[\"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"12h\", \"1d\"]\n</code></pre>"},{"location":"user-guide/aggregation/#complete-examples","title":"Complete Examples","text":""},{"location":"user-guide/aggregation/#example-1-multi-timeframe-to-csv","title":"Example 1: Multi-Timeframe to CSV","text":"<p>Save each timeframe to separate CSV:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=stream,\n        active_warmup=True\n    )\n\n    # Separate CSV for each timeframe\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"btc_1m.csv\"\n    ))\n\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"5m\",\n        file_path=\"btc_5m.csv\"\n    ))\n\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"15m\",\n        file_path=\"btc_15m.csv\"\n    ))\n\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1h\",\n        file_path=\"btc_1h.csv\"\n    ))\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>Result: 4 CSV files, each with its timeframe!</p>"},{"location":"user-guide/aggregation/#example-2-multi-timeframe-to-postgresql","title":"Example 2: Multi-Timeframe to PostgreSQL","text":"<p>Save all timeframes to one database table:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    \"\"\"All timeframes in one table\"\"\"\n    __tablename__ = 'klines'\n\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)  # Differentiates timeframes\n    open_ts = Column(BigInteger, primary_key=True)\n\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\", \"4h\"]\n    )\n\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=stream,\n        active_warmup=True\n    )\n\n    runner.register_emitter(postgres)\n\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>Query different timeframes:</p> <pre><code>-- 1-minute candles\nSELECT * FROM klines WHERE timeframe = '1m';\n\n-- 1-hour candles\nSELECT * FROM klines WHERE timeframe = '1h';\n\n-- All timeframes for BTC\nSELECT * FROM klines WHERE symbol = 'BTCUSDT' ORDER BY timeframe, open_ts;\n</code></pre>"},{"location":"user-guide/aggregation/#example-3-trading-strategy","title":"Example 3: Trading Strategy","text":"<p>Use multiple timeframes for analysis:</p> <pre><code>import asyncio\nimport streamforge as sf\n\n# Track latest prices per timeframe\nlatest_prices = {\n    \"1m\": None,\n    \"5m\": None,\n    \"15m\": None,\n    \"1h\": None\n}\n\nclass StrategyEmitter(sf.DataEmitter):\n    \"\"\"Custom emitter for trading logic\"\"\"\n\n    async def emit(self, data):\n        # Update latest price\n        latest_prices[data.timeframe] = data.close\n\n        # Check if all timeframes are bullish\n        if all(latest_prices.values()):\n            print(f\"\\nMulti-Timeframe Analysis:\")\n            print(f\"  1m:  ${latest_prices['1m']:,.2f}\")\n            print(f\"  5m:  ${latest_prices['5m']:,.2f}\")\n            print(f\"  15m: ${latest_prices['15m']:,.2f}\")\n            print(f\"  1h:  ${latest_prices['1h']:,.2f}\")\n\n            # Check trend\n            if (latest_prices[\"1m\"] &gt; latest_prices[\"5m\"] &gt; \n                latest_prices[\"15m\"] &gt; latest_prices[\"1h\"]):\n                print(\"  \u2b06\ufe0f  UPTREND across all timeframes!\")\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\",\n        aggregate_list=[\"5m\", \"15m\", \"1h\"]\n    )\n\n    runner = sf.BinanceRunner(\n        stream_input=stream,\n        active_warmup=True\n    )\n\n    runner.register_emitter(StrategyEmitter())\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/aggregation/#performance-considerations","title":"Performance Considerations","text":""},{"location":"user-guide/aggregation/#memory-usage","title":"Memory Usage","text":"<p>Each aggregate timeframe maintains a buffer:</p> <pre><code># Moderate memory\naggregate_list=[\"5m\", \"15m\"]\n\n# Higher memory (more buffers)\naggregate_list=[\"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"12h\", \"1d\"]\n</code></pre>"},{"location":"user-guide/aggregation/#computation","title":"Computation","text":"<p>Aggregation is lightweight:</p> <ul> <li>Simple OHLCV operations</li> <li>No heavy computation</li> <li>Minimal CPU impact</li> </ul>"},{"location":"user-guide/aggregation/#network-load","title":"Network Load","text":"<p>Aggregation reduces API calls:</p> <pre><code># Without aggregation - 4 WebSocket connections\nrunner_1m = BinanceRunner(timeframe=\"1m\")\nrunner_5m = BinanceRunner(timeframe=\"5m\")\nrunner_15m = BinanceRunner(timeframe=\"15m\")\nrunner_1h = BinanceRunner(timeframe=\"1h\")\n\n# With aggregation - 1 WebSocket connection\nrunner = BinanceRunner(\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"1h\"]  # \u2713 Better!\n)\n</code></pre>"},{"location":"user-guide/aggregation/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/aggregation/#pattern-1-full-spectrum","title":"Pattern 1: Full Spectrum","text":"<p>All major timeframes:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"30m\", \"1h\", \"4h\", \"1d\"]\n)\n</code></pre>"},{"location":"user-guide/aggregation/#pattern-2-traders-set","title":"Pattern 2: Trader's Set","text":"<p>Common trading timeframes:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"1h\", \"4h\"]\n)\n</code></pre>"},{"location":"user-guide/aggregation/#pattern-3-day-trader","title":"Pattern 3: Day Trader","text":"<p>Intraday timeframes only:</p> <pre><code>stream = sf.DataInput(\n    type=\"kline\",\n    symbols=[\"BTCUSDT\"],\n    timeframe=\"1m\",\n    aggregate_list=[\"5m\", \"15m\", \"30m\", \"1h\"]\n)\n</code></pre>"},{"location":"user-guide/aggregation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/aggregation/#aggregation-not-working","title":"Aggregation Not Working","text":"<p>Problem: No aggregated candles emitted.</p> <p>Solution:</p> <pre><code># \u2713 Make sure warmup is enabled\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True  # Required!\n)\n</code></pre>"},{"location":"user-guide/aggregation/#incomplete-candles","title":"Incomplete Candles","text":"<p>Problem: First aggregated candles seem wrong.</p> <p>Solution: Warmup loads historical data. The first candles after startup are correct.</p>"},{"location":"user-guide/aggregation/#wrong-timestamps","title":"Wrong Timestamps","text":"<p>Problem: Aggregated timestamps don't align.</p> <p>Solution: StreamForge automatically aligns timestamps to timeframe boundaries. This is expected behavior.</p>"},{"location":"user-guide/aggregation/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/aggregation/#1-always-use-warmup","title":"1. Always Use Warmup","text":"<pre><code># \u2713 Always enable for aggregation\nrunner = sf.BinanceRunner(\n    stream_input=stream,\n    active_warmup=True\n)\n</code></pre>"},{"location":"user-guide/aggregation/#2-choose-appropriate-base-timeframe","title":"2. Choose Appropriate Base Timeframe","text":"<pre><code># \u2713 Good - 1m base for intraday\ntimeframe=\"1m\", aggregate_list=[\"5m\", \"15m\", \"1h\"]\n\n# \u2713 Good - 1h base for swing trading\ntimeframe=\"1h\", aggregate_list=[\"4h\", \"1d\"]\n\n# \u26a0\ufe0f Wasteful - 1m base for daily only\ntimeframe=\"1m\", aggregate_list=[\"1d\"]  # Better to stream \"1d\" directly\n</code></pre>"},{"location":"user-guide/aggregation/#3-dont-over-aggregate","title":"3. Don't Over-Aggregate","text":"<pre><code># \u26a0\ufe0f Too many timeframes\naggregate_list=[\"3m\", \"5m\", \"7m\", \"10m\", \"12m\", \"15m\", ...]  # Overkill\n\n# \u2713 Reasonable\naggregate_list=[\"5m\", \"15m\", \"1h\", \"4h\"]\n</code></pre>"},{"location":"user-guide/aggregation/#next-steps","title":"Next Steps","text":"<ul> <li>Backfilling \u2192 - Load historical data</li> <li>Multi-Exchange \u2192 - Merge multiple exchanges</li> <li>Examples \u2192 - See aggregation in action</li> </ul>"},{"location":"user-guide/backfilling/","title":"Backfilling","text":"<p>Load historical data from exchanges to populate databases or create datasets. Backfilling is essential for initializing databases, analysis, and backtesting.</p>"},{"location":"user-guide/backfilling/#what-is-backfilling","title":"What is Backfilling?","text":"<p>Backfilling downloads historical OHLC/Kline data from exchange APIs:</p> <pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.run()  # Downloads year of data\n</code></pre> <p>Key Differences from Streaming:</p> Feature Streaming Backfilling Data Source WebSocket REST API Execution <code>async</code> Sync Speed Real-time Batch download Purpose Live data Historical data Method <code>runner.run()</code> <code>backfiller.run()</code>"},{"location":"user-guide/backfilling/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/backfilling/#binance-backfilling","title":"Binance Backfilling","text":"<pre><code>import streamforge as sf\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-10-01\",\n    to_date=\"2024-10-31\"\n)\n\n# Defaults to CSV if no emitter registered\nbackfiller.run()\n</code></pre> <p>Output: <code>Binance-BTCUSDT-1m-2024-10-01_2024-10-31.csv</code></p>"},{"location":"user-guide/backfilling/#okx-backfilling","title":"OKX Backfilling","text":"<pre><code>backfiller = sf.OkxBackfilling(\n    symbol=\"BTC-USDT\",      # OKX format\n    timeframe=\"1m\",\n    from_date=\"2024-10-01\",\n    to_date=\"2024-10-31\"\n)\n\nbackfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#parameters","title":"Parameters","text":"Parameter Type Description Example <code>symbol</code> <code>str</code> Trading pair <code>\"BTCUSDT\"</code> <code>timeframe</code> <code>str</code> Candle interval <code>\"1m\"</code>, <code>\"1h\"</code>, <code>\"1d\"</code> <code>from_date</code> <code>str</code> Start date <code>\"2024-01-01\"</code> <code>to_date</code> <code>str</code> End date <code>\"2024-12-31\"</code> or <code>\"now\"</code>"},{"location":"user-guide/backfilling/#date-formats","title":"Date Formats","text":"<p>Flexible date formats:</p> <pre><code># YYYY-MM-DD\nfrom_date=\"2024-01-01\"\n\n# YYYY-MM-DD HH:MM:SS\nfrom_date=\"2024-01-01 12:00:00\"\n\n# Special: \"now\"\nto_date=\"now\"  # Until present\n</code></pre>"},{"location":"user-guide/backfilling/#output-destinations","title":"Output Destinations","text":""},{"location":"user-guide/backfilling/#default-csv","title":"Default: CSV","text":"<p>If no emitter is registered, defaults to CSV:</p> <pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.run()\n# Creates: Binance-BTCUSDT-1h-2024-01-01_2024-12-31.csv\n</code></pre>"},{"location":"user-guide/backfilling/#postgresql","title":"PostgreSQL","text":"<p>Load directly into database:</p> <pre><code>import streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\n# Create emitter with upsert\npostgres = (sf.PostgresEmitter(\n        host=\"localhost\",\n        dbname=\"crypto\",\n        user=\"postgres\",\n        password=\"secret\"\n    )\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])  # Important!\n)\n\n# Backfill\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.register_emitter(postgres)\nbackfiller.run()\n</code></pre> <p>Always Use Upsert</p> <p>Always enable <code>on_conflict()</code> when backfilling to PostgreSQL. This allows safe re-running without duplicates.</p>"},{"location":"user-guide/backfilling/#custom-path-for-csv","title":"Custom Path for CSV","text":"<pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\",\n    file_path=\"my_custom_name.csv\"  # Custom filename\n)\n\nbackfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#complete-examples","title":"Complete Examples","text":""},{"location":"user-guide/backfilling/#example-1-simple-csv-backfill","title":"Example 1: Simple CSV Backfill","text":"<pre><code>import streamforge as sf\n\ndef backfill_to_csv():\n    \"\"\"Backfill BTC data to CSV\"\"\"\n\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1h\",\n        from_date=\"2024-01-01\",\n        to_date=\"2024-12-31\"\n    )\n\n    print(\"Starting backfill...\")\n    backfiller.run()\n    print(\"\u2713 Backfill complete!\")\n\nif __name__ == \"__main__\":\n    backfill_to_csv()\n</code></pre>"},{"location":"user-guide/backfilling/#example-2-postgresql-backfill","title":"Example 2: PostgreSQL Backfill","text":"<pre><code>import streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\ndef backfill_to_postgres():\n    \"\"\"Backfill to PostgreSQL database\"\"\"\n\n    # Create emitter\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"mysecretpassword\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    # Backfill\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        from_date=\"2024-10-01\",\n        to_date=\"2024-10-31\"\n    )\n\n    backfiller.register_emitter(postgres)\n\n    print(\"Backfilling to PostgreSQL...\")\n    backfiller.run()\n    print(\"\u2713 Done!\")\n\nif __name__ == \"__main__\":\n    backfill_to_postgres()\n</code></pre>"},{"location":"user-guide/backfilling/#example-3-multiple-symbols","title":"Example 3: Multiple Symbols","text":"<p>Backfill multiple cryptocurrencies:</p> <pre><code>import streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\ndef backfill_multiple_symbols():\n    \"\"\"Backfill multiple symbols to database\"\"\"\n\n    symbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"ADAUSDT\"]\n\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    for symbol in symbols:\n        print(f\"\\n\ud83d\udcca Backfilling {symbol}...\")\n\n        backfiller = sf.BinanceBackfilling(\n            symbol=symbol,\n            timeframe=\"1h\",\n            from_date=\"2024-01-01\",\n            to_date=\"2024-12-31\"\n        )\n\n        backfiller.register_emitter(postgres)\n        backfiller.run()\n\n        print(f\"\u2713 {symbol} complete!\")\n\n    print(\"\\n\u2713 All symbols backfilled!\")\n\nif __name__ == \"__main__\":\n    backfill_multiple_symbols()\n</code></pre>"},{"location":"user-guide/backfilling/#example-4-with-transformer","title":"Example 4: With Transformer","text":"<p>Transform data during backfilling:</p> <pre><code>import streamforge as sf\n\ndef price_transformer(data: dict) -&gt; dict:\n    \"\"\"Add computed fields\"\"\"\n    return {\n        **data,\n        \"price_change_pct\": ((data[\"close\"] - data[\"open\"]) / data[\"open\"]) * 100,\n        \"is_bullish\": data[\"close\"] &gt; data[\"open\"],\n        \"price_range\": data[\"high\"] - data[\"low\"]\n    }\n\ndef backfill_with_transformation():\n    \"\"\"Backfill with data transformation\"\"\"\n\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1h\",\n        from_date=\"2024-01-01\",\n        to_date=\"2024-12-31\",\n        file_path=\"btc_with_indicators.csv\"\n    )\n\n    backfiller.set_transformer(price_transformer)\n\n    print(\"Backfilling with transformation...\")\n    backfiller.run()\n    print(\"\u2713 Done!\")\n\nif __name__ == \"__main__\":\n    backfill_with_transformation()\n</code></pre>"},{"location":"user-guide/backfilling/#backfill-to-present","title":"Backfill to Present","text":"<p>Use <code>\"now\"</code> to backfill until the current time:</p> <pre><code>backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"now\"  # Until now\n)\n\nbackfiller.run()\n</code></pre> <p>This is useful for:</p> <ul> <li>Initial database population</li> <li>Catching up after downtime</li> <li>Continuous backfilling</li> </ul>"},{"location":"user-guide/backfilling/#time-periods","title":"Time Periods","text":""},{"location":"user-guide/backfilling/#short-period-days","title":"Short Period (Days)","text":"<pre><code># 7 days\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-10-01\",\n    to_date=\"2024-10-07\"\n)\n</code></pre>"},{"location":"user-guide/backfilling/#medium-period-months","title":"Medium Period (Months)","text":"<pre><code># 3 months\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-07-01\",\n    to_date=\"2024-09-30\"\n)\n</code></pre>"},{"location":"user-guide/backfilling/#long-period-years","title":"Long Period (Years)","text":"<pre><code># 2 years\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1d\",\n    from_date=\"2023-01-01\",\n    to_date=\"2024-12-31\"\n)\n</code></pre> <p>Timeframe Choice</p> <p>For long periods, use higher timeframes (1h, 1d) to reduce:</p> <ul> <li>API calls</li> <li>Download time</li> <li>Storage requirements</li> </ul>"},{"location":"user-guide/backfilling/#rate-limiting","title":"Rate Limiting","text":"<p>StreamForge handles rate limiting automatically:</p> <pre><code># Automatic rate limiting - no configuration needed\nbackfiller = sf.BinanceBackfilling(...)\nbackfiller.run()  # Respects exchange rate limits\n</code></pre> <p>For very large backfills, the process may take time:</p> Timeframe Period Approximate Time 1m 1 day ~1 minute 1m 1 month ~30 minutes 1m 1 year ~6 hours 1h 1 year ~15 minutes 1d 1 year ~1 minute"},{"location":"user-guide/backfilling/#safe-re-running","title":"Safe Re-Running","text":"<p>Backfilling is safe to re-run when using upsert:</p> <pre><code>postgres = (sf.PostgresEmitter(...)\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])  # Upsert!\n)\n\n# Run once\nbackfiller.register_emitter(postgres)\nbackfiller.run()\n\n# Run again - no duplicates, updates existing records\nbackfiller.run()\n</code></pre> <p>Without upsert: <pre><code># \u2717 Will create duplicates\npostgres.set_model(KlineTable)  # No on_conflict()\n\nbackfiller.register_emitter(postgres)\nbackfiller.run()  # First run\nbackfiller.run()  # Second run - DUPLICATES!\n</code></pre></p>"},{"location":"user-guide/backfilling/#gap-filling","title":"Gap Filling","text":"<p>Fill gaps in existing data:</p> <pre><code># You have data for Jan-Mar and Jul-Dec\n# Fill the Apr-Jun gap:\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-04-01\",  # Gap start\n    to_date=\"2024-06-30\"     # Gap end\n)\n\nbackfiller.register_emitter(postgres_with_upsert)\nbackfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/backfilling/#1-always-use-upsert-for-postgresql","title":"1. Always Use Upsert for PostgreSQL","text":"<pre><code># \u2713 Safe to re-run\npostgres.on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n\n# \u2717 Will create duplicates\npostgres.set_model(KlineTable)  # No upsert\n</code></pre>"},{"location":"user-guide/backfilling/#2-choose-appropriate-timeframe","title":"2. Choose Appropriate Timeframe","text":"<pre><code># \u2713 Good - 1h for analysis\nbackfiller = sf.BinanceBackfilling(\n    timeframe=\"1h\",\n    from_date=\"2023-01-01\",\n    to_date=\"2024-12-31\"\n)\n\n# \u26a0\ufe0f Slower - 1m for 2 years\nbackfiller = sf.BinanceBackfilling(\n    timeframe=\"1m\",  # Lots of data!\n    from_date=\"2023-01-01\",\n    to_date=\"2024-12-31\"\n)\n</code></pre>"},{"location":"user-guide/backfilling/#3-batch-large-backfills","title":"3. Batch Large Backfills","text":"<p>For very large periods, split into chunks:</p> <pre><code>import pandas as pd\n\n# Generate date ranges\ndate_ranges = pd.date_range(\n    start=\"2020-01-01\",\n    end=\"2024-12-31\",\n    freq=\"3MS\"  # 3-month intervals\n)\n\n# Backfill in chunks\nfor i in range(len(date_ranges) - 1):\n    from_date = date_ranges[i].strftime(\"%Y-%m-%d\")\n    to_date = date_ranges[i + 1].strftime(\"%Y-%m-%d\")\n\n    print(f\"Backfilling {from_date} to {to_date}...\")\n\n    backfiller = sf.BinanceBackfilling(\n        symbol=\"BTCUSDT\",\n        timeframe=\"1h\",\n        from_date=from_date,\n        to_date=to_date\n    )\n\n    backfiller.register_emitter(postgres)\n    backfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#4-test-with-small-ranges-first","title":"4. Test with Small Ranges First","text":"<pre><code># \u2713 Test first\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-10-01\",\n    to_date=\"2024-10-02\"  # Just 1 day\n)\n\n# Then scale up\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"  # Full year\n)\n</code></pre>"},{"location":"user-guide/backfilling/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/backfilling/#pattern-1-initial-database-population","title":"Pattern 1: Initial Database Population","text":"<pre><code># Populate fresh database\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n\nfor symbol in symbols:\n    backfiller = sf.BinanceBackfilling(\n        symbol=symbol,\n        timeframe=\"1h\",\n        from_date=\"2024-01-01\",\n        to_date=\"now\"\n    )\n    backfiller.register_emitter(postgres_with_upsert)\n    backfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#pattern-2-daily-update","title":"Pattern 2: Daily Update","text":"<pre><code>from datetime import datetime, timedelta\n\n# Backfill yesterday's data\nyesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\ntoday = datetime.now().strftime(\"%Y-%m-%d\")\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=yesterday,\n    to_date=today\n)\n\nbackfiller.register_emitter(postgres_with_upsert)\nbackfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#pattern-3-multi-exchange-backfill","title":"Pattern 3: Multi-Exchange Backfill","text":"<pre><code># Backfill same symbol from multiple exchanges\nsymbols_by_exchange = {\n    \"Binance\": \"BTCUSDT\",\n    \"OKX\": \"BTC-USDT\"\n}\n\n# Binance\nbinance_backfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\nbinance_backfiller.register_emitter(postgres)\nbinance_backfiller.run()\n\n# OKX\nokx_backfiller = sf.OkxBackfilling(\n    symbol=\"BTC-USDT\",\n    timeframe=\"1h\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\nokx_backfiller.register_emitter(postgres)\nokx_backfiller.run()\n</code></pre>"},{"location":"user-guide/backfilling/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/backfilling/#no-data-downloaded","title":"No Data Downloaded","text":"<p>Problem: Backfiller runs but no data appears.</p> <p>Solutions:</p> <ol> <li>Check date range is valid</li> <li>Verify symbol format for exchange</li> <li>Ensure exchange has data for that period</li> </ol>"},{"location":"user-guide/backfilling/#duplicate-data","title":"Duplicate Data","text":"<p>Problem: Duplicate rows in database.</p> <p>Solution: Enable upsert:</p> <pre><code>postgres.on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n</code></pre>"},{"location":"user-guide/backfilling/#slow-backfill","title":"Slow Backfill","text":"<p>Problem: Backfill takes very long.</p> <p>Solutions:</p> <ol> <li>Use higher timeframe (1h instead of 1m)</li> <li>Reduce date range</li> <li>This is normal for large datasets</li> </ol>"},{"location":"user-guide/backfilling/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Exchange \u2192 - Merge multiple exchanges</li> <li>Examples \u2192 - See backfilling examples</li> <li>API Reference \u2192 - Complete API docs</li> </ul>"},{"location":"user-guide/emitters/","title":"Emitters","text":"<p>Emitters define where your streaming data goes. StreamForge provides several built-in emitters, and you can create custom ones.</p>"},{"location":"user-guide/emitters/#overview","title":"Overview","text":"<p>An emitter receives normalized data and outputs it to a destination:</p> <pre><code>runner = sf.BinanceRunner(stream_input=stream)\nrunner.register_emitter(emitter)  # Data flows to emitter\nawait runner.run()\n</code></pre> <p>You can register multiple emitters - data flows to all of them:</p> <pre><code>runner.register_emitter(csv_emitter)\nrunner.register_emitter(postgres_emitter)\n# Data goes to all 2!\n</code></pre>"},{"location":"user-guide/emitters/#logging","title":"Logging","text":"<p>StreamForge uses a global logger that can be customized. Internal logging (connection status, errors, etc.) is handled automatically.</p>"},{"location":"user-guide/emitters/#using-the-global-logger","title":"Using the Global Logger","text":"<pre><code>import streamforge as sf\n\n# Default logger (uses Python's logging module)\n# All internal logging goes through sf.config.logger\n\n# Customize the logger\nfrom loguru import logger\nsf.config.logger = logger\n\n# Or use standard logging\nimport logging\nmy_logger = logging.getLogger(\"myapp\")\nsf.config.logger = my_logger\n\n# Or make it silent\nsf.config.set_silent()\n\n---\n\n## CSV Emitter\n\nSave data to CSV files for simple storage and analysis.\n\n### Basic Usage\n\n```python\nimport streamforge as sf\n\ncsv_emitter = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"btc_data.csv\"\n)\n\nrunner.register_emitter(csv_emitter)\n</code></pre>"},{"location":"user-guide/emitters/#parameters","title":"Parameters","text":"Parameter Type Required Description <code>source</code> <code>str</code> Yes Exchange name <code>symbol</code> <code>str</code> Yes Trading pair <code>timeframe</code> <code>str</code> Yes Candle interval <code>file_path</code> <code>str</code> Yes Output file path <code>transformer_function</code> <code>callable</code> No Data transformer"},{"location":"user-guide/emitters/#csv-format","title":"CSV Format","text":"<p>Generated CSV has these columns:</p> <pre><code>source,symbol,timeframe,open_ts,end_ts,open,high,low,close,volume\nBinance,BTCUSDT,1m,1735689600000,1735689659999,43250.00,43275.00,43240.00,43260.00,12.45\n</code></pre>"},{"location":"user-guide/emitters/#append-behavior","title":"Append Behavior","text":"<p>CSVEmitter appends to existing files:</p> <pre><code># First run - creates file\ncsv = sf.CSVEmitter(..., file_path=\"data.csv\")\n\n# Second run - appends to data.csv\ncsv = sf.CSVEmitter(..., file_path=\"data.csv\")\n</code></pre>"},{"location":"user-guide/emitters/#when-to-use","title":"When to Use","text":"<p>\u2713 Backfilling - Historical data dumps \u2713 Simple analysis - Pandas/Excel \u2713 Portability - Universal format \u2713 Quick exports - Fast and simple  </p> <p>\u2717 Real-time - File I/O overhead \u2717 Large datasets - Databases better \u2717 Querying - No indexes</p>"},{"location":"user-guide/emitters/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"5m\"\n    )\n\n    csv_emitter = sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"5m\",\n        file_path=\"binance_btc_5m.csv\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n    runner.register_emitter(csv_emitter)\n    # Internal logging handled by sf.config.logger\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>CSV Example \u2192</p>"},{"location":"user-guide/emitters/#postgresql","title":"PostgreSQL","text":""},{"location":"user-guide/emitters/#postgresql-emitter","title":"PostgreSQL Emitter","text":"<p>Save data to PostgreSQL database for production use.</p>"},{"location":"user-guide/emitters/#installation","title":"Installation","text":"<p>PostgreSQL support is included:</p> <pre><code>pip install streamforge  # Includes asyncpg\n</code></pre>"},{"location":"user-guide/emitters/#basic-usage","title":"Basic Usage","text":"<pre><code>import streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\n# Create emitter\npostgres = sf.PostgresEmitter(\n    host=\"localhost\",\n    dbname=\"crypto\",\n    user=\"postgres\",\n    password=\"mysecretpassword\"\n)\n\n# Set model\npostgres.set_model(KlineTable, inplace=True)\n\nrunner.register_emitter(postgres)\n</code></pre>"},{"location":"user-guide/emitters/#connection-methods","title":"Connection Methods","text":"ParametersURL <pre><code>postgres = sf.PostgresEmitter(\n    host=\"localhost\",\n    port=5432,\n    dbname=\"crypto\",\n    user=\"postgres\",\n    password=\"secret\"\n)\n</code></pre> <pre><code>postgres = sf.PostgresEmitter(\n    url=\"postgresql+asyncpg://user:pass@localhost:5432/crypto\"\n)\n</code></pre>"},{"location":"user-guide/emitters/#method-chaining","title":"Method Chaining","text":"<p>StreamForge supports fluent method chaining:</p> <pre><code>emitter = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n    .set_model(KlineTable)\n    .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    .set_transformer(my_transformer)\n)\n</code></pre> <p>Or step-by-step with <code>inplace=True</code>:</p> <pre><code>emitter = sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\nemitter.set_model(KlineTable, inplace=True)\nemitter.on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"], inplace=True)\n</code></pre>"},{"location":"user-guide/emitters/#upsert-on-conflict","title":"Upsert (ON CONFLICT)","text":"<p>Handle duplicate data with upsert:</p> <pre><code>postgres.on_conflict(\n    [\"source\", \"symbol\", \"timeframe\", \"open_ts\"],  # Primary key columns\n    inplace=True\n)\n</code></pre> <p>This enables <code>ON CONFLICT DO UPDATE</code>:</p> <pre><code>INSERT INTO klines VALUES (...)\nON CONFLICT (source, symbol, timeframe, open_ts)\nDO UPDATE SET\n    end_ts = EXCLUDED.end_ts,\n    open = EXCLUDED.open,\n    ...\n</code></pre> <p>When to use:</p> <ul> <li>Backfilling (may have duplicates)</li> <li>Re-running pipelines</li> <li>Gap filling</li> </ul> <p>When not to use:</p> <ul> <li>Pure append-only streaming</li> <li>No possibility of duplicates</li> </ul>"},{"location":"user-guide/emitters/#custom-conflict-actions","title":"Custom Conflict Actions","text":"<pre><code># Update only specific columns\npostgres.on_conflict(\n    conflict_columns=[\"source\", \"symbol\", \"timeframe\", \"open_ts\"],\n    update_columns=[\"close\", \"volume\"]  # Only update these\n)\n\n# Do nothing on conflict\npostgres.on_conflict_do_nothing(\n    [\"source\", \"symbol\", \"timeframe\", \"open_ts\"]\n)\n</code></pre>"},{"location":"user-guide/emitters/#database-setup","title":"Database Setup","text":"<p>Create your table:</p> <pre><code>CREATE TABLE klines (\n    source VARCHAR(255) NOT NULL,\n    symbol VARCHAR(255) NOT NULL,\n    timeframe VARCHAR(50) NOT NULL,\n    open_ts BIGINT NOT NULL,\n    end_ts BIGINT,\n    open FLOAT,\n    high FLOAT,\n    low FLOAT,\n    close FLOAT,\n    volume FLOAT,\n\n    PRIMARY KEY (source, symbol, timeframe, open_ts)\n);\n\nCREATE INDEX idx_symbol_time ON klines(symbol, open_ts);\n</code></pre>"},{"location":"user-guide/emitters/#complete-example_1","title":"Complete Example","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass KlineTable(Base):\n    __tablename__ = 'klines'\n    source = Column(String, primary_key=True)\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def main():\n    # Create emitter\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"mysecretpassword\"\n        )\n        .set_model(KlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    # Create stream\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    # Run\n    runner = sf.BinanceRunner(stream_input=stream)\n    runner.register_emitter(postgres)\n    # Internal logging handled by sf.config.logger\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre> <p>PostgreSQL Examples \u2192</p>"},{"location":"user-guide/emitters/#kafka-emitter","title":"Kafka Emitter","text":"<p>Stream data to Apache Kafka for real-time processing.</p>"},{"location":"user-guide/emitters/#installation_1","title":"Installation","text":"<p>Kafka support is included:</p> <pre><code>pip install streamforge  # Includes aiokafka\n</code></pre>"},{"location":"user-guide/emitters/#basic-usage_1","title":"Basic Usage","text":"<pre><code>import streamforge as sf\n\nkafka = sf.KafkaEmitter(\n    bootstrap_servers=\"localhost:9092\",\n    topic=\"crypto-stream\"\n)\n\nrunner.register_emitter(kafka)\n</code></pre>"},{"location":"user-guide/emitters/#parameters_1","title":"Parameters","text":"Parameter Type Default Description <code>bootstrap_servers</code> <code>str</code> Required Kafka broker address <code>topic</code> <code>str</code> Required Topic name <code>key</code> <code>str</code> <code>None</code> Message key <code>compression_type</code> <code>str</code> <code>None</code> gzip, snappy, lz4, zstd"},{"location":"user-guide/emitters/#message-format","title":"Message Format","text":"<p>Kafka messages are JSON:</p> <pre><code>{\n  \"source\": \"Binance\",\n  \"symbol\": \"BTCUSDT\",\n  \"timeframe\": \"1m\",\n  \"open_ts\": 1735689600000,\n  \"end_ts\": 1735689659999,\n  \"open\": 43250.00,\n  \"high\": 43275.00,\n  \"low\": 43240.00,\n  \"close\": 43260.00,\n  \"volume\": 12.45\n}\n</code></pre>"},{"location":"user-guide/emitters/#with-compression","title":"With Compression","text":"<pre><code>kafka = sf.KafkaEmitter(\n    bootstrap_servers=\"localhost:9092\",\n    topic=\"crypto-stream\",\n    compression_type=\"gzip\"\n)\n</code></pre>"},{"location":"user-guide/emitters/#complete-example_2","title":"Complete Example","text":"<pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    kafka = sf.KafkaEmitter(\n        bootstrap_servers=\"localhost:9092\",\n        topic=\"binance-klines\",\n        compression_type=\"gzip\"\n    )\n\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n    runner.register_emitter(kafka)\n    # Internal logging handled by sf.config.logger\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/emitters/#when-to-use_1","title":"When to Use","text":"<p>\u2713 Real-time pipelines - Stream processing \u2713 Microservices - Event streaming \u2713 Scalability - Distributed consumption \u2713 Multiple consumers - Fan-out pattern  </p> <p>\u2717 Simple use cases - CSV/DB easier \u2717 No Kafka - Requires infrastructure</p>"},{"location":"user-guide/emitters/#emitter-comparison","title":"Emitter Comparison","text":"Feature CSV PostgreSQL Kafka Persistence \u2713 File \u2713 Database \u2713 Stream Queryable Limited \u2713\u2713 \u274c Real-time \u274c \u26a0\ufe0f \u2713\u2713 Scalability \u274c \u2713 \u2713\u2713 Debugging \u26a0\ufe0f \u26a0\ufe0f \u274c Production \u26a0\ufe0f \u2713\u2713 \u2713\u2713 Complexity \u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 Setup None Database Kafka cluster <p>Legend: \u2713\u2713 Excellent | \u2713 Good | \u26a0\ufe0f Possible | \u274c Not suitable</p>"},{"location":"user-guide/emitters/#multiple-emitters","title":"Multiple Emitters","text":"<p>Send data to multiple destinations simultaneously:</p> <pre><code>import asyncio\nimport streamforge as sf\n\nasync def main():\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n\n    # Add multiple emitters\n    # Internal logging handled by sf.config.logger\n    runner.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"backup.csv\"\n    ))\n    runner.register_emitter(postgres_emitter)\n    runner.register_emitter(kafka_emitter)\n\n    # Data flows to ALL 4 emitters!\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/emitters/#use-cases","title":"Use Cases","text":"<ul> <li>CSV + PostgreSQL - Backup + database</li> <li>PostgreSQL + Kafka - Store + stream</li> <li>All 3 - Complete pipeline</li> </ul>"},{"location":"user-guide/emitters/#custom-emitters","title":"Custom Emitters","text":"<p>Create custom emitters by inheriting from <code>DataEmitter</code>:</p> <pre><code>from streamforge.base.emitters.base import DataEmitter\nfrom streamforge.base.normalize.ohlc.models.candle import Kline\n\nclass MyCustomEmitter(DataEmitter):\n    \"\"\"Custom emitter example\"\"\"\n\n    async def emit(self, data: Kline):\n        \"\"\"Handle each data point\"\"\"\n        # Your custom logic here\n        print(f\"Custom: {data.symbol} @ ${data.close}\")\n\n    async def connect(self):\n        \"\"\"Setup (optional)\"\"\"\n        print(\"Connecting to custom destination...\")\n\n    async def close(self):\n        \"\"\"Cleanup (optional)\"\"\"\n        print(\"Closing custom connection...\")\n\n# Use it\ncustom = MyCustomEmitter()\nrunner.register_emitter(custom)\n</code></pre>"},{"location":"user-guide/emitters/#advanced-custom-emitter","title":"Advanced Custom Emitter","text":"<pre><code>import aiohttp\nfrom streamforge.base.emitters.base import DataEmitter\n\nclass WebhookEmitter(DataEmitter):\n    \"\"\"Send data to webhook\"\"\"\n\n    def __init__(self, webhook_url: str):\n        self.url = webhook_url\n        self.session = None\n\n    async def connect(self):\n        self.session = aiohttp.ClientSession()\n\n    async def emit(self, data: Kline):\n        payload = {\n            \"symbol\": data.symbol,\n            \"price\": data.close,\n            \"timestamp\": data.open_ts\n        }\n        await self.session.post(self.url, json=payload)\n\n    async def close(self):\n        if self.session:\n            await self.session.close()\n\n# Use it\nwebhook = WebhookEmitter(\"https://api.example.com/webhook\")\nrunner.register_emitter(webhook)\n</code></pre>"},{"location":"user-guide/emitters/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/emitters/#1-choose-the-right-emitter","title":"1. Choose the Right Emitter","text":"<ul> <li>Simple storage \u2192 CSV</li> <li>Production \u2192 PostgreSQL</li> <li>Real-time processing \u2192 Kafka</li> </ul>"},{"location":"user-guide/emitters/#2-use-upsert-for-backfilling","title":"2. Use Upsert for Backfilling","text":"<pre><code># Always use on_conflict when backfilling\npostgres.on_conflict(primary_key_columns)\n</code></pre>"},{"location":"user-guide/emitters/#3-customize-logging","title":"3. Customize Logging","text":"<pre><code># Customize the global logger\nfrom loguru import logger\nsf.config.logger = logger\n\n# Or use standard logging\nimport logging\nmy_logger = logging.getLogger(\"myapp\")\nsf.config.logger = my_logger\n</code></pre>"},{"location":"user-guide/emitters/#4-batch-for-performance","title":"4. Batch for Performance","text":"<pre><code># PostgreSQL batches automatically\n# Adjust batch size if needed\npostgres.batch_size = 100\n</code></pre>"},{"location":"user-guide/emitters/#next-steps","title":"Next Steps","text":"<ul> <li>Transformers \u2192 - Modify data before emitting</li> <li>Examples \u2192 - See emitters in action</li> <li>API Reference \u2192 - Complete API docs</li> </ul>"},{"location":"user-guide/multi-exchange/","title":"Multi-Exchange","text":"<p>Stream and merge data from multiple cryptocurrency exchanges simultaneously. Perfect for price comparison, arbitrage monitoring, and unified data collection.</p>"},{"location":"user-guide/multi-exchange/#what-is-multi-exchange","title":"What is Multi-Exchange?","text":"<p>Multi-exchange streaming allows you to:</p> <ol> <li>Stream from multiple exchanges at once</li> <li>Merge streams into a unified pipeline</li> <li>Compare prices across exchanges</li> <li>Detect arbitrage opportunities</li> <li>Store in unified database with exchange labels</li> </ol>"},{"location":"user-guide/multi-exchange/#merge-streams","title":"Merge Streams","text":""},{"location":"user-guide/multi-exchange/#basic-merging","title":"Basic Merging","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def main():\n    # Create runners for different exchanges\n    binance_runner = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx_runner = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],  # OKX format\n            timeframe=\"1m\"\n        )\n    )\n\n    # Merge and process\n    async for data in merge_streams(binance_runner, okx_runner):\n        print(f\"{data.source:8} | {data.symbol:10} | ${data.close:,.2f}\")\n\nasyncio.run(main())\n</code></pre> <p>Output: <pre><code>Binance  | BTCUSDT    | $43,260.00\nOKX      | BTC-USDT   | $43,255.00\nBinance  | BTCUSDT    | $43,265.00\nOKX      | BTC-USDT   | $43,258.00\n</code></pre></p>"},{"location":"user-guide/multi-exchange/#three-exchanges","title":"Three Exchanges","text":"<pre><code>async def three_exchanges():\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    kraken = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\", \"ETH/USD\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    # Merge all 3\n    async for data in merge_streams(binance, okx, kraken):\n        print(f\"\ud83d\udce1 {data.source:8} | {data.symbol:12} | ${data.close:,.2f}\")\n\nasyncio.run(three_exchanges())\n</code></pre>"},{"location":"user-guide/multi-exchange/#symbol-format-mapping","title":"Symbol Format Mapping","text":"<p>Each exchange uses different symbol formats:</p> Exchange BTC/USD Format ETH/USD Format Binance <code>BTCUSDT</code> <code>ETHUSDT</code> OKX <code>BTC-USDT</code> <code>ETH-USDT</code> Kraken <code>BTC/USD</code> <code>ETH/USD</code> <p>When merging, StreamForge preserves the original symbol format. For comparison, normalize symbols in your code:</p> <pre><code>def normalize_symbol(symbol: str, source: str) -&gt; str:\n    \"\"\"Normalize symbol to common format\"\"\"\n    if source == \"Binance\":\n        return symbol  # Already normalized\n    elif source == \"OKX\":\n        return symbol.replace(\"-\", \"\")  # BTC-USDT \u2192 BTCUSDT\n    elif source == \"Kraken\":\n        return symbol.replace(\"/\", \"\")  # BTC/USD \u2192 BTCUSD\n    return symbol\n\nasync for data in merge_streams(binance, okx, kraken):\n    normalized = normalize_symbol(data.symbol, data.source)\n    print(f\"{data.source} {normalized}: ${data.close:,.2f}\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#unified-database","title":"Unified Database","text":"<p>Store data from all exchanges in one table:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass UnifiedKlineTable(Base):\n    \"\"\"One table for all exchanges\"\"\"\n    __tablename__ = 'unified_klines'\n\n    source = Column(String, primary_key=True)      # Exchange name\n    symbol = Column(String, primary_key=True)\n    timeframe = Column(String, primary_key=True)\n    open_ts = Column(BigInteger, primary_key=True)\n\n    end_ts = Column(BigInteger)\n    open = Column(Float)\n    high = Column(Float)\n    low = Column(Float)\n    close = Column(Float)\n    volume = Column(Float)\n\nasync def unified_database():\n    # Create shared emitter\n    postgres = (sf.PostgresEmitter(\n            host=\"localhost\",\n            dbname=\"crypto\",\n            user=\"postgres\",\n            password=\"secret\"\n        )\n        .set_model(UnifiedKlineTable)\n        .on_conflict([\"source\", \"symbol\", \"timeframe\", \"open_ts\"])\n    )\n\n    await postgres.connect()\n\n    # Create runners\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    # Merge and emit to shared database\n    async for data in merge_streams(binance, okx):\n        await postgres.emit(data)\n        print(f\"\ud83d\udcbe Saved {data.source} {data.symbol}\")\n\nasyncio.run(unified_database())\n</code></pre> <p>Query the unified table:</p> <pre><code>-- All BTC data across exchanges\nSELECT source, symbol, close, volume\nFROM unified_klines\nWHERE symbol LIKE '%BTC%'\nORDER BY open_ts DESC\nLIMIT 10;\n\n-- Compare prices by exchange\nSELECT \n    source,\n    AVG(close) as avg_price,\n    MAX(close) as max_price,\n    MIN(close) as min_price\nFROM unified_klines\nWHERE symbol LIKE '%BTC%'\n  AND timeframe = '1m'\n  AND open_ts &gt; EXTRACT(EPOCH FROM NOW() - INTERVAL '1 hour') * 1000\nGROUP BY source;\n</code></pre>"},{"location":"user-guide/multi-exchange/#price-comparison","title":"Price Comparison","text":"<p>Track price differences in real-time:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def price_comparison():\n    # Store latest prices\n    latest_prices = {}\n\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    async for data in merge_streams(binance, okx):\n        # Update latest price\n        latest_prices[data.source] = data.close\n\n        # Compare when we have both\n        if len(latest_prices) &gt;= 2:\n            binance_price = latest_prices.get(\"Binance\", 0)\n            okx_price = latest_prices.get(\"OKX\", 0)\n\n            if binance_price and okx_price:\n                diff = binance_price - okx_price\n                diff_pct = (diff / binance_price) * 100\n\n                print(f\"\\n\ud83d\udcb0 Price Comparison:\")\n                print(f\"   Binance: ${binance_price:,.2f}\")\n                print(f\"   OKX:     ${okx_price:,.2f}\")\n                print(f\"   Diff:    ${diff:+.2f} ({diff_pct:+.4f}%)\")\n\n                # Alert on large difference\n                if abs(diff_pct) &gt; 0.1:\n                    print(f\"   \ud83d\udea8 ARBITRAGE OPPORTUNITY!\")\n\nasyncio.run(price_comparison())\n</code></pre>"},{"location":"user-guide/multi-exchange/#arbitrage-detection","title":"Arbitrage Detection","text":"<p>Detect and alert on arbitrage opportunities:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\nfrom collections import defaultdict\n\nclass ArbitrageDetector:\n    \"\"\"Detect arbitrage opportunities\"\"\"\n\n    def __init__(self, threshold_pct=0.1):\n        self.threshold = threshold_pct\n        self.prices = defaultdict(dict)  # {symbol: {exchange: price}}\n\n    def update(self, data):\n        \"\"\"Update price and check for arbitrage\"\"\"\n        # Normalize symbol for comparison\n        symbol = self.normalize_symbol(data.symbol)\n\n        # Update price\n        self.prices[symbol][data.source] = data.close\n\n        # Check arbitrage\n        self.check_arbitrage(symbol)\n\n    def normalize_symbol(self, symbol: str) -&gt; str:\n        \"\"\"Normalize to BTC/USD format\"\"\"\n        return symbol.replace(\"-\", \"/\").replace(\"USDT\", \"/USDT\")\n\n    def check_arbitrage(self, symbol: str):\n        \"\"\"Check for arbitrage opportunities\"\"\"\n        prices = self.prices[symbol]\n\n        if len(prices) &lt; 2:\n            return\n\n        # Find highest and lowest\n        exchanges = list(prices.keys())\n        highest_exchange = max(exchanges, key=lambda e: prices[e])\n        lowest_exchange = min(exchanges, key=lambda e: prices[e])\n\n        highest_price = prices[highest_exchange]\n        lowest_price = prices[lowest_exchange]\n\n        # Calculate difference\n        diff = highest_price - lowest_price\n        diff_pct = (diff / lowest_price) * 100\n\n        # Alert if above threshold\n        if diff_pct &gt; self.threshold:\n            print(f\"\\n\ud83d\udea8 ARBITRAGE ALERT: {symbol}\")\n            print(f\"   Buy  @ {lowest_exchange:8}: ${lowest_price:,.2f}\")\n            print(f\"   Sell @ {highest_exchange:8}: ${highest_price:,.2f}\")\n            print(f\"   Profit: ${diff:,.2f} ({diff_pct:.2f}%)\")\n\nasync def arbitrage_monitor():\n    \"\"\"Monitor for arbitrage opportunities\"\"\"\n\n    detector = ArbitrageDetector(threshold_pct=0.1)\n\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    kraken = sf.KrakenRunner(\n        stream_input=sf.DataInput(\n            type=\"ohlc\",\n            symbols=[\"BTC/USD\", \"ETH/USD\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    async for data in merge_streams(binance, okx, kraken):\n        detector.update(data)\n\nasyncio.run(arbitrage_monitor())\n</code></pre>"},{"location":"user-guide/multi-exchange/#complete-examples","title":"Complete Examples","text":""},{"location":"user-guide/multi-exchange/#example-1-multi-symbol-multi-exchange","title":"Example 1: Multi-Symbol Multi-Exchange","text":"<pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def multi_everything():\n    \"\"\"Multiple symbols from multiple exchanges\"\"\"\n\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\", \"ETH-USDT\", \"SOL-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n\n    print(\"\u2713 Streaming:\")\n    print(\"  - 3 symbols (BTC, ETH, SOL)\")\n    print(\"  - 2 exchanges (Binance, OKX)\")\n    print(\"  = 6 data streams merged!\\n\")\n\n    async for data in merge_streams(binance, okx):\n        print(f\"\ud83d\udcc8 {data.source:8} | {data.symbol:10} | ${data.close:&gt;10,.2f} | Vol: {data.volume:&gt;10,.2f}\")\n\nasyncio.run(multi_everything())\n</code></pre>"},{"location":"user-guide/multi-exchange/#example-2-csv-per-exchange","title":"Example 2: CSV Per Exchange","text":"<p>Separate CSV files per exchange:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom streamforge.merge_stream import merge_streams\n\nasync def csv_per_exchange():\n    \"\"\"Save each exchange to separate CSV\"\"\"\n\n    binance = sf.BinanceRunner(\n        stream_input=sf.DataInput(\n            type=\"kline\",\n            symbols=[\"BTCUSDT\"],\n            timeframe=\"1m\"\n        )\n    )\n    binance.register_emitter(sf.CSVEmitter(\n        source=\"Binance\",\n        symbol=\"BTCUSDT\",\n        timeframe=\"1m\",\n        file_path=\"binance_btc.csv\"\n    ))\n\n    okx = sf.OKXRunner(\n        stream_input=sf.DataInput(\n            type=\"candle\",\n            symbols=[\"BTC-USDT\"],\n            timeframe=\"1m\"\n        )\n    )\n    okx.register_emitter(sf.CSVEmitter(\n        source=\"OKX\",\n        symbol=\"BTC-USDT\",\n        timeframe=\"1m\",\n        file_path=\"okx_btc.csv\"\n    ))\n\n    async for data in merge_streams(binance, okx):\n        pass  # Data automatically saved by emitters\n\nasyncio.run(csv_per_exchange())\n</code></pre>"},{"location":"user-guide/multi-exchange/#use-cases","title":"Use Cases","text":""},{"location":"user-guide/multi-exchange/#1-price-comparison","title":"1. Price Comparison","text":"<p>Monitor price differences for trading decisions:</p> <pre><code>async for data in merge_streams(binance, okx, kraken):\n    print(f\"{data.source}: ${data.close:,.2f}\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#2-arbitrage-trading","title":"2. Arbitrage Trading","text":"<p>Detect profitable price differences:</p> <pre><code>if binance_price &gt; okx_price + fees:\n    print(\"Buy OKX, Sell Binance!\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#3-data-redundancy","title":"3. Data Redundancy","text":"<p>Multiple sources for reliability:</p> <pre><code># If one exchange goes down, others continue\nasync for data in merge_streams(binance, okx, kraken):\n    save_to_database(data)\n</code></pre>"},{"location":"user-guide/multi-exchange/#4-volume-analysis","title":"4. Volume Analysis","text":"<p>Compare trading volumes across exchanges:</p> <pre><code>volumes = {}\nasync for data in merge_streams(binance, okx):\n    volumes[data.source] = volumes.get(data.source, 0) + data.volume\n</code></pre>"},{"location":"user-guide/multi-exchange/#5-exchange-health-monitoring","title":"5. Exchange Health Monitoring","text":"<p>Track exchange uptime and data quality:</p> <pre><code>async for data in merge_streams(*runners):\n    log_exchange_activity(data.source, data.symbol)\n</code></pre>"},{"location":"user-guide/multi-exchange/#performance-considerations","title":"Performance Considerations","text":""},{"location":"user-guide/multi-exchange/#memory-usage","title":"Memory Usage","text":"<p>Each runner maintains its own connection and buffers:</p> <pre><code># 3 runners = 3 WebSocket connections\nbinance = sf.BinanceRunner(...)\nokx = sf.OKXRunner(...)\nkraken = sf.KrakenRunner(...)\n</code></pre>"},{"location":"user-guide/multi-exchange/#network-load","title":"Network Load","text":"<p>Each exchange has its own WebSocket:</p> <pre><code># Each runner connects independently\n# Total connections = number of runners\nasync for data in merge_streams(r1, r2, r3):  # 3 connections\n    pass\n</code></pre>"},{"location":"user-guide/multi-exchange/#data-rate","title":"Data Rate","text":"<p>Merged stream combines data rates:</p> <pre><code># Binance: ~60 updates/min for 1m candles\n# OKX: ~60 updates/min for 1m candles\n# Merged: ~120 updates/min total\n</code></pre>"},{"location":"user-guide/multi-exchange/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/multi-exchange/#1-use-consistent-timeframes","title":"1. Use Consistent Timeframes","text":"<pre><code># \u2713 Good - same timeframe\nbinance = sf.BinanceRunner(DataInput(timeframe=\"1m\", ...))\nokx = sf.OKXRunner(DataInput(timeframe=\"1m\", ...))\n\n# \u26a0\ufe0f Mixed - harder to compare\nbinance = sf.BinanceRunner(DataInput(timeframe=\"1m\", ...))\nokx = sf.OKXRunner(DataInput(timeframe=\"5m\", ...))\n</code></pre>"},{"location":"user-guide/multi-exchange/#2-normalize-symbols","title":"2. Normalize Symbols","text":"<pre><code>def normalize_symbol(symbol: str) -&gt; str:\n    \"\"\"Convert all to common format\"\"\"\n    return symbol.replace(\"-\", \"\").replace(\"/\", \"\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#3-handle-exchange-specific-features","title":"3. Handle Exchange-Specific Features","text":"<pre><code># Some exchanges may have features others don't\nif data.source == \"Binance\":\n    # Binance-specific logic\n    pass\nelif data.source == \"OKX\":\n    # OKX-specific logic\n    pass\n</code></pre>"},{"location":"user-guide/multi-exchange/#4-monitor-connection-health","title":"4. Monitor Connection Health","text":"<pre><code>from collections import defaultdict\nfrom datetime import datetime, timedelta\n\nlast_update = defaultdict(lambda: datetime.now())\n\nasync for data in merge_streams(binance, okx, kraken):\n    last_update[data.source] = datetime.now()\n\n    # Check for stale connections\n    for exchange, last_time in last_update.items():\n        if datetime.now() - last_time &gt; timedelta(minutes=5):\n            print(f\"\u26a0\ufe0f  {exchange} hasn't sent data in 5 minutes!\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/multi-exchange/#different-update-rates","title":"Different Update Rates","text":"<p>Problem: Exchanges update at different rates.</p> <p>Solution: This is normal. Exchanges have different internal mechanisms.</p>"},{"location":"user-guide/multi-exchange/#symbol-format-confusion","title":"Symbol Format Confusion","text":"<p>Problem: Same asset has different symbols.</p> <p>Solution: Normalize symbols for comparison:</p> <pre><code>def normalize_symbol(symbol: str) -&gt; str:\n    return symbol.replace(\"-\", \"\").replace(\"/\", \"\").upper()\n</code></pre>"},{"location":"user-guide/multi-exchange/#missing-data-from-one-exchange","title":"Missing Data from One Exchange","text":"<p>Problem: One exchange stops sending data.</p> <p>Solution: Add timeout detection:</p> <pre><code>from datetime import datetime, timedelta\n\nlast_seen = {}\n\nasync for data in merge_streams(binance, okx):\n    last_seen[data.source] = datetime.now()\n\n    # Alert if an exchange goes silent\n    for exchange in [\"Binance\", \"OKX\"]:\n        if exchange not in last_seen:\n            continue\n        if datetime.now() - last_seen[exchange] &gt; timedelta(minutes=2):\n            print(f\"\u26a0\ufe0f  {exchange} connection may be down!\")\n</code></pre>"},{"location":"user-guide/multi-exchange/#next-steps","title":"Next Steps","text":"<ul> <li>Examples \u2192 - See multi-exchange examples</li> <li>API Reference \u2192 - Complete runner documentation</li> <li>Exchange Guides \u2192 - Exchange-specific details</li> </ul>"},{"location":"user-guide/transformers/","title":"Transformers","text":"<p>Transformers modify data before it reaches emitters. Use them to rename fields, add computed values, filter data, or adapt to your schema.</p>"},{"location":"user-guide/transformers/#what-are-transformers","title":"What are Transformers?","text":"<p>A transformer is a function that takes data and returns modified data:</p> <pre><code>def my_transformer(data: dict) -&gt; dict:\n    \"\"\"Transform data\"\"\"\n    return modified_data\n</code></pre> <p>Transformers sit between processors and emitters:</p> <pre><code>graph LR\n    A[Processor] --&gt; B[Transformer]\n    B --&gt; C[Emitter]</code></pre>"},{"location":"user-guide/transformers/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/transformers/#set-transformer-on-emitter","title":"Set Transformer on Emitter","text":"<pre><code>def rename_fields(data: dict) -&gt; dict:\n    \"\"\"Rename fields to match database schema\"\"\"\n    return {\n        \"exchange\": data[\"source\"],\n        \"ticker\": data[\"symbol\"],\n        \"timestamp\": data[\"open_ts\"],\n        \"price\": data[\"close\"]\n    }\n\n# Apply to emitter\nemitter.set_transformer(rename_fields)\n</code></pre>"},{"location":"user-guide/transformers/#with-postgresql","title":"With PostgreSQL","text":"<pre><code>postgres = sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\npostgres.set_model(MyTable)\npostgres.set_transformer(rename_fields)  # Transform before saving\n</code></pre>"},{"location":"user-guide/transformers/#with-csv","title":"With CSV","text":"<pre><code>csv = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"data.csv\",\n    transformer_function=rename_fields  # Pass in constructor\n)\n</code></pre>"},{"location":"user-guide/transformers/#common-transformers","title":"Common Transformers","text":""},{"location":"user-guide/transformers/#1-rename-fields","title":"1. Rename Fields","text":"<p>Map StreamForge fields to your schema:</p> <pre><code>def rename_transformer(data: dict) -&gt; dict:\n    \"\"\"Database uses different column names\"\"\"\n    return {\n        \"exchange\": data[\"source\"],      # source \u2192 exchange\n        \"ticker\": data[\"symbol\"],        # symbol \u2192 ticker\n        \"tf\": data[\"timeframe\"],         # timeframe \u2192 tf\n        \"timestamp\": data[\"open_ts\"],    # open_ts \u2192 timestamp\n        \"o\": data[\"open\"],\n        \"h\": data[\"high\"],\n        \"l\": data[\"low\"],\n        \"c\": data[\"close\"],\n        \"v\": data[\"volume\"]\n    }\n</code></pre> <p>Use case: Your database has different column names than StreamForge defaults.</p>"},{"location":"user-guide/transformers/#2-filter-fields","title":"2. Filter Fields","text":"<p>Keep only what you need:</p> <pre><code>def filter_fields(data: dict) -&gt; dict:\n    \"\"\"Keep only essential fields\"\"\"\n    return {\n        \"source\": data[\"source\"],\n        \"symbol\": data[\"symbol\"],\n        \"timeframe\": data[\"timeframe\"],\n        \"open_ts\": data[\"open_ts\"],\n        \"close\": data[\"close\"],      # Only close price\n        \"volume\": data[\"volume\"]     # Only volume\n        # Removed: open, high, low, end_ts\n    }\n</code></pre> <p>Use case: Save storage space, simplify schema.</p>"},{"location":"user-guide/transformers/#3-add-computed-fields","title":"3. Add Computed Fields","text":"<p>Calculate additional metrics:</p> <pre><code>def add_computed_fields(data: dict) -&gt; dict:\n    \"\"\"Add technical indicators\"\"\"\n    return {\n        **data,  # Keep all original fields\n        # Add new fields\n        \"price_range\": data[\"high\"] - data[\"low\"],\n        \"price_change\": data[\"close\"] - data[\"open\"],\n        \"price_change_pct\": ((data[\"close\"] - data[\"open\"]) / data[\"open\"]) * 100,\n        \"is_bullish\": data[\"close\"] &gt; data[\"open\"],\n        \"body_size\": abs(data[\"close\"] - data[\"open\"]),\n        \"upper_wick\": data[\"high\"] - max(data[\"open\"], data[\"close\"]),\n        \"lower_wick\": min(data[\"open\"], data[\"close\"]) - data[\"low\"],\n    }\n</code></pre> <p>Use case: Pre-calculate metrics for analysis.</p>"},{"location":"user-guide/transformers/#4-convert-units","title":"4. Convert Units","text":"<p>Change data units or scale:</p> <pre><code>def convert_units(data: dict) -&gt; dict:\n    \"\"\"Convert volume to millions\"\"\"\n    return {\n        **data,\n        \"volume\": data[\"volume\"] / 1_000_000,  # Convert to millions\n        \"volume_unit\": \"millions\",\n        \"volume_usd\": data[\"volume\"] * data[\"close\"]  # Add USD value\n    }\n</code></pre> <p>Use case: Normalize units, add derived metrics.</p>"},{"location":"user-guide/transformers/#5-format-timestamps","title":"5. Format Timestamps","text":"<p>Convert timestamps to different formats:</p> <pre><code>from datetime import datetime\n\ndef format_timestamps(data: dict) -&gt; dict:\n    \"\"\"Add human-readable timestamp\"\"\"\n    return {\n        **data,\n        \"open_datetime\": datetime.fromtimestamp(data[\"open_ts\"] / 1000).isoformat(),\n        \"date\": datetime.fromtimestamp(data[\"open_ts\"] / 1000).date().isoformat()\n    }\n</code></pre> <p>Use case: Easier datetime queries, human-readable exports.</p>"},{"location":"user-guide/transformers/#advanced-transformers","title":"Advanced Transformers","text":""},{"location":"user-guide/transformers/#stateful-transformer","title":"Stateful Transformer","text":"<p>Maintain state across transformations:</p> <pre><code>class StatefulTransformer:\n    \"\"\"Transformer with internal state\"\"\"\n\n    def __init__(self):\n        self.count = 0\n        self.running_total = 0\n\n    def transform(self, data: dict) -&gt; dict:\n        \"\"\"Add sequence number and running average\"\"\"\n        self.count += 1\n        self.running_total += data[\"close\"]\n\n        return {\n            **data,\n            \"sequence\": self.count,\n            \"running_avg\": self.running_total / self.count\n        }\n\n# Use it\ntransformer = StatefulTransformer()\nemitter.set_transformer(transformer.transform)\n</code></pre>"},{"location":"user-guide/transformers/#conditional-transformer","title":"Conditional Transformer","text":"<p>Apply different transformations based on conditions:</p> <pre><code>def conditional_transformer(data: dict) -&gt; dict:\n    \"\"\"Different transformations for different symbols\"\"\"\n\n    # Base data\n    result = data.copy()\n\n    # Symbol-specific logic\n    if data[\"symbol\"] == \"BTCUSDT\":\n        result[\"asset_class\"] = \"crypto\"\n        result[\"is_btc\"] = True\n    elif data[\"symbol\"] == \"ETHUSDT\":\n        result[\"asset_class\"] = \"crypto\"\n        result[\"is_btc\"] = False\n\n    # Price-based logic\n    if data[\"close\"] &gt; 50000:\n        result[\"price_level\"] = \"high\"\n    elif data[\"close\"] &gt; 30000:\n        result[\"price_level\"] = \"medium\"\n    else:\n        result[\"price_level\"] = \"low\"\n\n    return result\n</code></pre>"},{"location":"user-guide/transformers/#chained-transformers","title":"Chained Transformers","text":"<p>Apply multiple transformations:</p> <pre><code>def transform_1(data: dict) -&gt; dict:\n    \"\"\"First transformation\"\"\"\n    return {**data, \"step1\": True}\n\ndef transform_2(data: dict) -&gt; dict:\n    \"\"\"Second transformation\"\"\"\n    return {**data, \"step2\": True}\n\ndef chained_transformer(data: dict) -&gt; dict:\n    \"\"\"Apply multiple transformations\"\"\"\n    data = transform_1(data)\n    data = transform_2(data)\n    return data\n\nemitter.set_transformer(chained_transformer)\n</code></pre>"},{"location":"user-guide/transformers/#complete-examples","title":"Complete Examples","text":""},{"location":"user-guide/transformers/#example-1-database-schema-mapping","title":"Example 1: Database Schema Mapping","text":"<p>Your database has custom column names:</p> <pre><code>import asyncio\nimport streamforge as sf\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, String, Float, BigInteger\n\nBase = declarative_base()\n\nclass CustomKlineTable(Base):\n    \"\"\"Custom schema\"\"\"\n    __tablename__ = 'custom_klines'\n\n    exchange = Column(String, primary_key=True)\n    ticker = Column(String, primary_key=True)\n    tf = Column(String, primary_key=True)\n    timestamp = Column(BigInteger, primary_key=True)\n    o = Column(Float)\n    h = Column(Float)\n    l = Column(Float)\n    c = Column(Float)\n    v = Column(Float)\n\ndef schema_mapper(data: dict) -&gt; dict:\n    \"\"\"Map to custom schema\"\"\"\n    return {\n        \"exchange\": data[\"source\"],\n        \"ticker\": data[\"symbol\"],\n        \"tf\": data[\"timeframe\"],\n        \"timestamp\": data[\"open_ts\"],\n        \"o\": data[\"open\"],\n        \"h\": data[\"high\"],\n        \"l\": data[\"low\"],\n        \"c\": data[\"close\"],\n        \"v\": data[\"volume\"]\n    }\n\nasync def main():\n    postgres = (sf.PostgresEmitter(host=\"localhost\", dbname=\"crypto\")\n        .set_model(CustomKlineTable)\n        .set_transformer(schema_mapper)  # Apply transformer\n        .on_conflict([\"exchange\", \"ticker\", \"tf\", \"timestamp\"])\n    )\n\n    stream = sf.DataInput(\n        type=\"kline\",\n        symbols=[\"BTCUSDT\"],\n        timeframe=\"1m\"\n    )\n\n    runner = sf.BinanceRunner(stream_input=stream)\n    runner.register_emitter(postgres)\n\n    await runner.run()\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/transformers/#example-2-technical-indicators","title":"Example 2: Technical Indicators","text":"<p>Add computed technical indicators:</p> <pre><code>def add_indicators(data: dict) -&gt; dict:\n    \"\"\"Add technical analysis fields\"\"\"\n\n    # Price metrics\n    price_change = data[\"close\"] - data[\"open\"]\n    price_change_pct = (price_change / data[\"open\"]) * 100\n\n    # Candle metrics\n    body_size = abs(price_change)\n    upper_shadow = data[\"high\"] - max(data[\"open\"], data[\"close\"])\n    lower_shadow = min(data[\"open\"], data[\"close\"]) - data[\"low\"]\n    total_range = data[\"high\"] - data[\"low\"]\n\n    return {\n        **data,\n        # Price changes\n        \"price_change\": price_change,\n        \"price_change_pct\": price_change_pct,\n\n        # Candle type\n        \"is_bullish\": data[\"close\"] &gt; data[\"open\"],\n        \"is_doji\": body_size &lt; (total_range * 0.1),\n\n        # Candle components\n        \"body_size\": body_size,\n        \"upper_shadow\": upper_shadow,\n        \"lower_shadow\": lower_shadow,\n        \"total_range\": total_range,\n\n        # Ratios\n        \"body_ratio\": body_size / total_range if total_range &gt; 0 else 0,\n        \"upper_shadow_ratio\": upper_shadow / total_range if total_range &gt; 0 else 0,\n        \"lower_shadow_ratio\": lower_shadow / total_range if total_range &gt; 0 else 0,\n    }\n\n# Use with CSV\ncsv = sf.CSVEmitter(\n    source=\"Binance\",\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    file_path=\"btc_with_indicators.csv\",\n    transformer_function=add_indicators\n)\n</code></pre>"},{"location":"user-guide/transformers/#example-3-data-validation","title":"Example 3: Data Validation","text":"<p>Filter and validate data:</p> <pre><code>def validate_and_clean(data: dict) -&gt; dict:\n    \"\"\"Validate and clean data\"\"\"\n\n    # Ensure positive values\n    if data[\"open\"] &lt;= 0 or data[\"high\"] &lt;= 0 or data[\"low\"] &lt;= 0 or data[\"close\"] &lt;= 0:\n        raise ValueError(f\"Invalid price data: {data}\")\n\n    # Ensure high &gt;= low\n    if data[\"high\"] &lt; data[\"low\"]:\n        raise ValueError(f\"High &lt; Low: {data}\")\n\n    # Ensure volume is non-negative\n    if data[\"volume\"] &lt; 0:\n        data[\"volume\"] = 0\n\n    # Round prices to 2 decimals\n    return {\n        **data,\n        \"open\": round(data[\"open\"], 2),\n        \"high\": round(data[\"high\"], 2),\n        \"low\": round(data[\"low\"], 2),\n        \"close\": round(data[\"close\"], 2),\n        \"volume\": round(data[\"volume\"], 8)\n    }\n\nemitter.set_transformer(validate_and_clean)\n</code></pre>"},{"location":"user-guide/transformers/#transformer-with-backfilling","title":"Transformer with Backfilling","text":"<p>Apply transformers during historical data loading:</p> <pre><code>def my_transformer(data: dict) -&gt; dict:\n    return {\n        **data,\n        \"price_change_pct\": ((data[\"close\"] - data[\"open\"]) / data[\"open\"]) * 100\n    }\n\nbackfiller = sf.BinanceBackfilling(\n    symbol=\"BTCUSDT\",\n    timeframe=\"1m\",\n    from_date=\"2024-01-01\",\n    to_date=\"2024-12-31\"\n)\n\nbackfiller.set_transformer(my_transformer)\nbackfiller.register_emitter(emitter)\nbackfiller.run()\n</code></pre>"},{"location":"user-guide/transformers/#performance-considerations","title":"Performance Considerations","text":""},{"location":"user-guide/transformers/#keep-transformers-fast","title":"Keep Transformers Fast","text":"<p>Transformers run on every data point:</p> <pre><code># \u2713 Good - simple operations\ndef fast_transformer(data: dict) -&gt; dict:\n    return {\n        **data,\n        \"price_change\": data[\"close\"] - data[\"open\"]\n    }\n\n# \u2717 Slow - heavy computation\ndef slow_transformer(data: dict) -&gt; dict:\n    # Don't do this on every data point!\n    import time\n    time.sleep(1)  # Blocks pipeline\n    return data\n</code></pre>"},{"location":"user-guide/transformers/#avoid-external-api-calls","title":"Avoid External API Calls","text":"<p>Don't make network requests in transformers:</p> <pre><code># \u2717 Bad - blocks on every data point\ndef bad_transformer(data: dict) -&gt; dict:\n    response = requests.get(\"https://api.example.com/rate\")  # Slow!\n    data[\"exchange_rate\"] = response.json()[\"rate\"]\n    return data\n\n# \u2713 Good - cache external data\nclass CachedTransformer:\n    def __init__(self):\n        self.exchange_rate = self.fetch_rate()\n\n    def fetch_rate(self):\n        # Fetch once\n        return requests.get(\"https://api.example.com/rate\").json()[\"rate\"]\n\n    def transform(self, data: dict) -&gt; dict:\n        return {\n            **data,\n            \"exchange_rate\": self.exchange_rate  # Use cached value\n        }\n</code></pre>"},{"location":"user-guide/transformers/#testing-transformers","title":"Testing Transformers","text":"<p>Test transformers in isolation:</p> <pre><code>def my_transformer(data: dict) -&gt; dict:\n    return {\n        **data,\n        \"price_change\": data[\"close\"] - data[\"open\"]\n    }\n\n# Test it\ntest_data = {\n    \"source\": \"Binance\",\n    \"symbol\": \"BTCUSDT\",\n    \"timeframe\": \"1m\",\n    \"open_ts\": 1735689600000,\n    \"end_ts\": 1735689659999,\n    \"open\": 43250.00,\n    \"high\": 43275.00,\n    \"low\": 43240.00,\n    \"close\": 43260.00,\n    \"volume\": 12.45\n}\n\nresult = my_transformer(test_data)\nprint(result)\n\nassert \"price_change\" in result\nassert result[\"price_change\"] == 10.00\nprint(\"\u2713 Transformer test passed!\")\n</code></pre>"},{"location":"user-guide/transformers/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/transformers/#1-use-type-hints","title":"1. Use Type Hints","text":"<pre><code>def my_transformer(data: dict) -&gt; dict:\n    \"\"\"\n    Transform kline data.\n\n    Args:\n        data: Kline dictionary\n\n    Returns:\n        Transformed dictionary\n    \"\"\"\n    return modified_data\n</code></pre>"},{"location":"user-guide/transformers/#2-document-transformations","title":"2. Document Transformations","text":"<pre><code>def complex_transformer(data: dict) -&gt; dict:\n    \"\"\"\n    Apply multiple transformations:\n    1. Rename fields for database schema\n    2. Add price change percentage\n    3. Add technical indicators\n    4. Round prices to 2 decimals\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"user-guide/transformers/#3-keep-original-data","title":"3. Keep Original Data","text":"<p>Use spread operator to preserve original:</p> <pre><code>def safe_transformer(data: dict) -&gt; dict:\n    return {\n        **data,  # Keep original\n        \"new_field\": \"value\"  # Add new\n    }\n</code></pre>"},{"location":"user-guide/transformers/#4-handle-missing-fields","title":"4. Handle Missing Fields","text":"<pre><code>def robust_transformer(data: dict) -&gt; dict:\n    \"\"\"Handle optional fields\"\"\"\n    return {\n        **data,\n        \"price_change\": data.get(\"close\", 0) - data.get(\"open\", 0)\n    }\n</code></pre>"},{"location":"user-guide/transformers/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/transformers/#pattern-1-rename-for-schema","title":"Pattern 1: Rename for Schema","text":"<pre><code>def rename_for_db(data: dict) -&gt; dict:\n    return {\n        \"db_field_1\": data[\"source\"],\n        \"db_field_2\": data[\"symbol\"],\n        # ... map all fields\n    }\n</code></pre>"},{"location":"user-guide/transformers/#pattern-2-add-computed-fields","title":"Pattern 2: Add Computed Fields","text":"<pre><code>def add_metrics(data: dict) -&gt; dict:\n    return {\n        **data,\n        \"metric1\": compute_metric1(data),\n        \"metric2\": compute_metric2(data)\n    }\n</code></pre>"},{"location":"user-guide/transformers/#pattern-3-filter-and-clean","title":"Pattern 3: Filter and Clean","text":"<pre><code>def clean_data(data: dict) -&gt; dict:\n    return {\n        k: v for k, v in data.items()\n        if k in [\"field1\", \"field2\", \"field3\"]\n    }\n</code></pre>"},{"location":"user-guide/transformers/#next-steps","title":"Next Steps","text":"<ul> <li>Aggregation \u2192 - Multi-timeframe streaming</li> <li>Examples \u2192 - See transformers in action</li> <li>API Reference \u2192 - Emitter API details</li> </ul>"}]}